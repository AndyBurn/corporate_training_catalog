{
  "@odata.context": "https://corporatetrainingcatalogsearch.search.windows.net/indexes('azureblob-index')/$metadata#docs(*)",
  "value": [
    {
      "@search.score": 1.4933738,
      "content": "\nORIGINAL RESEARCH\n\nDiscriminated by an algorithm: a systematic review\nof discrimination and fairness by algorithmic decision-\nmaking in the context of HR recruitment and HR\ndevelopment\n\nAlina Köchling1\n• Marius Claus Wehner1\n\nReceived: 15 October 2019 / Accepted: 1 November 2020 / Published online: 20 November 2020\n\n� The Author(s) 2020\n\nAbstract Algorithmic decision-making is becoming increasingly common as a new\n\nsource of advice in HR recruitment and HR development. While firms implement\n\nalgorithmic decision-making to save costs as well as increase efficiency and\n\nobjectivity, algorithmic decision-making might also lead to the unfair treatment of\n\ncertain groups of people, implicit discrimination, and perceived unfairness. Current\n\nknowledge about the threats of unfairness and (implicit) discrimination by algo-\n\nrithmic decision-making is mostly unexplored in the human resource management\n\ncontext. Our goal is to clarify the current state of research related to HR recruitment\n\nand HR development, identify research gaps, and provide crucial future research\n\ndirections. Based on a systematic review of 36 journal articles from 2014 to 2020,\n\nwe present some applications of algorithmic decision-making and evaluate the\n\npossible pitfalls in these two essential HR functions. In doing this, we inform\n\nresearchers and practitioners, offer important theoretical and practical implications,\n\nand suggest fruitful avenues for future research.\n\nKeywords Fairness � Discrimination � Perceived fairness � Ethics �\nAlgorithmic decision-making in HRM � Literature review\n\n1 Introduction\n\nAlgorithmic decision-making in human resource management (HRM) is becoming\n\nincreasingly common as a new source of information and advice, and it will gain\n\nmore importance due to the rapid growth of digitalization in organizations.\n\n& Alina Köchling\n\nalina.koechling@hhu.de\n\n1 Faculty of Business Administration and Economics, Heinrich-Heine-University Düsseldorf,\n\nUniversitätsstrasse 1, 40225 Dusseldorf, Germany\n\n123\n\nBusiness Research (2020) 13:795–848\n\nhttps://doi.org/10.1007/s40685-020-00134-w\n\nhttp://orcid.org/0000-0001-7039-9852\nhttp://orcid.org/0000-0002-1932-3155\nhttp://crossmark.crossref.org/dialog/?doi=10.1007/s40685-020-00134-w&amp;domain=pdf\nhttps://doi.org/10.1007/s40685-020-00134-w\n\n\nAlgorithmic decision-making is defined as automated decision-making and remote\n\ncontrol, as well as standardization of routinized workplace decisions (Möhlmann\n\nand Zalmanson 2017). Algorithms, instead of humans, make decisions, and this has\n\nimportant individual and societal implications in organizational optimization\n\n(Chalfin et al. 2016; Lee 2018; Lindebaum et al. 2019). These changes in favor\n\nof algorithmic decision-making make it easier to discover hidden talented\n\nemployees in organizations and review a large number of applications automatically\n\n(Silverman and Waller 2015; Carey and Smith 2016; Savage and Bales 2017). In a\n\nsurvey of 200 artificial intelligence (AI) specialists from German companies, 79%\n\nstated that AI is irreplaceable for competitive advantages (Deloitte 2020). Several\n\ncommercial providers, such as Google, IBM, SAP, and Microsoft, already offer\n\nalgorithmic platforms and systems that facilitate current human resource (HR)\n\npractices, such as hiring and performance measurements (Walker 2012). In turn,\n\nwell-known and large companies, such as Vodafone, Intel, Unilever, and Ikea, apply\n\nalgorithmic decision-making in HR recruitment and HR development (Daugherty\n\nand Wilson 2018; Precire 2020).\n\nThe major driving forces for algorithmic decision-making are savings in both\n\ncosts and time, minimizing risks, enhancing productivity, and increasing certainty in\n\ndecision-making (Suen et al. 2019; McDonald et al. 2017; McColl and Michelotti\n\n2019; Woods et al. 2020). Besides these economic reasons, firms seek to diminish\n\nthe human biases (e.g., prejudices and personal beliefs) by applying algorithmic\n\ndecision-making, thereby increasing the objectivity, consistency, and fairness of the\n\nHR recruitment as well as HR development processes (Langer et al. 2019;\n\nFlorentine 2016; Raghavan et al. 2020). For example, Deloitte argues that the\n\nalgorithmic decision-making system always manages each application with the\n\nsame attention according to the same requirements and criteria (Deloitte 2018). At\n\nfirst glance, algorithmic decision-making seems to be more objective and fairer than\n\nhuman decision-making (Lepri et al. 2018).\n\nHowever, there is a possible threat of discrimination and unfairness by relying\n\nsolely on algorithmic decision-making (e.g., (Lee 2018; Lindebaum et al. 2019;\n\nSimbeck 2019)). In general, discrimination is defined as the unequal treatment of\n\ndifferent groups based on gender, age, or ethnicity instead of on qualitative\n\ndifferences, such as individual performance (Arrow 1973). Algorithms produce\n\ndiscrimination or biased outcomes if they are trained on inaccurate (Kim 2016),\n\nbiased (Barocas and Selbst 2016), or unrepresentative input data (Suresh and Guttag\n\n2019). Consequently, algorithms are vulnerable to produce or replicate biased\n\ndecisions if their input (or training) data are biased (Chander 2016).\n\nComplicating this issue, biases and discrimination are often only recognized after\n\nalgorithms have made a decision. As a prominent example stemming from the\n\ncurrent debate around transparency, bias, and fairness in algorithmic decision-\n\nmaking (Dwork et al. 2012; Lepri et al. 2018; Diakopoulos 2015), the hiring\n\nalgorithms applied by the American e-commerce specialist Amazon yielded an\n\nextreme disadvantage of female applicants, which finally led Amazon to shut down\n\nthe complete algorithmic decision-making for their hiring decision (Dastin 2018;\n\nMiller 2015). Thus, the lack of transparency and accountability of the input data, the\n\nalgorithm itself, and the factors influencing algorithmic outcomes are potential\n\n796 Business Research (2020) 13:795–848\n\n123\n\n\n\nissues associated with algorithmic decision-making (Citron and Pasquale 2014;\n\nPasquale 2015). Another question remains whether applicants and/or employees\n\nperceive the algorithmic decision-making to be fair. Previous studies showed that\n\napplicants’ and employees’ acceptance of algorithmic decision-making is lower in\n\nHR recruitment and HR development compared to common procedures conducted\n\nby humans (Kaibel et al. 2019; Langer et al. 2019; Lee 2018).\n\nConsequently, there is a discrepancy between the enthusiasm about algorithmic\n\ndecision-making as a panacea for inefficiencies and labor shortages on one hand and\n\nthe threat of discrimination and unfairness of algorithmic decision-making on the\n\nother side. While the literature in the field of computer science has already\n\naddressed the issues of biases, knowledge about the potential downsides of\n\nalgorithmic decision-making is still in its infancy in the field of HRM despite its\n\nimportance due to increased digitization and automation in HRM. This heteroge-\n\nneous state of research on discrimination and fairness raises distinct challenges for\n\nfuture research. From a practical point of view, it is problematic if large and well-\n\nknown companies implement algorithms without being aware of the possible pitfalls\n\nand negative consequences. Thus, to move the field forward, it is paramount to\n\nsystematically review and synthesize existing knowledge about biases and\n\ndiscrimination in algorithmic decision-making and to offer new research avenues.\n\nThe aim of this study is threefold. First, this review creates an awareness of\n\npotential biases and discrimination resulting from algorithmic decision-making in\n\nthe context of HR recruitment and HR development. Second, this study contributes\n\nto the current literature by informing both researchers and practitioners about the\n\npotential dangers of algorithmic decision-making in the HRM context. Finally, we\n\nguide future research directions with an understanding of existing knowledge and\n\ngaps in the literature. To this end, the present paper conducts a systematic review of\n\nthe current literature with a focus on HR recruitment and HR development. These\n\ntwo HR functions deal with the potential of future and current employees and the\n\n(automatic) prediction of person-organization fit, career development, and future\n\nperformance (Huselid 1995; Walker 2012). Decisions made by algorithms and AI in\n\nthese two important HR areas have serious consequences for individuals, the\n\ncompany, and society concerning ethics and both procedural and distributive\n\nfairness (Ötting and Maier 2018; Lee 2018; Tambe et al. 2019; Cappelli et al. 2020).\n\nOur study contributes to the existing body of research in several ways. First, the\n\nsystematic literature review contributes to the literature by highlighting the current\n\ndebate on ethical issues associated with algorithmic decision-making, including bias\n\nand discrimination (Barocas and Selbst 2016). Second, our research provides\n\nillustrative examples of various algorithmic decision-making tools used in HR\n\nrecruitment, HR development, and their potential for discrimination and perceived\n\nfairness. Moreover, our systematic review underlines the fact that it is a timely topic\n\ngaining enormous importance. Companies will face legal and reputational risk if\n\ntheir HR recruitment and HR development methods turn out to be discriminatory,\n\nand applicants and employees may consider the algorithmic selection or develop-\n\nment process to be unfair.\n\nFor this reason, companies need to know that the use of algorithmic decision-\n\nmaking can yield to discrimination, unfairness, and dissatisfaction in the context of\n\nBusiness Research (2020) 13:795–848 797\n\n123\n\n\n\nHRM. We offer an understanding of how discrimination might arise when\n\nimplementing algorithmic decision-making. We try to give guidance on how\n\ndiscrimination and perceived unfairness could be avoided and provide detailed\n\ndirections for future research in the existing literature, especially in the HRM field.\n\nMoreover, we identify several research gaps, mainly a lacking focus on perceived\n\nfairness.\n\nThe paper is organized as follows: first, we give an understanding of key terms\n\nand definitions. Afterward, we present the methodology of our systematic literature\n\nreview accompanied by a descriptive analysis of the reviewed literature. This is\n\nfollowed by an illustration of the current state of knowledge on algorithmic\n\ndecision-making and subsequent discussion. Finally, we offer practical as well as\n\ntheoretical implications and outline future research avenues.\n\n2 Conceptual background and definitions\n\n2.1 Definition of algorithms\n\nThe Oxford Living Dictionary defines algorithms as ‘‘processes or sets of rules to be\n\nfollowed in calculations or other problem-solving operations, especially by a\n\ncomputer.’’ Möhlmann and Zalmanson (2017) refer to algorithmic decision-making\n\nas automated decision-making and remote control, and standardization of routinized\n\nworkplace decision. Thus, in this paper, we use the term algorithmic decision-\n\nmaking to describe a computational mechanism that autonomously makes decisions\n\nbased on rules and statistical models without explicit human interference (Lee\n\n2018). Algorithms are the basis for several AI decision tools.\n\nAI is an umbrella term for a wide array of models, methods, and prescriptions\n\nused to simulate human intelligence, often when it comes to collecting, processing,\n\nand acting on data. AI applications can apply rules, learn over time through the\n\nacquisition of new data and information, and adapt to changes in the environment\n\n(Russell and Norvig 2016). AI includes several different research areas, such as\n\nmachine learning (ML), speech and image recognition, and natural language\n\nprocessing (NLP) (Kaplan and Haenlein 2019; Paschen et al. 2020).\n\nAs mentioned, the basis for many AI decision-making tools used in HR are ML\n\nalgorithms, which can be categorized into three major types: supervised, unsuper-\n\nvised, and reinforcement learning (Lee and Shin 2020). Supervised ML algorithms\n\naim to make predictions (often divided into classification- or regression-type\n\nproblems), given the input data and desired outputs considered as the ground truth.\n\nHuman experts often provide these labels and thus provide the algorithm with the\n\nground truth. To replicate human decisions or to make predictions, the algorithm\n\nlearns patterns from the labeled data and develops rules, which can be applied for\n\nfuture instances for the same problem (Canhoto and Clear 2020). In contrast, in\n\nunsupervised ML, only input data are given, and the model learns patterns from the\n\ndata without a priori labeling (Murphy 2012). Unsupervised ML algorithms capture\n\nthe structural behaviors of variables in the input data for theme analysis or grouping\n\n798 Business Research (2020) 13:795–848\n\n123\n\n\n\ndata (Canhoto and Clear 2020). Finally, reinforcement learning, as a separate group\n\nof methods, is not based on fixed input/output data. Instead, the ML algorithm learns\n\nbehavior through trial-and-error interactions with a dynamic environment (Kael-\n\nbling et al. 1996).\n\nFurthermore, instead of grouping ML models as supervised, unsupervised, or\n\nreinforcement type learning, the methodologies of algorithms may also be used to\n\ncategorize ML models. Examples are probabilistic models, which may be used in\n\nsupervised or unsupervised settings (Murphy 2012), or deep learning models (Lee\n\nand Shin 2020), which rely on artificial neural networks and perform complex\n\nlearning tasks. In supervised settings, neural network models often determine the\n\nrelationship between input and output using network structures containing the so-\n\ncalled hidden layers, meaning phases of transformation of the input data. Single\n\nnodes of these layers (neurons) were first modeled after neurons in the human brain,\n\nand they resemble human thinking (Bengio et al. 2017). In other settings, deep\n\nlearning may be used, for instance, to (1) process information through multiple\n\nstages of nonlinear transformation; or (2) determine features, representations of the\n\ndata providing an advantage for, e.g., prediction tasks (Deng and Yu 2014).\n\n2.2 Reason for biases\n\nFor any estimation bY of a random variable Y , bias refers to the difference between\n\nthe expected values of bY and Y and is also referred to as systematic error\n\n(Kauermann and Kuechenhoff 2010; Goodfellow et al. 2016). Cognitive biases,\n\nspecifically, are systematic errors in human judgment when dealing with uncertainty\n\n(Kahneman et al. 1982). These cognitive biases are thought to be transferred to\n\nalgorithmic evaluations or predictions, where bias may refer to ‘‘computer systems\n\nthat systematically and unfairly discriminate against certain individuals or groups in\n\nfavor of others’’ (Friedman and Nissenbaum 1996, p. 332).\n\nAlgorithms are often characterized as ‘‘black box’’. In the context of HRM,\n\nCheng and Hackett (2019) characterize algorithms as ‘‘glass boxes’’, since some,\n\nbut not all, components of the theory are reflective. In this context, the consideration\n\nand distinction of the three core elements are necessary, namely, transparency,\n\ninterpretability, and explainability (Roscher et al. 2020). Transparency is concerned\n\nwith the ML approach, while interpretability is concerned with the ML model in\n\ncombination with the data, which means the making sense of the obtained ML\n\nmodel (Roscher et al. 2020). Finally, explainability comprises the model, the data,\n\nand human involvement (Roscher et al. 2020). Concerning the former, transparency\n\ncan be distinguished at three different levels: ‘‘[…] at the level of the entire model\n\n(simulatability), at the level of individual components, such as parameters\n\n(decomposability), and at the level of the training (algorithmic transparency)’’\n\n(Roscher et al. 2020, p. 4). Interpretability concerns the characteristics of an ML\n\nmodel that need to be understood by a human (Roscher et al. 2020). Finally, the\n\nelement of explainability is paramount in HRM. Contextual information of human\n\nand their knowledge from the domain of HRM are necessary to explain the different\n\nsets of interpretations and derive conclusions about the results of the algorithms\n\nBusiness Research (2020) 13:795–848 799\n\n123\n\n\n\n(Roscher et al. 2020). Especially in HRM, in which ML algorithms are increasingly\n\nused for prediction of variables of interest to the HR department (e.g., personality\n\ncharacteristics, employee satisfaction, and turnover intentions), it is essential to\n\nunderstand how the ML algorithm operates (e.g., how the ML algorithm uses data\n\nand weighs specific criteria) and the underlying reasons for the produced decision.\n\nIn the following, we will outline the main reasons for biases in algorithmic\n\ndecision-making and briefly summarize different biases, namely historical, repre-\n\nsentation, technical, and emergent bias. One of the main reasons for bias in\n\nalgorithmic decision-making is the quality of input data, because algorithms learn\n\nfrom historical data as an example; thus, the learning process depends on the\n\nexposed examples (Friedman and Nissenbaum 1996; Barocas and Selbst 2016;\n\nDanks and London 2017). The input data are usually historical. Consequently, if the\n\ninput data set is biased in one way or another, the subsequent analysis is biased, as\n\nwell (keyword: ‘‘garbage in, garbage out’’). For example, if the input data of an\n\nalgorithm include implicit or explicit human judgments, stereotypes, or biases, an\n\naccurate algorithmic output will inevitably entail these human judgments, stereo-\n\ntypes, and prejudices (Diakopoulos 2015; Suresh and Guttag 2019; Barfield and\n\nPagallo 2018). This bias usually exists before the creation of the system and may not\n\nbe apparent at first glance. In turn, the algorithm replicates these preexisting biases,\n\nbecause it treats all information, in which a certain kind of discrimination or bias is\n\nembedded, as a valid example (Barocas and Selbst 2016; Lindebaum et al. 2019). In\n\nthe worst case, the algorithm can yield racist or discriminatory outputs (Veale and\n\nBinns 2017). Algorithms exhibit these tendencies, even if it is not the intention of\n\nthe manual programming since they compound the historical biases of the past.\n\nThus, any predictive algorithmic decision-making tool built on historical data may\n\ninherit historical biases (Datta et al. 2015).\n\nAs an example from the recruitment process, if an algorithm is trained on\n\nhistorical employment data, integrating an implicit bias that favors white men over\n\nHispanics, then, without even being fed data on gender or ethnicity, an algorithm\n\nmay recognize patterns in the data, which expose an applicant as a member of a\n\ncertain protected group, which, historically, is less likely to be chosen for a job\n\ninterview. This, in turn, may lead to a systematic disadvantage of certain groups,\n\neven if the designer has no intention of marginalizing people based on these\n\ncategories and if the algorithm is not directly given this information (Barocas and\n\nSelbst 2016).\n\nAnother reason for biases in algorithms related to the input data is that certain\n\ngroups or characteristics are mostly underrepresented or sometimes overrepre-\n\nsented, which is also called representation bias (Barocas and Selbst 2016; Suresh\n\nand Guttag 2019; Barfield and Pagallo 2018). Any decision based on this kind of\n\nbiased data might lead to disadvantages of groups of individuals who are\n\nunderrepresented or overrepresented (Barocas and Selbst 2016). Another reason\n\nfor representation bias can be the absence of specific information (Barfield and\n\nPagallo 2018). Thus, not only the selection of measurements but also the\n\npreprocessing of the measurement data might yield to bias. ML models often\n\nevolve in several steps of feature engineering or model testing, since there is no\n\nuniversally best model (as shown in the ‘‘no free lunch’’ theorems, [see Wolpert and\n\n800 Business Research (2020) 13:795–848\n\n123\n\n\n\nMacready (1997)]. Here, the choice of the benchmark or rather the value indicating\n\nthe performance of the model is optimized through rotations of different\n\nrepresentations of the data and methods for prediction. For example, representative\n\nbias might occur if females in comparison to males are underrepresented in the\n\ntraining data of an algorithm. Hence, the outcome could be in favor of the\n\noverrepresented group (i.e., males) and, hence, lead to discriminatory outcomes.\n\nTechnical bias may arise from technical constraints or technical consideration for\n\nseveral reasons. For example, technical bias can originate from limited ‘‘[…]\n\ncomputer technology, including hardware, software, and peripherals’’ (Friedman\n\nand Nissenbaum 1996, p. 334). Another reason could be a decontextualized\n\nalgorithm that does not manage to treat all groups fairly under all important\n\nconditions (Friedman and Nissenbaum 1996; Bozdag 2013). The formalization of\n\nhuman constructs to computers can be another problem leading to technical bias.\n\nHuman constructs, such as judgments or intuitions, are often hard to quantify, which\n\nmakes it difficult or even impossible to translate them to the computer (Friedman\n\nand Nissenbaum 1996). As an example, the human interpretation of law can be\n\nambiguous and highly dependent on the specific context, making it difficult for an\n\nalgorithmic system to correctly advise in litigation (c.f., Friedman and Nissenbaum\n\n1996).\n\nIn the context of real users, emergent bias may arise. Typically, this bias occurs\n\nafter the construction as a result of changed societal knowledge, population, or\n\ncultural values (Friedman and Nissenbaum 1996). Consequently, a shift in the\n\ncontext of use might yield to problems and an emergent bias due to two reasons,\n\nnamely ‘‘new societal knowledge’’ and ‘‘mismatch between users and system\n\ndesign’’ (see Table 1 in Friedman and Nissenbaum 1996, p. 335). If it is not possible\n\nto incorporate new knowledge in society into the system design, emergent bias due\n\nto new societal knowledge occurs. The mismatch between users and system design\n\ncan occur due to changes in state-of-the-art-research or due to different values. Also,\n\nemergent bias can occur if a population uses the system with different values than\n\nthose assumed in the design process (Friedman and Nissenbaum 1996). Problems\n\noccur, for example, when users originate from a cultural context that avoids\n\ncompetition and promotes cooperative efforts, while the algorithm is trained to\n\nreward individualistic and competitive behavior (Friedman and Nissenbaum 1996).\n\n2.3 Fairness and discrimination in information systems\n\nLeventhal (1980) describes fairness as equal treatment based on people’s\n\nperformance and needs. Table 1 offers an overview of the different fairness\n\ndefinitions. Individual fairness means that, independent of group membership, two\n\nindividuals who are perceived to be similar by the measures at hand should also be\n\ntreated similarly (Dwork et al. 2012). Rising from the micro-level onto the meso-\n\nlevel, Dwork et al. (2012) also proposed another measure of fairness, that is, group\n\nfairness, in which entire (protected) groups of people are required to be treated\n\nsimilarly (statistical parity). Hardt et al. (2016) extended these notions by including\n\ntrue outcomes of predicted variables to achieve fair treatment. In their sense, false-\n\nBusiness Research (2020) 13:795–848 801\n\n123\n\n\n\npositives/negatives are sources of disadvantage and should be equal among groups\n\nmeans equal opportunity for false-positives/negatives (Hardt et al. 2016).\n\nUnfair treatment of certain groups of people or individual subjects yields to\n\ndiscrimination. Discrimination is defined as the unequal treatment of different\n\ngroups (Arrow 1973). Discrimination is very similar to unfairness. Discriminatory\n\ncategories can be strongly correlated with non-discriminatory categories, such as\n\nage (i.e., discriminatory) and years of working experience (non-discriminatory)\n\n(Persson 2016). Also, there is a difference between implicit and explicit\n\ndiscrimination. Implicit discrimination is based on implicit attitudes or stereotypes\n\nand often unintentional (Bertrand et al. 2005). In contrast, explicit discrimination is\n\na conscious process due to an aversion to certain groups of people. In HR\n\nrecruitment and HR development, discrimination means the not-hiring or support of\n\na person due to characteristics not related to that person’s productivity in the current\n\nposition (Frijters 1998).\n\nThe HR literature, especially the literature on personnel selection, is concerned\n\nwith fairness in hiring decisions, because every selection measure of individual\n\ndifferences is inevitably discriminatory (Cascio and Aguinis 2013). However, the\n\nquestion arises ‘‘whether the measure discriminates unfairly’’ (Cascio and Aguinis\n\n2013, p. 183). Hence, the actual fairness of prediction systems needs to be tested\n\nbased on probabilities and estimates, which we refer to as objective fairness. In the\n\nselection context, the literature distinguishes between differential validity (i.e.,\n\ndifferences in subgroup validity) and differential prediction (i.e., differences in\n\nslopes and intercepts of subgroups), and both might lead to biased results (Meade\n\nand Fetzer 2009; Roth et al. 2017; Bobko and Bartlett 1978).\n\nIn HR recruitment and HR development, both objective fairness and subjective\n\nfairness perceptions of applicants and employees about the usage of algorithmic\n\ndecision-making need to be considered. In this regard, perceived fairness or justice\n\nis more a subjective and descriptive personal evaluation rather than an objective\n\nreality (Cropanzano et al. 2007). Subjective fairness plays an essential role in the\n\nrelationship between humans and their employers. Previous studies showed that the\n\nTable 1 Definitions of fairness\n\nName Author Definition\n\nIndividual\n\nfairness\n\nDwork et al.\n\n(2012)\n\n‘‘Similar’’ subjects should have ‘‘similar’’ classifications\n\nGroup\n\nfairness\n\nSubjects in protected and unprotected groups have an equal probability\n\nof being assigned positive\n\nP bY ¼ 1\n� �\n\n�\n\n�G ¼ 1Þ ¼ Pð bY ¼ 1jG ¼ 0Þ\n\nEqual\n\nopportunity\n\nHardt et al.\n\n(2016)\n\nFalse-negative rates should be equal\n\nP bY ¼ 0\n� �\n\n�\n\n�Y ¼ 1;G ¼ 1Þ ¼ Pð bY ¼ 0jY ¼ 1;G ¼ 0Þ\n\nY 2 0; 1f g is a random variable describing, e.g., the recidivism of a subject, bY its estimator and G 2\nf0; 1g; describes whether a subject is a member of a certain protected group (G ¼ 1Þ or not ðG ¼ 0Þ\n\n802 Business Research (2020) 13:795–848\n\n123\n\n\n\nlikelihood of conscientious behavior and altruisms is higher for employees who feel\n\ntreated fairly (Cohen-Charash and Spector 2001). Conversely, unfairness can have\n\nconsiderable adverse consequences. For example, in the recruitment context,\n\nfairness perceptions of candidates during the selection process have important\n\nconsequences for decision to stay in the applicant pool or accept a job offer (Bauer\n\net al. 2001). Therefore, it is crucial to know how people feel about algorithmic\n\ndecision-making taking over managerial decisions formerly made by humans, since\n\nthe fairness perceptions during the recruitment process and/or training process have\n\nessential and meaningful effects on attitudes, performance, morale, intentions, and\n\nbehavior (e.g., the acceptance or rejection of a job offer or job turnover, job\n\ndissatisfaction, and reduction or elimination of conflicts) (Gilliland 1993; McCarthy\n\net al. 2017; Hausknecht et al. 2004; Cropanzano et al. 2007; Cohen-Charash and\n\nSpector 2001). Moreover, negative experiences might damage the employer�s\nimage. Several online platforms offer the possibility of rating companies and their\n\nrecruitment and development process (Van Hoye 2013; Woods et al. 2020).\n\nConsidering justice and fairness in the organizational context (Gilliland 1993),\n\nthere are three core dimensions of justice: distributive, procedural, and interactional.\n\nThe three dimensions tend to be correlated. Distributive justice deals with the\n\noutcome that some humans receive and some do not (Cropanzano et al. 2007). Rules\n\nthat can lead to distributive justice are ‘‘[…] equality (to each the same), equity (to\n\neach in accordance with contributions, and need (to each in accordance with the\n\nmost urgency)’’ (Cropanzano et al. 2007, p. 37). To some extent, especially\n\nconcerning equity, this can be connected with individual fairness and group fairness\n\nfrom Dwork et al. (2012) and equal opportunities from Hardt et al. (2016).\n\nProcedural justice means that the process is consistent with all humans, not\n\nincluding bias, accurate, and consistent with the ethical norms (Cropanzano et al.\n\n2007; Leventhal 1980). Consistency plays an essential role in procedural justice,\n\nmeaning that all employees and all candidates need to receive the same treatment.\n\nAdditionally, the lack of bias, accuracy, representation of all parties, correction, and\n\nethics play an important role in achieving a high procedural justice (Cropanzano\n\net al. 2007). In contrast, interactional justice is about the treatment of humans,\n\nmeaning the appropriateness of the treatment from another member of the company,\n\nthe treatment with dignity, courtesy, and respect, and informational justice (share of\n\nrelevant information) (Cropanzano et al. 2007).\n\nIn general, algorithmic decision-making increases the standardization of\n\nprocedures, so that decisions should be more objective and less biased, and errors\n\nshould occur less frequently (Kaibel et al. 2019), since information processing by\n\nhuman raters can be unsystematic, leading to contradictory and insufficient\n\nevidence-based decisions (Woods et al. 2020). Consequently, procedural justice and\n\ndistributive justice are higher using algorithmic decision-making, because the\n\nprocess is more standardized, which still not means that it is without bias.\n\nHowever, especially in the context of an application or an employee evaluation, it\n\nis not only about how fair the procedure itself is (according to fairness measures),\n\nbut it is also about how people involved in the decision process perceive the fairness\n\nof the whole process. Often the personal contact, which characterizes the\n\nBusiness Research (2020) 13:795–848 803\n\n123\n\n\n\ninteractional fairness, is missing when using algorithmic decision-making. It is\n\ndifficult to fulfill all three fairness dimensions.\n\n3 Methods\n\nThis systematic literature review aims at offering a coherent, transparent, and\n\nreliable picture of existing knowledge and providing insights into fruitful research\n\navenues about the discrimination potential and fairness when using algorithmic\n\ndecision-making in HR recruitment and HR development. This is in line with other\n\nsystematic literature reviews that organize, evaluate, and synthesize knowledge in a\n\nparticular field and provide an overall picture of knowledge and suggestions for\n\nfuture research (Petticrew and Roberts 2008; Crossan and Apaydin 2010; Siddaway\n\net al. 2019). To this end, we followed the systematic literature review approach\n\ndescribed by Siddaway et al. (2019) and Gough et al. (2017) to ensure a methodical,\n\ntransparent, and replicable approach.1\n\n3.1 Search terms and databases\n\nWe engaged in an extensive keyword searching, which we derived in an iterative\n\nprocess of search and discussion between the two authors of this study (see\n\n‘‘Appendix’’ for the employed keywords). According to our research question, we\n\nfirst defined individual concepts to create search terms. We considered different\n\nterminology, including synonyms, singular/plural forms, different spellings, broader\n\nvs. narrow terms, and classification terms of databases to categorize contents\n\n(Siddaway et al. 2019) (see Table 2 for a complete list of employed keywords and\n\nsearch strings). Our priority was to achieve the balance between sensitivity and\n\nspecificity to get broad coverage of the literature and to avoid the unintentional\n\nomission of relevant articles (Siddaway et al. 2019).\n\nAs the first source of data, we used the social science citation index (SSCI) to\n\nensure broad coverage of scholarly literature. This database covers English-\n\nlanguage peer-reviewed journals in business and management. As part of the Web\n\nof Knowledge, the database includes all journals with an impact factor, which is a\n\nreasonable proxy for the most important publications in the field. We completed our\n\nsearch with the EBSCO Business Source Premier database to add further breadth.\n\nSince electronic databases are not fully comprehensive, we additionally searched in\n\nthe reference section of the considered papers and manually searched for articles\n\n(Siddaway et al. 2019).\n\nWe considered scholarly articles from a high-quality source of evidence (peer-\n\nreviewed and published) journals in English and excluded book reviews, comments,\n\nand editorial notes. Moreover, we searched for unpublished articles in conference\n\nproceedings from renowned conferences, such as AOM, EURAM, ACM, and IEEE,\n\nand contacted the authors to prevent publication bias and to gain further valuable\n\n1 We thank the anonymous reviewer for this valuable recommendation.\n\n804 Business Research (2020) 13:795–848\n\n123\n\n\n\ninsights (Siddaway et al. 2019; Lipsey and Wilson 2001; Ferguson and Brannick\n\n2012). In April 2020, this search approach resulted in 3207 articles.\n\n3.2 Screening, eligibility process, and inclusion process\n\nFollowing this initial identification, we manually screened each article (title and\n\nabstract) to evaluate whether its content was fundamental relevant to impact bias,\n\ndiscrimination, or fairness of algorithmic decision-making in HRM, especially in\n\nrecruitment, selection, development, and training in particular. The process of\n\nTable 2 Overview of search terms, databases, and results\n\nSearch string Database Resultsa\n\nTITLE: (‘‘algorithm* OR algorithmic model* OR data-algorithm*OR algorithmic decision-making OR\n\nalgorithmic decision* OR artificial intelligence OR facial expression tool* OR facial expression\n\nprocessing* OR language processing* OR natural language processing* OR recommender system* OR\n\nsearch engine* OR data*OR data set*’’)\n\nTOPIC: (‘‘discrimination* OR discriminat* OR classification* OR ‘‘classification problem*’’ OR\n\n‘‘classification scheme*’’ OR ‘‘algorithmic discrimination*’’ OR ‘‘algorithmic bias discrimination*’’\n\nOR ‘‘preventing discrimination*’’ OR anti-discrimination* OR non-discrimination* OR gender, age,\n\nsex, sexism, origin OR ‘‘difference* among demographic group*’’ OR ethic* OR ‘‘ethical\n\nimplication*’’ OR ‘‘data mining discrimination*’’ OR ‘‘unfair treatment*’’ OR fair* OR unfair* OR\n\n‘‘perceived fairness’’ OR ‘‘algorithmic fairness’’ OR ‘‘fairness word*’’ OR ‘‘fairness speech*’’ OR\n\n‘‘fairness recommendation*’’ OR equal* OR equit* OR inequal* OR ‘‘equal opportunit*’’ OR\n\ntransparen* OR legal* OR right* OR truth OR impartial* OR correct*OR evaluat* OR judgement* OR\n\n‘‘algorithmic judgement*’’ OR ‘‘human judgement*’’ OR ‘‘mechanical judgement*’’ OR rank* OR\n\nrate* OR measure* OR valuation* OR bias* OR ‘‘algorithmic bias*’’ OR ‘‘national bias*’’ OR gender-\n\nbias* OR ‘‘decision-making bias*’’ OR ‘‘human bias* OR ‘‘technical bias*’’ OR ‘‘implicit bias* in\n\nalgorithm*’’ OR ‘‘dealing with bias*’’ OR ‘‘pattern distortion*’’ OR pre-justice* OR tendenc* OR\n\nprone*OR justiceb OR adverse impactb) AND TOPIC: (‘‘Human Resource*’’ OR ‘‘Human Resource\n\nManagement’’ OR Management OR ‘‘applicant selection*’’ OR ‘‘employee selection*’’ OR ‘‘algorithm-\n\nbased HR decision-making’’ OR ‘‘recruitment process* OR ‘‘application process*’’ OR ‘‘selection\n\nprocess*’’ OR recruitment* OR online-recruitment* OR ‘‘personnel decision*’’, OR ‘‘personnel\n\nselection*’’ OR ‘‘people analytic*’’ OR ‘‘HR analytic*’’ OR ‘‘job advertisement*’’ OR ‘‘online\n\npersonalization*’’)\n\nDOCUMENT TYPES = (ARTICLE)\n\nAND\n\nLANGUAGES = (ENGLISH)\n\nSSCI\n\npsychology, psychology experimental, psychology\n\nmultidisciplinary science, ethics, law, psychology\n\napplied, operations research management science,\n\ncomputer science artificial intelligence, computer\n\nscience interdisciplinary applications, computer\n\nscience information systems, management,\n\nbusiness, behavioral science, social sciences\n\ninterdisciplinary, sociology, social issues,\n\nhumanities interdisciplinary\n\n2892\n\narticles\n\nScholarly (Peer Reviewed) Journals,\n\nAcademic Journal, Article English\n\nEBSCO Business Source Premier 244\n\narticles\n\naResults show the gross hits per search string and database for scholarly articles\nbRobustness check\n\nBusiness Research (2020) 13:795–848 805\n\n123\n\n\n\nrelevance screening resulted in 102 articles that were deemed to be substantially\n\nrelevant.\n\nSecond, we conducted the eligibility stage by reading the full text and shifting\n\nfrom sensitivity to specificity. Studies eligible for our review (1) had to be\n\nconsistent with our definition of algorithmic decision-making as well as with our\n\ndefinitions of fairness, bias, or discrimination (2), and the content had to refer to\n\nHRM (3). The list of studies that we excluded at the eligibility stage is available\n\nupon request. The two authors independently checked each paper to increase the\n\nreliability of the research results. We applied this structured approach to ensure a\n\nhigh level of objectivity.\n\nAfterward, the actual review started, and we synthesized and assessed our\n\nfindings. We analyzed the material abductively following a set of predefined\n\ncategories without, however, relying on preexisting codes to extract all relevant\n\ninformation. Analytic categories were, for example, ‘‘research design,’’ ‘‘field of the\n\njournal,’’ ‘‘research geography,’’ or ‘‘year of publication,’’ and ‘‘key findings.’’\n\nAgain, the authors filled these categories with their inductively generated codes.\n\nOur systematic review used the Preferred Reporting Items for Systematic\n\nReviews (PRISMA) recommendations, including assessment of research content as\n\nwell as a detailed report of the number of records identified through the search and\n\nthe number of studies included and excluded in the review. Figure 1 presents a\n\nPRISMA flow diagram to provide a succinct summary of the process (Siddaway\n\net al. 2019; Moher et al. 2009).\n\n3.3 Robustness check\n\nWe implemented a robustness check to offer a reliable and coherent picture of the\n\ndiscrimination potential and fairness when using algorithmic decision-making in\n\nHR recruitment and HR development. With the robustness check, we want to ensure\n\nthat all relevant articles were included in the literature review. We conducted the\n\nrobustness check 3 months after the actual search process with two additional\n\nkeywords, namely: ‘‘justice’’ and ‘‘adverse impact’’ (see Table 2). The search in the\n\ndatabase SSCI resulted in 632 articles and the EBSCO search in 690 articles. We\n\nmanually screened each article (title and abstract) to assess whether the content was\n\nessentially relevant to bias, discrimination, or the fairness of algorithmic decision-\n\nmaking in HRM, especially recruitment, selection, training, and development. The\n\nmajority of articles dealt with the fairness of algorithmic decision-making, but had\n\nno reference to HR. After manually screening each article, the process of relevance\n\nscreening resulted in eight articles for the eligibility stage. We found that no further\n\narticles can be included in the literature review by reading the full text. Since out of\n\nthese eight articles, three articles were already included in the literature review (Lee\n\n2018; Tambe et al. 2019; Yarger et al. 2019), two articles were excluded in the\n\neligibility stage of the initial search process (Hoffmann 2019; Sumser 2017) (no\n\nreference to HRM and comment), and the remaining three articles neither discussed\n\nfairness nor the HR recruitment and/or HR development context (Varghese et al.\n\n1988; Horton 2017; Gil-Lafuente and Oh 2012). The robustness check verified that\n\nthe literature review offers a reliable and transparent picture of the current literature\n\n806 Business Research (2020) 13:795–848\n\n123\n\n\n\nregarding the discrimination potential and fairness when using algorithmic decision-\n\nmaking in HR recruitment and HR development.\n\n3.4 Limitations of the research process\n\nThis approach is not without limitations. First, the reliance on two databases might\n\nbe regarded as a limitation; however, the approach of selecting two broad and\n\ncommon databases contributed to the validity and replicability of our findings due to\n\nthe extensive coverage of high-impact, peer-reviewed journals in these databases\n\n(Podsakoff et al. 2005). Second, our review focused on two essential HR functions\n\nthat have severe consequences for individuals and society concerning ethics, namely\n\nHR recruitment and HR development. We did not consider other areas of HRM,\n\nsince the focus of other HR functions is mainly the automation process (e.g., pay or\n\nanother administrative task). Thus, the situation is different in HR recruitment and\n\nHR development, because societal decisions are made, which have crucial\n\nconsequences for the individual applicants and employees, such as job offer or\n\npromotion opportunities. Especially when it comes to decisions about individuals\n\nRecords identified through \ndatabase searching\n\n(n = 3,136)\nSc\nre\nen\nin\ng\n\nIn\ncl\nud\n\ned\nEl\nig\nib\nili\nty\n\nId\nen\ntif\nic\nat\nio\nn\n\nAdditional records identified \nthrough other sources\n\n(n = 71)\n\nRecords after duplicates removed\n(n = 3,204)\n\nRecords screened\n(n = 3,204)\n\nRecords excludeda\n\n(n = 3,102)\n\nFull-text articles \nassessed for eligibility\n\n(n = 102)\n\nFull-text articles \nexcluded, with reasonsb\n\n(n = 66)\n\nStudies included in \nliterature review\n\n(n = 36)\n\nFig. 1 PRISMA flow diagram illustrating the process. aTopic did not fit, mostly no HR and/or fairness,\nno obvious discrimination context, bMostly no HR and/or fairness, no discrimination context after\nreading the full text or not meeting the inclusion criteria\n\nBusiness Research (2020) 13:795–848 807\n\n123\n\n\n\nand their potential, objective and perceived fairness is paramount (Ötting and Maier\n\n2018; Lee 2018).\n\nMoreover, only articles written in the English-language were part of the literature\n\nreview. Even though this procedure is accepted practice and there is some evidence\n\nthat including only English articles does not bias the results, it should be noted that\n\nnon-English articles were not included because English is the dominant language in\n\nresearch (Morrison et al. 2012).\n\n4 Descriptive results\n\nThe following section shows the current research landscape. We summarize the\n\nmain characteristics of the identified articles in Table 3 and present the main\n\nfindings in Table 4. This table reports the name of authors, year of publication, the\n\nmain focus of the study (i.e., focus on bias, discrimination, fairness, or perceived\n\nfairness), applied method, the field of research, algorithmic decision-making\n\nsystem, HR context (i.e., recruitment- distinguished between recruitment and\n\nselection- or development), and the key findings. We analyze the main focus and the\n\nkey findings of the studies in the following sections. The table is sorted by the focus\n\nof the article and whether it is on bias as a trigger for unfairness and discrimination\n\nor specifically on fairness and discrimination.\n\nFigure 2 illustrates the distribution of publications over time and the research\n\nmethods used. The first identified article in our sample of literature was published in\n\n2014. From 2014 to 2016, only a few articles are published per year. From 2017,\n\ninterest in algorithmic decision-making and discrimination increased notably. As\n\nshown in Fig. 2, there was enormous interest in the topic in 2019.\n\nFrom a methodological perspective, another noteworthy result of this systematic\n\nreview is the predominance of non-empirical evidence, as Table 3 and Fig. 2 show\n\nthat the large majority of articles are non-empirical (i.e., conceptual paper, reviews,\n\nand case studies). A reason for this is that scientific investigation of discrimination\n\nby algorithmic decision-making represents a relatively new topic. However, the\n\nnumber of quantitative papers increased from 2018. Most of the studies focused on\n\nbias, discrimination, and objective fairness, while 12 studies examined perceived\n\nfairness perceptions of applicants and employees (see Table 1). Furthermore, the\n\nmajority of studies are located in the area of recruitment and selection, whereby\n\nthese studies mostly focus on selection. Twelve studies are located in the area of HR\n\ndevelopment. The majority of studies provided either no geographical specification\n\nor were conducted in the USA (see Table 3).\n\nThirteen articles originate from management, and fourteen articles originate\n\nfrom computer science, four articles originate from law, two from psychology, two\n\nfrom information systems, and one from the behavioral sciences. This distribution\n\nillustrates that the field does not have a core in business and management research\n\nand is rather interdisciplinary. Nevertheless, the majority of articles originating from\n\nmanagement were published in high-ranked journals, such as Journal of Business\nEthics, Human Resource Management Review, Management Science, Academy of\nManagement Annals, and Journal of Management. The majority of these studies\n\n808 Business Research (2020) 13:795–848\n\n123\n\n\n\nT\na\n\nb\nle\n\n3\nO\nv\ner\nv\nie\nw\n\no\nf\nst\nu\nd\nie\ns\n\nA\nu\nth\no\nr(\ns)\n,\ny\nea\nr\n\nM\nai\nn\nfo\ncu\ns\n\nB\n/D\n/F\n/P\nF\n\nM\net\nh\no\nd\n\nF\nie\nld\n\no\nf\n\nre\nse\nar\nch\n\nS\ny\nst\nem\n\nR\nec\nru\nit\nm\nen\nt,\n\nse\nle\nct\nio\nn\n,\n\nd\nev\nel\no\np\nm\nen\nt,\n\ntr\nai\nn\nin\ng\n\nK\ney\n\nfi\nn\nd\nin\ng\ns\n\nG\neo\ng\nra\np\nh\ny\n\nN\nai\nm\n\net\nal\n.\n(2\n0\n1\n6\n)\n\nT\nh\ne\nau\nto\nm\nat\ned\n\nan\nal\ny\nsi\ns\no\nf\nfa\nci\nal\n\nex\np\nre\nss\nio\nn\ns,\n\nla\nn\ng\nu\nag\ne,\n\nan\nd\n\np\nro\nso\nd\nic\n\nin\nfo\nrm\n\nat\nio\nn\no\nf\n\nin\nte\nrv\nie\nw\nee\ns\nin\n\na\n\njo\nb\nin\nte\nrv\nie\nw\n\nB\nE\nm\np\nir\nic\nal\n-\n\nq\nu\nan\nti\nta\nti\nv\ne;\n\nan\nal\ny\nsi\ns\no\nf\n\nin\nte\nrv\nie\nw\ns\n\nC\no\nm\np\nu\nte\nr\n\nsc\nie\nn\nce\n\nN\nL\nP\n,\nF\nE\nP\n\nS\nel\nec\nti\no\nn\n\nR\nec\no\nm\nm\nen\nd\ns\nto\n\nsp\nea\nk\n\nm\no\nre\n\nfl\nu\nen\ntl\ny\n,\nu\nse\n\nle\nss\n\nfi\nll\ner\n\nw\no\nrd\ns,\nan\nd\nsm\n\nil\ne\n\nm\no\nre\n\nS\nh\no\nw\ns\nth\nat\n\nth\ne\nst\nu\nd\nen\nts\n\nw\nh\no\nw\ner\ne\nra\nte\nd\nh\nig\nh\nly\n\nw\nh\nil\ne\nan\nsw\n\ner\nin\ng\nth\ne\n\nfi\nrs\nt\nin\nte\nrv\nie\nw\n\nq\nu\nes\nti\no\nn\n\nw\ner\ne\nal\nso\n\nra\nte\nd\nh\nig\nh\nly\n\no\nv\ner\nal\nl\n(i\n.e\n.,\nfi\nrs\nt\n\nim\np\nre\nss\nio\nn\nm\nat\nte\nrs\n)\n\nU\nS\nA\n\nC\nh\nen\ng\nan\nd\n\nH\nac\nk\net\nt\n(2\n0\n1\n9\n)\n\nA\ncr\nit\nic\nal\n\nre\nv\nie\nw\n\no\nf\n\nal\ng\no\nri\nth\nm\ns\nin\n\nH\nR\nM\n\nB\nE\nm\np\nir\nic\nal\n-\n\nq\nu\nal\nit\nat\niv\ne;\n\nsi\nn\ng\nle\n\nca\nse\n\nst\nu\nd\ny\n;\nre\nv\nie\nw\n\nM\nan\nag\nem\n\nen\nt\n\nG\nen\ner\nal\n\nR\nec\nru\nit\nm\nen\nt\n\nan\nd\n\nse\nle\nct\nio\nn\n\nO\nrg\nan\niz\nat\nio\nn\ns\nh\nav\ne\nto\n\nin\ncr\nea\nse\n\nth\ne\np\ner\nce\niv\ned\n\nau\nth\nen\nti\nci\nty\n\no\nf\n\nal\ng\no\nri\nth\nm\ns\n\nN\nee\nd\nto\n\nev\nal\nu\nat\ne\n\nal\ng\no\nri\nth\nm\ns\nfr\no\nm\n\na\n\nre\nse\nar\nch\n\np\ner\nsp\nec\nti\nv\ne\n\nL\nac\nk\nb\net\nw\nee\nn\np\nra\nct\nic\ne\n\nan\nd\nre\nse\nar\nch\n\nN\no\nt sp\nec\nifi\ned\n\nBusiness Research (2020) 13:795–848 809\n\n123\n\n\n\nT\na\n\nb\nle\n\n3\nco\nn\nti\nn\nu\ned\n\nA\nu\nth\no\nr(\ns)\n,\ny\nea\nr\n\nM\nai\nn\nfo\ncu\ns\n\nB\n/D\n/F\n/P\nF\n\nM\net\nh\no\nd\n\nF\nie\nld\n\no\nf\n\nre\nse\nar\nch\n\nS\ny\nst\nem\n\nR\nec\nru\nit\nm\nen\nt,\n\nse\nle\nct\nio\nn\n,\n\nd\nev\nel\no\np\nm\nen\nt,\n\ntr\nai\nn\nin\ng\n\nK\ney\n\nfi\nn\nd\nin\ng\ns\n\nG\neo\ng\nra\np\nh\ny\n\nM\nan\nn\nan\nd\nO\n’N\n\nei\nl\n\n(2\n0\n1\n6\n)\n\nE\nx\np\nla\nin\ns\nw\nh\ny\n\nal\ng\no\nri\nth\nm\ns\nar\ne\n\nn\no\nt\nn\neu\ntr\nal\n\nan\nd\n\no\nff\ner\ns\nso\nm\ne\n\nim\np\nli\nca\nti\no\nn\ns\nto\n\nre\nd\nu\nce\n\nth\ne\nri\nsk\n\no\nf\n\nb\nia\nse\ns\no\nf\n\nal\ng\no\nri\nth\nm\nic\n\nd\nec\nis\nio\nn\n-m\n\nak\nin\ng\n\nin\nth\ne\nh\nir\nin\ng\n\np\nro\nce\nss\n\nB\n,\nD\n\nN\no\nn\n-e\nm\np\nir\nic\nal\n;\n\nco\nn\nce\np\ntu\nal\n\np\nap\ner\n\nM\nan\nag\nem\n\nen\nt\n\nG\nen\ner\nal\n,\nh\nir\nin\ng\n\nal\ng\no\nri\nth\nm\ns\n\nS\nel\nec\nti\no\nn\n\nA\nlg\no\nri\nth\nm\ns\nre\nfl\nec\nt\n\nh\nu\nm\nan\n\nb\nia\nse\ns\nan\nd\n\np\nre\nju\nd\nic\nes\n\nth\nat\n\nle\nad\n\nto\n\nm\nac\nh\nin\ne\nle\nar\nn\nin\ng\n\nm\nis\nta\nk\nes\n\nan\nd\n\nm\nis\nin\nte\nrp\nre\nta\nti\no\nn\ns\n\nB\nia\ns\nan\nd\np\nre\nju\nd\nic\ne\n\nca\nn\nn\no\nt\nb\ne\nco\nm\np\nle\nte\nly\n\nel\nim\n\nin\nat\ned\n\nfr\no\nm\n\nh\nir\nin\ng\n\nH\nR\np\nro\nfe\nss\nio\nn\nal\ns\nm\nu\nst\n\nco\nn\nsi\nd\ner\n\nth\ne\n\nco\nn\nse\nq\nu\nen\nce\ns\no\nf\nth\nes\ne\n\nsy\nst\nem\n\ns\nan\nd\nen\nsu\nre\n\nth\ney\n\nal\nw\nay\ns\nre\nfl\nec\nt\nth\ne\n\nb\nes\nt\nh\nu\nm\nan\n\nin\nte\nn\nti\no\nn\ns\n\nU\nS\nA\n\nK\nim\n\n(2\n0\n1\n7\n)\n\nE\nx\nam\n\nin\nes\n\nth\ne\nu\nse\n\no\nf\n\ncl\nas\nsi\nfi\nca\nti\no\nn\n\nsc\nh\nem\n\nes\n/d\nat\na\n\nal\ng\no\nri\nth\nm\ns\nin\n\nte\nrm\n\ns\no\nf\n\np\ner\nso\nn\nn\nel\n\nd\nec\nis\nio\nn\ns\n\nS\nh\no\nw\ns\nli\nm\nit\nat\nio\nn\ns\nin\n\nex\nis\nti\nn\ng\nla\nw\n\nan\nd\n\nim\np\nro\nv\nem\n\nen\nt\n\np\nro\np\no\nsa\nls\n\nB\n,\nD\n\nN\no\nn\n-e\nm\np\nir\nic\nal\n;\n\nco\nn\nce\np\ntu\nal\n\np\nap\ner\n\nL\naw\n\nG\nen\ner\nal\n,\n\ncl\nas\nsi\nfi\nca\nti\no\nn\n\nR\nec\nru\nit\nm\nen\nt\n\nan\nd\n\nse\nle\nct\nio\nn\n,\n\ntr\nai\nn\nin\ng\nan\nd\n\nd\nev\nel\no\np\nm\nen\nt\n\nB\nec\nau\nse\n\no\nf\nth\ne\nn\nat\nu\nre\n\no\nf\n\nd\nat\na\nm\nin\nin\ng\n\nte\nch\nn\niq\nu\nes\n,\nem\n\np\nlo\ny\ner\n\nre\nli\nan\nce\n\no\nn\nth\nes\ne\nto\no\nls\n\np\no\nse\ns\nn\no\nv\nel\n\nch\nal\nle\nn\ng\nes\n\nto\n\nw\no\nrk\np\nla\nce\n\neq\nu\nal\nit\ny\n\nU\nS\nA\n\n810 Business Research (2020) 13:795–848\n\n123\n\n\n\nT\na\n\nb\nle\n\n3\nco\nn\nti\nn\nu\ned\n\nA\nu\nth\no\nr(\ns)\n,\ny\nea\nr\n\nM\nai\nn\nfo\ncu\ns\n\nB\n/D\n/F\n/P\nF\n\nM\net\nh\no\nd\n\nF\nie\nld\n\no\nf\n\nre\nse\nar\nch\n\nS\ny\nst\nem\n\nR\nec\nru\nit\nm\nen\nt,\n\nse\nle\nct\nio\nn\n,\n\nd\nev\nel\no\np\nm\nen\nt,\n\ntr\nai\nn\nin\ng\n\nK\ney\n\nfi\nn\nd\nin\ng\ns\n\nG\neo\ng\nra\np\nh\ny\n\nR\no\nse\nn\nb\nla\nt\net\n\nal\n.\n\n(2\n0\n1\n6\n)\n\nE\nx\nam\n\nin\nes\n\nd\nis\ncr\nim\n\nin\nat\nio\nn\n\nth\no\nro\nu\ng\nh\n\nev\nal\nu\nat\nio\nn\nin\n\nth\ne\n\nca\nse\n\no\nf\nU\nb\ner\n\nd\nri\nv\ner\ns\n\nB\n,\nD\n\nE\nm\np\nir\nic\nal\n-\n\nq\nu\nal\nit\nat\niv\ne;\n\nca\nse\n\nst\nu\nd\ny\n\nC\no\nm\np\nu\nte\nr\n\nsc\nie\nn\nce\n\nE\nv\nal\nu\nat\nio\nn\n\nsy\nst\nem\n\ns\n\nD\nev\nel\no\np\nm\nen\nt\n\nT\nh\ne\nn\nee\nd\nto\n\nex\ner\nci\nse\n\nq\nu\nal\nit\ny\nco\nn\ntr\no\nl\no\nv\ner\n\na\n\nla\nrg\ne\nd\nis\nag\ng\nre\ng\nat\ned\n\nw\no\nrk\nfo\nrc\ne\nm\nay\n\np\ner\nm\nit\n\nth\ne\nco\nn\nti\nn\nu\ned\n\nu\nse\n\no\nf\n\nra\nti\nn\ng\n\nS\ny\nst\nem\n\ns\nu\nn\nd\ner\n\nex\nis\nti\nn\ng\n\nem\np\nlo\ny\nm\nen\nt\n\nd\nis\ncr\nim\n\nin\nat\nio\nn\nla\nw\n\nN\no\nt sp\nec\nifi\ned\n\nS\nav\nag\ne\nan\nd\nB\nal\nes\n\n(2\n0\n1\n7\n)\n\nE\nx\nam\n\nin\nes\n\nh\no\nw\n\nv\nid\neo\n\ng\nam\n\ne\n\nal\ng\no\nri\nth\nm\ns\nar\ne\n\nin\nco\nrp\no\nra\nte\nd\nin\nto\n\nth\ne\njo\nb\nh\nir\nin\ng\n\np\nro\nce\nss\n\nS\nh\no\nw\ns\nth\ne\nd\neb\nat\ne\n\no\nv\ner\n\nw\nh\net\nh\ner\n\nth\nes\ne\nal\ng\no\nri\nth\nm\ns\n\nd\nis\ncr\nim\n\nin\nat\ne\n\nB\n,\nD\n\nN\no\nn\n-e\nm\np\nir\nic\nal\n;\n\nco\nn\nce\np\ntu\nal\n\np\nap\ner\n\nL\naw\n\nG\nam\n\nifi\nca\nti\no\nn\n\nS\nel\nec\nti\no\nn\n,\n\nd\nev\nel\no\np\nm\nen\nt\n\nV\nid\neo\n\ng\nam\n\nes\nin\n\nin\nit\nia\nl\n\nh\nir\nin\ng\nst\nag\nes\n\nca\nn\n\np\ner\nm\nit\nn\no\nn\n-\n\nd\nis\ncr\nim\n\nin\nat\no\nry\n\nev\nal\nu\nat\nio\nn\no\nf\nal\nl\nth\ne\n\nca\nn\nd\nid\nat\nes\n\nU\nS\nA\n\nBusiness Research (2020) 13:795–848 811\n\n123\n\n\n\nT\na\n\nb\nle\n\n3\nco\nn\nti\nn\nu\ned\n\nA\nu\nth\no\nr(\ns)\n,\ny\nea\nr\n\nM\nai\nn\nfo\ncu\ns\n\nB\n/D\n/F\n/P\nF\n\nM\net\nh\no\nd\n\nF\nie\nld\n\no\nf\n\nre\nse\nar\nch\n\nS\ny\nst\nem\n\nR\nec\nru\nit\nm\nen\nt,\n\nse\nle\nct\nio\nn\n,\n\nd\nev\nel\no\np\nm\nen\nt,\n\ntr\nai\nn\nin\ng\n\nK\ney\n\nfi\nn\nd\nin\ng\ns\n\nG\neo\ng\nra\np\nh\ny\n\nW\nil\nli\nam\n\ns\net\n\nal\n.\n\n(2\n0\n1\n8\n)\n\nE\nx\nam\n\nin\nes\n\nd\nis\ncr\nim\n\nin\nat\nio\nn\n\nth\nro\nu\ng\nh\nth\ne\nu\nse\n\no\nf\n\nal\ng\no\nri\nth\nm\ns\nin\n\nd\nec\nis\nio\nn\n-m\n\nak\nin\ng\n\np\nro\nce\nss\nes\n\nP\nro\np\no\nse\ns\nst\nra\nte\ng\nie\ns\n\nfo\nr\nth\ne\np\nre\nv\nen\nti\no\nn\n\no\nf\nd\nis\ncr\nim\n\nin\nat\nio\nn\n\nB\n,\nD\n\nE\nm\np\nir\nic\nal\n-\n\nq\nu\nal\nit\nat\niv\ne;\n\nm\nu\nlt\nip\nle\n\nca\nse\n\nst\nu\nd\nie\ns\n\nIn\nfo\nrm\n\nat\nio\nn\n\nG\nen\ner\nal\n\nR\nec\nru\nit\nm\nen\nt\n\nan\nd\n\nse\nle\nct\nio\nn\n\nA\nlg\no\nri\nth\nm\nic\n\np\nre\nd\nic\nti\no\nn\n\nca\nn\nin\ncl\nu\nd\ne\nin\nju\nst\nic\nes\n\nT\nh\ne\np\nre\nd\nic\nti\no\nn\ns\nh\nav\ne\nto\n\nb\ne\nch\nec\nk\ned\n\nfo\nr\nb\nia\ns\n\nan\nd\nsh\no\nu\nld\n\nb\ne\n\nco\nrr\nec\nte\nd\nto\n\nav\no\nid\n\nd\nis\ncr\nim\n\nin\nat\nio\nn\n\nU\nS\nA\n\nL\nam\n\nb\nre\nch\nt\nan\nd\n\nT\nu\nck\ner\n\n(2\n0\n1\n9\n)\n\nE\nx\nam\n\nin\nes\n\ng\nen\nd\ner\n\nb\nia\ns\nin\n\nd\nel\niv\ner\ny\no\nf\n\njo\nb\nad\ns\n\nC\no\nn\nd\nu\nct\ns\nfi\nel\nd\nte\nst\n\no\nf\nh\no\nw\n\nan\n\nal\ng\no\nri\nth\nm\n\nd\nel\niv\ner\ned\n\nad\ns\n\np\nro\nm\no\nti\nn\ng\njo\nb\n\no\np\np\no\nrt\nu\nn\nit\nie\ns\nin\n\nth\ne\nsc\nie\nn\nce\n,\n\nte\nch\nn\no\nlo\ng\ny\n,\n\nen\ng\nin\nee\nri\nn\ng\nan\nd\n\nm\nat\nh\nfi\nel\nd\ns\n\nB\n,\nD\n\nE\nm\np\nir\nic\nal\n-\n\nq\nu\nan\nti\nta\nti\nv\ne;\n\nfi\nel\nd\nte\nst\n\nM\nan\nag\nem\n\nen\nt\n\nR\nec\no\nm\nm\nen\nd\ner\n\nsy\nst\nem\n\ns\n\nR\nec\nru\nit\nm\nen\nt\n\nF\new\n\ner\nw\no\nm\nen\n\nsa\nw\n\nS\nT\nE\nM\n\nad\ns\nth\nan\n\nm\nen\n\nA\nn\nal\ng\no\nri\nth\nm\n\nth\nat\n\nsi\nm\np\nly\n\no\np\nti\nm\niz\nes\n\nco\nst\n-\n\nef\nfe\nct\niv\nen\nes\ns\nin\n\nad\n\nd\nel\niv\ner\ny\nw\nil\nl\nd\nel\niv\ner\n\nad\ns\nth\nat\n\nw\ner\ne\nin\nte\nn\nd\ned\n\nto\nb\ne\ng\nen\nd\ner\n\nn\neu\ntr\nal\n\nin\n\nan\nap\np\nar\nen\ntl\ny\n\nd\nis\ncr\nim\n\nin\nat\no\nry\n\nw\nay\n\n1\n9\n1 co\nu\nn\ntr\nie\ns\n\n812 Business Research (2020) 13:795–848\n\n123\n\n\n\nT\na\n\nb\nle\n\n3\nco\nn\nti\nn\nu\ned\n\nA\nu\nth\no\nr(\ns)\n,\ny\nea\nr\n\nM\nai\nn\nfo\ncu\ns\n\nB\n/D\n/F\n/P\nF\n\nM\net\nh\no\nd\n\nF\nie\nld\n\no\nf\n\nre\nse\nar\nch\n\nS\ny\nst\nem\n\nR\nec\nru\nit\nm\nen\nt,\n\nse\nle\nct\nio\nn\n,\n\nd\nev\nel\no\np\nm\nen\nt,\n\ntr\nai\nn\nin\ng\n\nK\ney\n\nfi\nn\nd\nin\ng\ns\n\nG\neo\ng\nra\np\nh\ny\n\nS\naj\nja\nd\nia\nn\ni\net\n\nal\n.\n\n(2\n0\n1\n9\n)\n\nP\nre\nd\nic\nti\no\nn\no\nf\nfu\ntu\nre\n\nw\no\nrk\n\no\nu\ntc\no\nm\nes\n\nsu\nch\n\nas\nv\no\nlu\nn\nta\nry\n\ntu\nrn\no\nv\ner\n,\n\nin\nv\no\nlu\nn\nta\nry\n\ntu\nrn\no\nv\ner\n,\nan\nd\n\nv\nal\nu\ne-\nad\nd\ned\n\nb\nas\ned\n\no\nn\nw\no\nrk\n\nh\nis\nto\nry\n\ncr\nit\ner\nia\n\n(w\no\nrk\n\nex\np\ner\nie\nn\nce\n\nre\nle\nv\nan\nce\n,\nte\nn\nu\nre\n\nh\nis\nto\nry\n,\n\nat\ntr\nib\nu\nti\no\nn\ns\nfo\nr\n\np\nre\nv\nio\nu\ns\n\ntu\nrn\no\nv\ner\n)\n\nB\n,\nF\n\nE\nm\np\nir\nic\nal\n-\n\nq\nu\nan\nti\nta\nti\nv\ne,\n\nst\nat\nis\nti\nca\nl\n\nte\nst\ns;\n\nm\nac\nh\nin\ne\n\nle\nar\nn\nin\ng\n\nP\nsy\nch\no\nlo\ng\ny\n\nG\nen\ner\nal\n\nS\nel\nec\nti\no\nn\n\nA\nlg\no\nri\nth\nm\nic\nm\net\nh\no\nd\ns\nar\ne\n\no\nft\nen\n\nca\nli\nb\nra\nte\nd\n\nex\ncl\nu\nsi\nv\nel\ny\nto\n\na\n\nsp\nec\nifi\nc\nap\np\nli\nca\nti\no\nn\n\np\no\no\nl\n\nP\nai\nri\nn\ng\nes\nta\nb\nli\nsh\ned\n\nth\neo\nry\n\nle\nad\ns\nto\n\nb\net\nte\nr\n\nre\nsu\nlt\ns\nth\nan\n\nu\nn\niq\nu\ne\n\nw\no\nrd\n\nap\np\nli\nca\nti\no\nn\ns\n\nU\nS\nA\n\nY\nar\ng\ner\n\net\nal\n.\n\n(2\n0\n1\n9\n)\n\nC\nri\nti\nca\nl\nan\nal\ny\nsi\ns\no\nf\n\nta\nle\nn\nt\nac\nq\nu\nis\nit\nio\nn\n\nso\nft\nw\nar\ne\nan\nd\nit\ns\n\np\no\nte\nn\nti\nal\n\nfo\nr\n\nfo\nst\ner\nin\ng\neq\nu\nit\ny\n\nin\nth\ne\nh\nir\nin\ng\n\np\nro\nce\nss\n\nfo\nr\n\nu\nn\nd\ner\nre\np\nre\nse\nn\nte\nd\n\nIT\np\nro\nfe\nss\nio\nn\nal\ns\n\nB\n,\nF\n\nN\no\nn\n-e\nm\np\nir\nic\nal\n;\n\nco\nn\nce\np\ntu\nal\n\np\nap\ner\n\nIn\nfo\nrm\n\nat\nio\nn\n\nG\nen\ner\nal\n\nR\nec\nru\nit\nm\nen\nt\n\nan\nd\n\nse\nle\nct\nio\nn\n\nH\nu\nm\nan\n\nex\np\ner\nti\nse\n\nis\nst\nil\nl\n\nn\nec\nes\nsa\nry\n\nE\nv\nen\n\nw\nel\nl-\nin\nte\nn\nti\no\nn\ned\n\nal\ng\no\nri\nth\nm\ns\nar\ne\nn\no\nt\n\nn\neu\ntr\nal\n\nan\nd\nsh\no\nu\nld\n\nb\ne\n\nau\nd\nit\ned\n\nfo\nr\nm\no\nra\nll\ny\n\nan\nd\nle\ng\nal\nly\n\nu\nn\nac\nce\np\nta\nb\nle\n\nd\nec\nis\nio\nn\ns\n\nU\nS\nA\n\nBusiness Research (2020) 13:795–848 813\n\n123\n\n\n\nT\na\n\nb\nle\n\n3\nco\nn\nti\nn\nu\ned\n\nA\nu\nth\no\nr(\ns)\n,\ny\nea\nr\n\nM\nai\nn\nfo\ncu\ns\n\nB\n/D\n/F\n/P\nF\n\nM\net\nh\no\nd\n\nF\nie\nld\n\no\nf\n\nre\nse\nar\nch\n\nS\ny\nst\nem\n\nR\nec\nru\nit\nm\nen\nt,\n\nse\nle\nct\nio\nn\n,\n\nd\nev\nel\no\np\nm\nen\nt,\n\ntr\nai\nn\nin\ng\n\nK\ney\n\nfi\nn\nd\nin\ng\ns\n\nG\neo\ng\nra\np\nh\ny\n\nR\nag\nh\nav\nan\n\net\nal\n.\n\n(2\n0\n2\n0\n)\n\nD\no\ncu\nm\nen\nts\nan\nd\n\nan\nal\ny\nze\ns\nth\ne\n\ncl\nai\nm\ns\nan\nd\n\np\nra\nct\nic\nes\n\no\nf\n\nco\nm\np\nan\nie\ns\n\no\nff\ner\nin\ng\n\nal\ng\no\nri\nth\nm\ns\nfo\nr\n\nem\np\nlo\ny\nm\nen\nt\n\nas\nse\nss\nm\nen\nt\n\nB\n,\nF\n\nE\nm\np\nir\nic\nal\n-\n\nq\nu\nal\nit\nat\niv\ne;\n\nca\nse\n\nst\nu\nd\ny\n\nC\no\nm\np\nu\nte\nr\n\nsc\nie\nn\nce\n\nE\nm\np\nlo\ny\nm\nen\nt\n\nas\nse\nss\nm\nen\nt\n\nS\nel\nec\nti\no\nn\n\nT\nar\ng\net\n\nv\nar\nia\nb\nle\ns\nan\nd\n\ntr\nai\nn\nin\ng\nd\nat\na:\n\nm\no\nst\no\nf\n\nth\ne\nv\nen\nd\no\nrs\n\no\nff\ner\n\ncu\nst\no\nm\niz\nab\nle\n\nas\nse\nss\nm\nen\nt\n\nV\nal\nid\nat\nio\nn\n:\nv\nen\nd\no\nr’\ns\n\nw\neb\nsi\nte\ns\no\nft\nen\n\nd\no\nn\no\nt\n\ncl\nar\nif\ny\nw\nh\net\nh\ner\n\nth\ney\n\nv\nal\nid\nat\ne\nth\nei\nr\nm\no\nd\nel\ns\n\nS\nev\ner\nal\n\nco\nu\nn\ntr\nie\ns\n\nS\nán\nch\nez\n-\n\nM\no\nn\ned\ner\no\net\n\nal\n.\n\n(2\n0\n2\n0\n)\n\nE\nx\nam\n\nin\nes\n\nh\no\nw\nth\nre\ne\n\nau\nto\nm\nat\ned\n\nh\nir\nin\ng\n\nsy\nst\nem\n\ns\nca\nn\nb\ne\n\nu\nn\nd\ner\nst\nan\nd\nan\nd\n\nat\nte\nm\np\nt\nto\n\nm\nit\nig\nat\ne\nb\nia\ns\nan\nd\n\nd\nis\ncr\nim\n\nin\nat\nio\nn\nin\n\nth\ne\nU\nK\n\nB\n,\nF\n\nE\nm\np\nir\nic\nal\n-\n\nq\nu\nal\nit\nat\niv\ne;\n\nca\nse\n\nst\nu\nd\ny\n\nC\no\nm\np\nu\nte\nr\n\nsc\nie\nn\nce\n\nE\nm\np\nlo\ny\nm\nen\nt\n\nas\nse\nss\nm\nen\nt\n\nS\nel\nec\nti\no\nn\n\nO\nft\nen\n\nla\nck\n\no\nf\n\nin\nfo\nrm\n\nat\nio\nn\no\nn\nh\no\nw\n\nth\ne\nsy\nst\nem\n\nw\no\nrk\ned\n\nC\nla\nim\n\ns\nan\nd\nv\nal\nid\nat\nio\nn\n\nar\ne\no\nft\nen\n\nv\nag\nu\ne\n\nU\nK\n\n814 Business Research (2020) 13:795–848\n\n123\n\n\n\nT\na\n\nb\nle\n\n3\nco\nn\nti\nn\nu\ned\n\nA\nu\nth\no\nr(\ns)\n,\ny\nea\nr\n\nM\nai\nn\nfo\ncu\ns\n\nB\n/D\n/F\n/P\nF\n\nM\net\nh\no\nd\n\nF\nie\nld\n\no\nf\n\nre\nse\nar\nch\n\nS\ny\nst\nem\n\nR\nec\nru\nit\nm\nen\nt,\n\nse\nle\nct\nio\nn\n,\n\nd\nev\nel\no\np\nm\nen\nt,\n\ntr\nai\nn\nin\ng\n\nK\ney\n\nfi\nn\nd\nin\ng\ns\n\nG\neo\ng\nra\np\nh\ny\n\nS\nto\nn\ne\net\nal\n.\n(2\n0\n1\n5\n)\n\nR\nev\nie\nw\ns\nse\nv\ner\nal\n\no\nf\n\nth\ne\np\nri\nm\nar\ny\n\nfo\nrc\nes\n\nth\nat\n\nar\ne\n\np\nre\nse\nn\nti\nn\ng\n\nch\nal\nle\nn\ng\nes\n\nfo\nr\n\nH\nR\nre\nse\nar\nch\n\nan\nd\n\np\nra\nct\nic\ne\n\nT\nri\nes\n\nto\nan\nsw\n\ner\nth\ne\n\nq\nu\nes\nti\no\nn\nw\nh\net\nh\ner\n\neH\nR\nM\n\nin\nfl\nu\nen\nce\ns\n\no\nrg\nan\niz\nat\nio\nn\nal\n\nef\nfe\nct\niv\nen\nes\ns\nan\nd\n\nw\nh\net\nh\ner\n\nit\nen\nab\nle\ns\n\no\nrg\nan\niz\nat\nio\nn\ns\nto\n\nac\nh\nie\nv\ne\nth\nei\nr\nH\nR\n\ng\no\nal\ns\n\nB\n,\nP\nF\n\nN\no\nn\n-e\nm\np\nir\nic\nal\n;\n\nco\nn\nce\np\ntu\nal\n\np\nap\ner\n\nM\nan\nag\nem\n\nen\nt\n\nS\nev\ner\nal\n\nel\nec\ntr\no\nn\nic\n\nH\nR\nM\n\nto\no\nls\n\nR\nec\nru\nit\nm\nen\nt\n\nan\nd\n\nse\nle\nct\nio\nn\n,\n\nd\nev\nel\no\np\nm\nen\nt\n\nT\nh\ner\ne\nar\ne\nst\nil\nl\na\nn\nu\nm\nb\ner\n\no\nf\nq\nu\nes\nti\no\nn\ns\nab\no\nu\nt\n\nw\nh\net\nh\ner\n\nth\nes\ne\nn\new\n\nsy\nst\nem\n\ns\nen\nab\nle\n\no\nrg\nan\niz\nat\nio\nn\ns\nto\n\nac\nh\nie\nv\ne\nth\nei\nr\np\nri\nm\nar\ny\n\nH\nR\ng\no\nal\ns\n\nU\nS\nA\n\nW\no\no\nd\nru\nff\net\n\nal\n.\n\n(2\n0\n1\n8\n)\n\nE\nx\np\nlo\nre\ns\nh\no\nw\n\nm\nem\n\nb\ner\ns\no\nf\n\np\no\nte\nn\nti\nal\nly\n\naf\nfe\nct\ned\n\nco\nm\nm\nu\nn\nit\nie\ns\nin\n\nth\ne\nU\nS\nA\n\nfe\nel\n\nab\no\nu\nt\nal\ng\no\nri\nth\nm\nic\n\nfa\nir\nn\nes\ns\n\nB\n,\nP\nF\n\nE\nm\np\nir\nic\nal\n-\n\nq\nu\nal\nit\nat\niv\ne;\n\nw\no\nrk\nsh\no\np\n;\n\nin\nte\nrv\nie\nw\ns\n\nC\no\nm\np\nu\nte\nr\n\nsc\nie\nn\nce\n\nG\nen\ner\nal\n\nR\nec\nru\nit\nm\nen\nt\n\nan\nd\n\nse\nle\nct\nio\nn\n\nC\no\nn\nce\np\nt\no\nf\nal\ng\no\nri\nth\nm\nic\n\nfa\nir\nn\nes\ns\nis\n\nla\nrg\nel\ny\n\nu\nn\nfa\nm\nil\nia\nr\n\nL\nea\nrn\nin\ng\nab\no\nu\nt\n\nal\ng\no\nri\nth\nm\nic\n\n(u\nn\n)f\nai\nrn\nes\ns\nel\nic\nit\ned\n\nn\neg\nat\niv\ne\nfe\nel\nin\ng\ns\n\nC\no\nm\np\nan\ny\nh\nan\nd\nli\nn\ng\no\nf\n\nal\ng\no\nri\nth\nm\nic\n\nfa\nir\nn\nes\ns\n\nin\nte\nra\nct\ns\nsi\ng\nn\nifi\nca\nn\ntl\ny\n\nw\nit\nh\nu\nse\nr\ntr\nu\nst\n\nU\nS\nA\n\nBusiness Research (2020) 13:795–848 815\n\n123\n\n\n\nT\na\n\nb\nle\n\n3\nco\nn\nti\nn\nu\ned\n\nA\nu\nth\no\nr(\ns)\n,\ny\nea\nr\n\nM\nai\nn\nfo\ncu\ns\n\nB\n/D\n/F\n/P\nF\n\nM\net\nh\no\nd\n\nF\nie\nld\n\no\nf\n\nre\nse\nar\nch\n\nS\ny\nst\nem\n\nR\nec\nru\nit\nm\nen\nt,\n\nse\nle\nct\nio\nn\n,\n\nd\nev\nel\no\np\nm\nen\nt,\n\ntr\nai\nn\nin\ng\n\nK\ney\n\nfi\nn\nd\nin\ng\ns\n\nG\neo\ng\nra\np\nh\ny\n\nL\nei\nch\nt-\nD\neo\nb\nal\nd\n\net\nal\n.\n(2\n0\n1\n9\n)\n\nId\nen\nti\nfi\nes\n\nch\nal\nle\nn\ng\nes\n\nar\nis\nin\ng\nfr\no\nm\n\nal\ng\no\nri\nth\nm\n-b\nas\ned\n\nH\nR\nd\nec\nis\nio\nn\n-\n\nm\nak\nin\ng\n\nA\nn\nal\ny\nze\ns\nh\no\nw\n\nal\ng\no\nri\nth\nm\n-b\nas\ned\n\nH\nR\n\nD\nec\nis\nio\nn\n-m\n\nak\nin\ng\n\nm\nay\n\nin\nfl\nu\nen\nce\n\nem\np\nlo\ny\nee\ns’\n\np\ner\nso\nn\nal\n\nin\nte\ng\nri\nty\n,\n\nan\nd\nac\nti\no\nn\ns\n\nB\n,\nP\nF\n\nN\no\nn\n-e\nm\np\nir\nic\nal\n;\n\nco\nn\nce\np\ntu\nal\n\np\nap\ner\n\nM\nan\nag\nem\n\nen\nt\n\nG\nen\ner\nal\n\nD\nev\nel\no\np\nm\nen\nt\n\nA\nlg\no\nri\nth\nm\n-b\nas\ned\n\nd\nec\nis\nio\nn\n-m\n\nak\nin\ng\nca\nn\n\nh\nel\np\nm\no\nn\nit\no\nr\n\nem\np\nlo\ny\nee\ns\nm\no\nre\n\nef\nfe\nct\niv\nel\ny\nb\nu\nt\nca\nn\nb\ne\n\net\nh\nic\nal\nly\n\np\nro\nb\nle\nm\nat\nic\n\nS\nu\ng\ng\nes\nts\n\nfo\nu\nr\n\nm\nec\nh\nan\nis\nm\ns\nto\n\nre\nd\nu\nce\n\nn\neg\nat\niv\ne\nco\nn\nse\nq\nu\nen\nce\ns\n\nN\no\nt sp\nec\nifi\ned\n\nT\nam\n\nb\ne\net\n\nal\n.\n\n(2\n0\n1\n9\n)\n\nId\nen\nti\nfi\nes\n\nch\nal\nle\nn\ng\nes\n\nin\nu\nsi\nn\ng\nd\nat\na\n\nsc\nie\nn\nce\n\nte\nch\nn\niq\nu\nes\n\nfo\nr\n\nH\nR\nta\nsk\ns\n\nP\nro\np\no\nse\ns\np\nra\nct\nic\nal\n\nre\nsp\no\nn\nse\ns\nto\n\nth\nes\ne\n\nch\nal\nle\nn\ng\nes\n\nb\nas\ned\n\no\nn\nth\ne\np\nri\nn\nci\np\nle\ns\n\nca\nu\nsa\nl\nre\nas\no\nn\nin\ng\n,\n\nra\nn\nd\no\nm\niz\nat\nio\nn\nan\nd\n\nex\np\ner\nim\n\nen\nts\n,\nan\nd\n\nem\np\nlo\ny\nee\n\nco\nn\ntr\nib\nu\nti\no\nn\n\nB\n,\nP\nF\n\nE\nm\np\nir\nic\nal\n-\n\nq\nu\nal\nit\nat\niv\ne;\n\nw\no\nrk\nsh\no\np\n\nan\nd\nsu\nrv\ney\n\nM\nan\nag\nem\n\nen\nt\n\nG\nen\ner\nal\n\nR\nec\nru\nit\nm\nen\nt\n\nan\nd\n\nse\nle\nct\nio\nn\n\nF\no\nu\nr\nch\nal\nle\nn\ng\nes\n\nid\nen\nti\nfi\ned\n:\nco\nm\np\nle\nx\nit\ny\n\no\nf\nH\nR\n\np\nh\nen\no\nm\nen\na,\n\nco\nn\nst\nra\nin\nts\nim\n\np\no\nse\nd\n\nb\ny\nsm\n\nal\nl\nd\nat\na\nse\nts\n,\n\nac\nco\nu\nn\nta\nb\nil\nit\ny\n\nq\nu\nes\nti\no\nn\ns\nas\nso\nci\nat\ned\n\nw\nit\nh\nfa\nir\nn\nes\ns\nan\nd\n\no\nth\ner\n\net\nh\nic\nal\n\nan\nd\nle\ng\nal\n\nco\nn\nst\nra\nin\nts\n,\nan\nd\n\np\no\nss\nib\nle\n\nad\nv\ner\nse\n\nem\np\nlo\ny\nee\n\nre\nac\nti\no\nn\ns\n\nU\nS\nA\n\n816 Business Research (2020) 13:795–848\n\n123\n\n\n\nT\na\n\nb\nle\n\n3\nco\nn\nti\nn\nu\ned\n\nA\nu\nth\no\nr(\ns)\n,\ny\nea\nr\n\nM\nai\nn\nfo\ncu\ns\n\nB\n/D\n/F\n/P\nF\n\nM\net\nh\no\nd\n\nF\nie\nld\n\no\nf\n\nre\nse\nar\nch\n\nS\ny\nst\nem\n\nR\nec\nru\nit\nm\nen\nt,\n\nse\nle\nct\nio\nn\n,\n\nd\nev\nel\no\np\nm\nen\nt,\n\ntr\nai\nn\nin\ng\n\nK\ney\n\nfi\nn\nd\nin\ng\ns\n\nG\neo\ng\nra\np\nh\ny\n\nR\no\nse\nn\nb\nla\nt\net\n\nal\n.\n\n(2\n0\n1\n4\n)\n\nF\no\ncu\nse\ns\no\nn\nth\ne\nn\new\n\nto\no\nl’\ns\nem\n\np\nlo\ny\ner\ns\n\nu\nse\n\nto\nsi\nft\nth\nro\nu\ng\nh\n\njo\nb\nap\np\nli\nca\nti\no\nn\ns\n\nA\nd\nd\nre\nss\nes\n\nis\nsu\nes\n\no\nf\n\np\nri\nv\nac\ny\n,\nfa\nir\nn\nes\ns,\n\ntr\nan\nsp\nar\nen\ncy\n,\n\nac\ncu\nra\ncy\n,\nan\nd\n\nin\neq\nu\nal\nit\ny\nu\nn\nd\ner\n\nth\ne\nru\nb\nri\nc\no\nf\n\nd\nis\ncr\nim\n\nin\nat\nio\nn\n\nB\n,\nD\n,\nF\n\nN\no\nn\n-e\nm\np\nir\nic\nal\n;\n\nli\nte\nra\ntu\nre\n\nre\nv\nie\nw\n\nC\no\nm\np\nu\nte\nr\n\nsc\nie\nn\nce\n\nG\nen\ner\nal\n\nR\nec\nru\nit\nm\nen\nt\n\nan\nd\n\nse\nle\nct\nio\nn\n\nE\nm\np\nlo\ny\ner\ns\np\no\nte\nn\nti\nal\nly\n\nh\nav\ne\nac\nce\nss\n\nto\nm\no\nre\n\nco\nm\np\nre\nh\nen\nsi\nv\ne\n\nel\nec\ntr\no\nn\nic\n\np\nro\nfi\nle\ns\no\nn\n\njo\nb\nca\nn\nd\nid\nat\nes\n\nth\nan\n\nh\nas\n\nb\nee\nn\ntr\nad\nit\nio\nn\nal\nly\n\nav\nai\nla\nb\nle\n\nto\nth\nem\n\n,\n\nw\nh\nic\nh\nca\nn\nex\np\no\nse\n\njo\nb\n\nca\nn\nd\nid\nat\nes\n\nto\na\ng\nre\nat\ner\n\nsc\nru\nti\nn\ny\no\nf\nth\nei\nr\n\np\ner\nso\nn\nal\n\nli\nv\nes\n\nN\no\nt sp\nec\nifi\ned\n\nB\nu\nrd\no\nn\nan\nd\n\nH\nar\np\nu\nr\n(2\n0\n1\n5\n)\n\nE\nx\nam\n\nin\nes\n\np\no\nte\nn\nti\nal\n\nfo\nr\n\nd\nis\ncr\nim\n\nin\nat\no\nry\n\np\nra\nct\nic\nes\n\nto\n\nd\nev\nel\no\np\nth\nro\nu\ng\nh\n\nin\nfo\nrm\n\nat\nio\nn\n\nin\nfr\nas\ntr\nu\nct\nu\nre\ns\nin\n\nw\nh\nic\nh\nu\nn\nfa\nir\nn\nes\ns\n\nan\nd\n\nd\nis\ncr\nim\n\nin\nat\nio\nn\n\nar\ne\nem\n\nb\ned\nd\ned\n\nin\nto\n\nth\ne\n\np\nre\nsc\nri\np\nti\nv\ne\n\np\nro\nce\nss\nes\n\nan\nd\n\nin\nfr\nas\ntr\nu\nct\nu\nre\ns\no\nf\n\nta\nle\nn\nt\nan\nal\ny\nti\ncs\n\nB\n,\nD\n,\nF\n\nN\no\nn\n-e\nm\np\nir\nic\nal\n;\n\nco\nn\nce\np\ntu\nal\n\np\nap\ner\n\nL\naw\n\nG\nen\ner\nal\n\nS\nel\nec\nti\no\nn\n,\n\nd\nev\nel\no\np\nm\nen\nt\n\nP\nro\nce\nss\nes\n\no\nf\np\nre\nd\nic\nti\nv\ne\n\nse\ng\nm\nen\nta\nti\no\nn\nca\nn\n\np\nro\nd\nu\nce\n\nin\neq\nu\nal\nit\nie\ns\n\nth\nro\nu\ng\nh\nth\ne\n\nse\ng\nm\nen\nta\nti\no\nn\no\nf\n\nem\np\nlo\ny\nee\n\ng\nro\nu\np\nin\ng\ns\n\nb\nas\ned\n\no\nn\nu\nn\nin\ntu\nit\niv\ne\n\nat\ntr\nib\nu\nte\ns\nth\nat\n\nar\ne\n\nev\ner\n-c\nh\nan\ng\nin\ng\n\nA\nu\nst\nra\nli\na\n\nBusiness Research (2020) 13:795–848 817\n\n123\n\n\n\nT\na\n\nb\nle\n\n3\nco\nn\nti\nn\nu\ned\n\nA\nu\nth\no\nr(\ns)\n,\ny\nea\nr\n\nM\nai\nn\nfo\ncu\ns\n\nB\n/D\n/F\n/P\nF\n\nM\net\nh\no\nd\n\nF\nie\nld\n\no\nf\n\nre\nse\nar\nch\n\nS\ny\nst\nem\n\nR\nec\nru\nit\nm\nen\nt,\n\nse\nle\nct\nio\nn\n,\n\nd\nev\nel\no\np\nm\nen\nt,\n\ntr\nai\nn\nin\ng\n\nK\ney\n\nfi\nn\nd\nin\ng\ns\n\nG\neo\ng\nra\np\nh\ny\n\nP\ner\nss\no\nn\n(2\n0\n1\n6\n)\n\nA\nn\nal\ny\nze\ns\nth\ne\n\np\nro\nb\nle\nm\ns\no\nf\n\nim\np\nli\nci\nt\nb\nia\ns\nin\n\nal\ng\no\nri\nth\nm\ns\n\nre\ng\nar\nd\nin\ng\n\nre\ncr\nu\nit\nm\nen\nt\n\np\nro\nce\nss\nes\n,\n\nd\nis\ncr\nim\n\nin\nat\nio\nn\n,\n\nan\nd\nu\nn\nfa\nir\nn\nes\ns\nb\ny\n\nu\nsi\nn\ng\nal\ng\no\nri\nth\nm\ns\n\nS\nh\no\nw\ns\np\no\nss\nib\nle\n\nso\nlu\nti\no\nn\ns\n\nB\n,\nD\n,\nF\n\nE\nm\np\nir\nic\nal\n-\n\nq\nu\nal\nit\nat\niv\ne;\n\nex\np\nlo\nra\nti\nv\ne\n\nan\nal\ny\nsi\ns\n\nC\no\nm\np\nu\nte\nr\n\nsc\nie\nn\nce\n\nD\nat\na\nm\nin\nin\ng\n,\n\np\nro\nfi\nli\nn\ng\n\nR\nec\nru\nit\nm\nen\nt\n\nan\nd\n\nse\nle\nct\nio\nn\n\nE\nm\np\nlo\ny\ner\ns\nm\nig\nh\nt\nm\nis\ns\n\nth\ne\nb\nes\nt\nca\nn\nd\nid\nat\nes\n,\nas\n\nth\ne\nem\n\np\nlo\ny\ned\n\nal\ng\no\nri\nth\nm\ns\nar\ne\ntu\nn\ned\n\nw\nit\nh\nli\nm\nit\ned\n\nan\nd\n\no\nu\ntd\nat\ned\n\nd\nat\na\n\nT\nh\ne\nri\nsk\n\no\nf\nd\nir\nec\ntl\ny\no\nr\n\nin\nd\nir\nec\ntl\ny\n\nd\nis\ncr\nim\n\nin\nat\nin\ng\n\nca\nn\nd\nid\nat\nes\n\nex\nis\nts\n\nN\no\nt sp\nec\nifi\ned\n\nV\nas\nco\nn\nce\nlo\ns\net\n\nal\n.\n\n(2\n0\n1\n7\n)\n\nP\nro\np\no\nse\ns\na\n\nst\nru\nct\nu\nre\nd\n\nap\np\nro\nac\nh\nto\n\nm\nit\nig\nat\ne\n\nd\nis\ncr\nim\n\nin\nat\nio\nn\n\nan\nd\nu\nn\nfa\nir\nn\nes\ns\n\nca\nu\nse\nd\nb\ny\nb\nia\ns\nin\n\nA\nI\nsy\nst\nem\n\ns\nin\n\nh\nir\nin\ng\nd\nec\nis\nio\nn\n\nsc\nen\nar\nio\ns\n\nB\n,\nD\n,\nF\n\nN\no\nn\n-e\nm\np\nir\nic\nal\n;\n\nco\nn\nce\np\ntu\nal\n\np\nap\ner\n\nC\no\nm\np\nu\nte\nr\n\nsc\nie\nn\nce\n\nG\nen\ner\nal\n,\nh\nir\nin\ng\n\nal\ng\no\nri\nth\nm\ns\n\nS\nel\nec\nti\no\nn\n\nP\no\nin\nts\no\nu\nt\nco\nn\nn\nec\nti\no\nn\ns\n\nb\net\nw\nee\nn\nb\nia\ns\no\nf\nA\nI\n\nan\nd\nth\ne\np\nro\nb\nle\nm\n\no\nf\n\nin\nd\nu\nct\nio\nn\n\nS\nh\no\nw\ns\nth\nat\n\nth\ner\ne\nis\n\na\n\nlo\ng\nic\nal\n\nth\neo\nry\n\no\nf\n\np\nre\nfe\nre\nn\nce\ns\n\nN\no\nt sp\nec\nifi\ned\n\n818 Business Research (2020) 13:795–848\n\n123\n\n\n\nT\na\n\nb\nle\n\n3\nco\nn\nti\nn\nu\ned\n\nA\nu\nth\no\nr(\ns)\n,\ny\nea\nr\n\nM\nai\nn\nfo\ncu\ns\n\nB\n/D\n/F\n/P\nF\n\nM\net\nh\no\nd\n\nF\nie\nld\n\no\nf\n\nre\nse\nar\nch\n\nS\ny\nst\nem\n\nR\nec\nru\nit\nm\nen\nt,\n\nse\nle\nct\nio\nn\n,\n\nd\nev\nel\no\np\nm\nen\nt,\n\ntr\nai\nn\nin\ng\n\nK\ney\n\nfi\nn\nd\nin\ng\ns\n\nG\neo\ng\nra\np\nh\ny\n\nC\nh\nen\n\net\nal\n.\n(2\n0\n1\n8\n)\n\nIn\nv\nes\nti\ng\nat\nes\n\ng\nen\nd\ner\n-\n\nb\nas\ned\n\nin\neq\nu\nal\nit\nie\ns\n\nin\nth\ne\nco\nn\nte\nx\nt\no\nf\n\nre\nsu\nm\ne\nse\nar\nch\n\nen\ng\nin\nes\n,\n\nd\nis\ncr\nim\n\nin\nat\nio\nn\n\nB\n,\nD\n,\nF\n\nE\nm\np\nir\nic\nal\n-\n\nq\nu\nan\nti\nta\nti\nv\ne;\n\nst\nat\nis\nti\nca\nl\n\nte\nst\ns\n\nC\no\nm\np\nu\nte\nr\n\nsc\nie\nn\nce\n\nS\nea\nrc\nh\nen\ng\nin\nes\n\nR\nec\nru\nit\nm\nen\nt\n\nIn\nd\niv\nid\nu\nal\n\nfa\nir\nn\nes\ns:\nev\nen\n\nw\nh\nen\n\nco\nn\ntr\no\nll\nin\ng\nfo\nr\n\nal\nl\no\nth\ner\n\nv\nis\nib\nle\n\nca\nn\nd\nid\nat\ne\nfe\nat\nu\nre\ns,\n\nth\ner\ne\nis\n\na\nsl\nig\nh\nt\n\np\nen\nal\nty\n\nag\nai\nn\nst\nfe\nm\nal\ne\n\nca\nn\nd\nid\nat\nes\n\nG\nro\nu\np\nfa\nir\nn\nes\ns:\n\n8\n.5\n–\n1\n3\n.2\n%\n\no\nf\njo\nb\nti\ntl\ne/\n\nci\nty\n\np\nai\nrs\n\nsh\no\nw\n\nst\nat\nis\nti\nca\nll\ny\nsi\ng\nn\nifi\nca\nn\nt\n\ng\nro\nu\np\nu\nn\nfa\nir\nn\nes\ns\n\nU\nS\nA\n\nB\no\ng\nen\n\n(2\n0\n1\n9\n)\n\nA\nn\nal\ny\nsi\ns\no\nf\n\np\nre\nd\nic\nti\nv\ne\nto\no\nls\n\nac\nro\nss\n\nth\ne\nh\nir\nin\ng\n\np\nro\nce\nss\n\nto\ncl\nar\nif\ny\n\nw\nh\nat\n\nh\nir\nin\ng\n\nal\ng\no\nri\nth\nm\ns\nd\no\n,\n\nan\nd\nw\nh\ner\ne\nan\nd\n\nh\no\nw\n\nb\nia\ns\nca\nn\n\nen\nte\nr\nin\nto\n\nth\ne\n\np\nro\nce\nss\n\nB\n,\nD\n,\nF\n\nN\no\nn\n-e\nm\np\nir\nic\nal\n;\n\nco\nn\nce\np\ntu\nal\n\np\nap\ner\n\nM\nan\nag\nem\n\nen\nt\n\nG\nen\ner\nal\n,\nh\nir\nin\ng\n\nal\ng\no\nri\nth\nm\ns\n\nR\nec\nru\nit\nm\nen\nt\n\nan\nd\n\nse\nle\nct\nio\nn\n\nM\no\nst\nh\nir\nin\ng\nal\ng\no\nri\nth\nm\ns\n\nw\nil\nl\nd\nri\nft\nto\nw\nar\nd\nb\nia\ns\n\nb\ny\nd\nef\nau\nlt\n\nP\no\nte\nn\nti\nal\n\nto\nh\nel\np\nre\nd\nu\nce\n\nin\nte\nrp\ner\nso\nn\nal\n\nb\nia\ns\n\nsh\no\nu\nld\n\nn\no\nt\nb\ne\n\nd\nis\nco\nu\nn\nte\nd\n\nO\nn\nly\n\nto\no\nls\nth\nat\n\np\nro\nac\nti\nv\nel\ny\nta\nck\nle\n\nd\nee\np\ner\n\nd\nis\np\nar\nit\nie\ns\nw\nil\nl\n\no\nff\ner\n\nan\ny\nh\no\np\ne\nth\nat\n\np\nre\nd\nic\nti\nv\ne\nte\nch\nn\no\nlo\ng\ny\n\nca\nn\nh\nel\np\np\nro\nm\no\nte\n\neq\nu\nit\ny\n,\nra\nth\ner\n\nth\nan\n\ner\no\nd\ne\nit\n\nU\nS\nA\n\nBusiness Research (2020) 13:795–848 819\n\n123\n\n\n\nT\na\n\nb\nle\n\n3\nco\nn\nti\nn\nu\ned\n\nA\nu\nth\no\nr(\ns)\n,\ny\nea\nr\n\nM\nai\nn\nfo\ncu\ns\n\nB\n/D\n/F\n/P\nF\n\nM\net\nh\no\nd\n\nF\nie\nld\n\no\nf\n\nre\nse\nar\nch\n\nS\ny\nst\nem\n\nR\nec\nru\nit\nm\nen\nt,\n\nse\nle\nct\nio\nn\n,\n\nd\nev\nel\no\np\nm\nen\nt,\n\ntr\nai\nn\nin\ng\n\nK\ney\n\nfi\nn\nd\nin\ng\ns\n\nG\neo\ng\nra\np\nh\ny\n\nS\nim\n\nb\nec\nk\n(2\n0\n1\n9\n)\n\nD\nis\ncu\nss\nes\n\nth\ne\n\net\nh\nic\nal\n\nim\np\nli\nca\nti\no\nn\ns\no\nf\n\nth\ne\nap\np\nli\nca\nti\no\nn\no\nf\n\nso\np\nh\nis\nti\nca\nte\nd\n\nan\nal\ny\nti\nca\nl\n\nm\net\nh\no\nd\ns\nto\n\nq\nu\nes\nti\no\nn\ns\nin\n\nH\nR\n\nm\nan\nag\nem\n\nen\nt\n\nB\n,\nD\n,\nF\n\nN\no\nn\n-e\nm\np\nir\nic\nal\n;\n\nco\nn\nce\np\ntu\nal\n\np\nap\ner\n\nM\nan\nag\nem\n\nen\nt\n\nG\nen\ner\nal\n\nR\nec\nru\nit\nm\nen\nt\n\nan\nd\n\nse\nle\nct\nio\nn\n,\n\nd\nev\nel\no\np\nm\nen\nt\n\nT\nh\ne\nri\nsi\nn\ng\nd\nat\na\no\nn\n\nem\np\nlo\ny\nee\ns\nw\nil\nl\n\nL\nea\nd\nto\n\nan\n\nu\nn\np\nre\nce\nd\nen\nte\nd\n\ntr\nan\nsp\nar\nen\ncy\n\no\nf\n\nem\np\nlo\ny\nee\ns\n\nP\nro\np\no\nse\ns\nto\n\ntr\nan\nsf\ner\n\nk\ney\n\net\nh\nic\nal\n\nco\nn\nce\np\nts\n\nfr\no\nm\n\nm\ned\nic\nal\n\nre\nse\nar\nch\n,\n\nar\nti\nfi\nci\nal\n\nin\nte\nll\nig\nen\nce\n,\n\nle\nar\nn\nin\ng\nan\nal\ny\nti\ncs\n,\nan\nd\n\nco\nac\nh\nin\ng\nto\n\nH\nR\n\nan\nal\ny\nti\ncs\n\nN\no\nt sp\nec\nifi\ned\n\n820 Business Research (2020) 13:795–848\n\n123\n\n\n\nT\na\n\nb\nle\n\n3\nco\nn\nti\nn\nu\ned\n\nA\nu\nth\no\nr(\ns)\n,\ny\nea\nr\n\nM\nai\nn\nfo\ncu\ns\n\nB\n/D\n/F\n/P\nF\n\nM\net\nh\no\nd\n\nF\nie\nld\n\no\nf\n\nre\nse\nar\nch\n\nS\ny\nst\nem\n\nR\nec\nru\nit\nm\nen\nt,\n\nse\nle\nct\nio\nn\n,\n\nd\nev\nel\no\np\nm\nen\nt,\n\ntr\nai\nn\nin\ng\n\nK\ney\n\nfi\nn\nd\nin\ng\ns\n\nG\neo\ng\nra\np\nh\ny\n\nK\nel\nlo\ng\ng\net\n\nal\n.\n\n(2\n0\n2\n0\n)\n\nA\nn\nal\ny\nze\ns\nh\no\nw\n\nth\ne\n\nim\np\nle\nm\nen\nta\nti\no\nn\n\no\nf\nal\ng\no\nri\nth\nm\nic\n\nte\nch\nn\no\nlo\ng\nie\ns\nin\n\no\nrg\nan\niz\nat\nio\nn\ns\n\nm\nay\n\nre\nsh\nap\ne\n\no\nrg\nan\niz\nat\nio\nn\nal\n\nco\nn\ntr\no\nl\n\nB\n,\nD\n,\nF\n\nN\no\nn\n-e\nm\np\nir\nic\nal\n;\n\nli\nte\nra\ntu\nre\n\nre\nv\nie\nw\n\nM\nan\nag\nem\n\nen\nt\n\nA\nlg\no\nri\nth\nm\nic\n\nre\nco\nm\nm\nen\nd\nin\ng\n,\n\nre\nst\nri\nct\nin\ng\n,\n\nre\nco\nrd\nin\ng\n,\n\nra\nti\nn\ng\n,\n\nre\np\nla\nci\nn\ng\n,\nan\nd\n\nre\nw\nar\nd\nin\ng\n\nD\nev\nel\no\np\nm\nen\nt\n\nA\nlg\no\nri\nth\nm\nic\n\nco\nn\ntr\no\nl\nin\n\nth\ne\nw\no\nrk\np\nla\nce\n\no\np\ner\nat\nes\n\nth\nro\nu\ng\nh\nsi\nx\n\nm\nai\nn\nm\nec\nh\nan\nis\nm\ns:\n\nre\nst\nri\nct\nin\ng\n,\n\nre\nco\nm\nm\nen\nd\nin\ng\n,\n\nre\nco\nrd\nin\ng\n,\nra\nti\nn\ng\n,\n\nre\np\nla\nci\nn\ng\n,\nre\nw\nar\nd\nin\ng\n\nT\nh\ne\nte\nch\nn\nic\nal\n\nca\np\nab\nil\nit\nie\ns\no\nf\n\nal\ng\no\nri\nth\nm\nic\n\nsy\nst\nem\n\ns\n\nfa\nci\nli\nta\nte\n\na\nfo\nrm\n\no\nf\n\nra\nti\no\nn\nal\n\nco\nn\ntr\no\nl\nth\nat\n\nis\n\nd\nis\nti\nn\nct\n\nfr\no\nm\n\nco\nn\ntr\no\nl\n\nu\nse\nd\nb\ny\nem\n\np\nlo\ny\ner\ns\nfo\nr\n\nth\ne\np\nas\nt\nce\nn\ntu\nry\n\nE\nm\np\nlo\ny\nee\ns\nar\ne\n\nin\nd\niv\nid\nu\nal\nly\n\nan\nd\n\nco\nll\nec\nti\nv\nel\ny\nre\nsi\nst\nin\ng\n\nal\ng\no\nri\nth\nm\nic\n\nco\nn\ntr\no\nl\n\nth\nro\nu\ng\nh\na\nse\nt\no\nf\n\nem\ner\ng\nin\ng\nta\nct\nic\ns\n\nN\no\nt sp\nec\nifi\ned\n\nBusiness Research (2020) 13:795–848 821\n\n123\n\n\n\nT\na\n\nb\nle\n\n3\nco\nn\nti\nn\nu\ned\n\nA\nu\nth\no\nr(\ns)\n,\ny\nea\nr\n\nM\nai\nn\nfo\ncu\ns\n\nB\n/D\n/F\n/P\nF\n\nM\net\nh\no\nd\n\nF\nie\nld\n\no\nf\n\nre\nse\nar\nch\n\nS\ny\nst\nem\n\nR\nec\nru\nit\nm\nen\nt,\n\nse\nle\nct\nio\nn\n,\n\nd\nev\nel\no\np\nm\nen\nt,\n\ntr\nai\nn\nin\ng\n\nK\ney\n\nfi\nn\nd\nin\ng\ns\n\nG\neo\ng\nra\np\nh\ny\n\nC\nh\nam\n\no\nrr\no\n-\n\nP\nre\nm\nu\nzi\nc\net\n\nal\n.\n\n(2\n0\n1\n7\n)\n\nR\nev\nie\nw\ns\nth\nre\ne\n\nin\nn\no\nv\nat\nio\nn\ns\nth\nat\n\nh\nav\ne\nth\ne\np\no\nte\nn\nti\nal\n\nto\nre\nv\no\nlu\nti\no\nn\niz\ne\n\nth\ne\nw\nay\n\no\nrg\nan\niz\nat\nio\nn\ns\n\nid\nen\nti\nfy\n,\nd\nev\nel\no\np\n,\n\nan\nd\nen\ng\nag\ne\nta\nle\nn\nt\n\nan\nd\nar\ne\nem\n\ner\ng\nin\ng\n\nas\nto\no\nls\n\nu\nse\nd\nb\ny\n\np\nra\nct\nit\nio\nn\ner\ns\nan\nd\n\nfi\nrm\n\ns\n\nD\nN\no\nn\n-e\nm\np\nir\nic\nal\n;\n\nco\nn\nce\np\ntu\nal\n\np\nap\ner\n\nB\neh\nav\nio\nra\nl\n\nsc\nie\nn\nce\n\nM\nac\nh\nin\ne-\nle\nar\nn\nin\ng\n\nal\ng\no\nri\nth\nm\ns,\n\nso\nci\nal\n\nse\nn\nsi\nn\ng\n\nte\nch\nn\no\nlo\ng\ny\n,\n\ng\nam\n\nifi\ned\n\nA\nss\nes\nsm\n\nen\nt\nto\no\nls\n\nR\nec\nru\nit\nm\nen\nt\n\nan\nd\n\nse\nle\nct\nio\nn\n,\n\nd\nev\nel\no\np\nm\nen\nt\n\nT\nal\nen\nt\nan\nal\ny\nti\ncs\n\nre\np\nre\nse\nn\nt\na\nm\no\nre\n\nd\nat\na-\n\nd\nri\nv\nen\n\nan\nd\nev\nid\nen\nce\n-\n\nb\nas\ned\n\nap\np\nro\nac\nh\nth\nan\n\nh\nu\nm\nan\n\nin\ntu\nit\nio\nn\n\nN\no\nt sp\nec\nifi\ned\n\nK\nim\n\nan\nd\nS\nco\ntt\n\n(2\n0\n1\n8\n)\n\nE\nx\nam\n\nin\nes\n\nd\nis\ncr\nim\n\nin\nat\nio\nn\nin\n\nth\ne\no\nn\nli\nn\ne\n\nap\np\nli\nca\nti\no\nn\n\np\nro\nce\nss\n\nD\nev\nel\no\np\ns\n\nm\nec\nh\nan\nis\nm\ns\nto\n\nch\nec\nk\nw\nh\nen\n\nd\nis\ncr\nim\n\nin\nat\nio\nn\n\no\ncc\nu\nrs\n\nin\no\nn\nli\nn\ne\n\nre\ncr\nu\nit\nm\nen\nt\n\nD\nE\nm\np\nir\nic\nal\n-\n\nq\nu\nal\nit\nat\niv\ne\n\nL\naw\n\nR\nec\no\nm\nm\nen\nd\ner\n\nsy\nst\nem\n\ns\n\nR\nec\nru\nit\nm\nen\nt\n\nIt\nis\n\nn\no\nt\nce\nrt\nai\nn\nw\nh\net\nh\ner\n\ncu\nrr\nen\nt\nla\nw\n\nis\n\nad\neq\nu\nat\ne\nto\n\nre\nac\nh\nal\nl\n\nfo\nrm\n\ns\no\nf\nta\nrg\net\ned\n\nR\nec\nru\nit\nm\nen\nt\nw\nit\nh\n\nsi\ng\nn\nifi\nca\nn\nt\n\nd\nis\ncr\nim\n\nin\nat\no\nry\n\nef\nfe\nct\ns\n\nN\no\nt sp\nec\nifi\ned\n\n822 Business Research (2020) 13:795–848\n\n123\n\n\n\nT\na\n\nb\nle\n\n3\nco\nn\nti\nn\nu\ned\n\nA\nu\nth\no\nr(\ns)\n,\ny\nea\nr\n\nM\nai\nn\nfo\ncu\ns\n\nB\n/D\n/F\n/P\nF\n\nM\net\nh\no\nd\n\nF\nie\nld\n\no\nf\n\nre\nse\nar\nch\n\nS\ny\nst\nem\n\nR\nec\nru\nit\nm\nen\nt,\n\nse\nle\nct\nio\nn\n,\n\nd\nev\nel\no\np\nm\nen\nt,\n\ntr\nai\nn\nin\ng\n\nK\ney\n\nfi\nn\nd\nin\ng\ns\n\nG\neo\ng\nra\np\nh\ny\n\nC\nap\np\nel\nli\n(2\n0\n1\n9\n)\n\nP\nre\nse\nn\nts\n\np\nro\nb\nle\nm\ns\n\nw\nh\nic\nh\no\ncc\nu\nr\n\nb\nec\nau\nse\n\no\nf\nth\ne\n\nri\nse\n\no\nf\nd\nat\na\n\nsc\nie\nn\nce\n\nin\nh\nir\nin\ng\n\np\nro\nce\nss\nes\n\nb\ny\n\nu\nsi\nn\ng\nd\nri\nv\nen\n\nal\ng\no\nri\nth\nm\ns\nto\n\nfi\nn\nd\n\nan\nd\nas\nse\nss\n\njo\nb\n\nca\nn\nd\nid\nat\nes\n\nD\nN\no\nn\n-e\nm\np\nir\nic\nal\n;\n\nil\nlu\nst\nra\nti\nv\ne\n\nca\nse\n\nM\nan\nag\nem\n\nen\nt\n\nG\nen\ner\nal\n\nS\nel\nec\nti\no\nn\n\nP\no\nss\nib\nle\n\nso\nlu\nti\no\nn\nm\nig\nh\nt\n\nb\ne\ntr\nac\nk\nin\ng\nth\ne\n\np\ner\nce\nn\nta\ng\ne\no\nf\n\no\np\nen\nin\ng\ns\nfi\nll\ned\n\nfr\no\nm\n\nw\nit\nh\nin\n,\nre\nq\nu\nir\nin\ng\nth\nat\n\nal\nl\no\np\nen\nin\ng\ns\nb\ne\np\no\nst\ned\n\nin\nte\nrn\nal\nly\n\nan\nd\n\nre\nco\ng\nn\niz\nin\ng\nth\ne\nco\nst\ns\n\no\nf\no\nu\nts\nid\ne\nh\nir\nin\ng\n\nW\nay\ns\nto\n\nre\nv\nam\n\np\nth\ne\n\nh\nir\nin\ng\np\nro\nce\nss\n\nco\nu\nld\n\nb\ne\n\nam\no\nn\ng\no\nth\ner\ns\nn\no\nt\nto\n\np\no\nst\n‘‘\np\nh\nan\nto\nm\n\njo\nb\ns‘\n‘,\n\nd\nes\nig\nn\nin\ng\njo\nb\ns\nw\nit\nh\n\nre\nal\nis\nti\nc\nre\nq\nu\nir\nem\n\nen\nts\n\nU\nS\nA\n\nBusiness Research (2020) 13:795–848 823\n\n123\n\n\n\nT\na\n\nb\nle\n\n3\nco\nn\nti\nn\nu\ned\n\nA\nu\nth\no\nr(\ns)\n,\ny\nea\nr\n\nM\nai\nn\nfo\ncu\ns\n\nB\n/D\n/F\n/P\nF\n\nM\net\nh\no\nd\n\nF\nie\nld\n\no\nf\n\nre\nse\nar\nch\n\nS\ny\nst\nem\n\nR\nec\nru\nit\nm\nen\nt,\n\nse\nle\nct\nio\nn\n,\n\nd\nev\nel\no\np\nm\nen\nt,\n\ntr\nai\nn\nin\ng\n\nK\ney\n\nfi\nn\nd\nin\ng\ns\n\nG\neo\ng\nra\np\nh\ny\n\nL\nee\n\net\nal\n.\n(2\n0\n1\n5\n)\n\nE\nx\np\nlo\nre\ns\nth\ne\nim\n\np\nac\nt\n\no\nf\nal\ng\no\nri\nth\nm\nic\n,\n\nd\nat\na-\nd\nri\nv\nen\n\nm\nan\nag\nem\n\nen\nt\nin\n\nth\ne\nco\nn\nte\nx\nt\no\nf\n\nn\new\n\nri\nd\ne\nsh\nar\nin\ng\n\nse\nrv\nic\nes\n\nH\nig\nh\nli\ng\nh\nts\n\no\np\np\no\nrt\nu\nn\nit\nie\ns\nan\nd\n\nch\nal\nle\nn\ng\nes\n\nin\n\nd\nes\nig\nn\nin\ng\nh\nu\nm\nan\n-\n\nce\nn\nte\nre\nd\n\nal\ng\no\nri\nth\nm\nic\n\nw\no\nrk\n\nas\nsi\ng\nn\nm\nen\nt,\n\nin\nfo\nrm\n\nat\nio\nn\n,\nan\nd\n\nev\nal\nu\nat\nio\nn\n\nF\n,\nP\nF\n\nE\nm\np\nir\nic\nal\n-\n\nq\nu\nal\nit\nat\niv\ne;\n\nse\nm\ni-\n\nst\nru\nct\nu\nre\nd\n\nin\nte\nrv\nie\nw\ns;\n\np\no\nst\nan\nal\ny\nsi\ns\n\nC\no\nm\np\nu\nte\nr\n\nsc\nie\nn\nce\n\nE\nv\nal\nu\nat\nio\nn\np\nro\nce\nss\n\nD\nev\nel\no\np\nm\nen\nt\n\nH\nig\nh\nli\ng\nh\nts\nh\no\nw\n\ntr\nan\nsp\nar\nen\ncy\n\no\nf\n\nal\ng\no\nri\nth\nm\nic\n\nas\nsi\ng\nn\nm\nen\nt\nin\nfl\nu\nen\nce\ns\n\nem\np\nlo\ny\nee\n’s\n\nco\no\np\ner\nat\nio\nn\n,\nw\no\nrk\n\nst\nra\nte\ng\ny\n,\nan\nd\n\nw\no\nrk\nar\no\nu\nn\nd\ncr\nea\nti\no\nn\n\nT\nh\nes\ne\nn\nu\nm\ner\nic\n\nsy\nst\nem\n\ns\n\nth\nat\n\nm\nad\ne\nd\nri\nv\ner\ns\n\nac\nco\nu\nn\nta\nb\nle\n\nfo\nr\nal\nl\n\nin\nte\nra\nct\nio\nn\ns\nw\ner\ne\n\nso\nm\net\nim\n\nes\nse\nen\n\nas\n\nu\nn\nfa\nir\nan\nd\nin\nef\nfe\nct\niv\ne\n\nan\nd\ncr\nea\nte\nd\nn\neg\nat\niv\ne\n\np\nsy\nch\no\nlo\ng\nic\nal\n\nfe\nel\nin\ng\ns\n\nin\nd\nri\nv\ner\ns\n\nU\nS\nA\n\n824 Business Research (2020) 13:795–848\n\n123\n\n\n\nT\na\n\nb\nle\n\n3\nco\nn\nti\nn\nu\ned\n\nA\nu\nth\no\nr(\ns)\n,\ny\nea\nr\n\nM\nai\nn\nfo\ncu\ns\n\nB\n/D\n/F\n/P\nF\n\nM\net\nh\no\nd\n\nF\nie\nld\n\no\nf\n\nre\nse\nar\nch\n\nS\ny\nst\nem\n\nR\nec\nru\nit\nm\nen\nt,\n\nse\nle\nct\nio\nn\n,\n\nd\nev\nel\no\np\nm\nen\nt,\n\ntr\nai\nn\nin\ng\n\nK\ney\n\nfi\nn\nd\nin\ng\ns\n\nG\neo\ng\nra\np\nh\ny\n\nM\ncC\n\nar\nth\ny\net\n\nal\n.\n\n(2\n0\n1\n7\n)\n\nC\no\nm\np\nre\nh\nen\nsi\nv\ne\n\nre\nv\nie\nw\n\no\nf\n\nre\nse\nar\nch\n\no\nn\n\nap\np\nli\nca\nn\nt\n\nre\nac\nti\no\nn\ns\nto\n\nse\nle\nct\nio\nn\n\np\nro\nce\nd\nu\nre\ns\n\np\nu\nb\nli\nsh\ned\n\nsi\nn\nce\n\n2\n0\n0\n0\n(i\nn\ncl\nu\nd\nin\ng\n\nal\ng\no\nri\nth\nm\nic\n\nb\nas\ned\n\nse\nle\nct\nio\nn\nto\no\nls\n)\n\nP\nF\n\nN\no\nn\n-e\nm\np\nir\nic\nal\n;\n\nn\nar\nra\nti\nv\ne\n\nre\nv\nie\nw\n\nM\nan\nag\nem\n\nen\nt\n\nS\nev\ner\nal\n\nse\nle\nct\nio\nn\n\nto\no\nls\n\nS\nel\nec\nti\no\nn\n\nT\nh\ne\nfi\nel\nd\no\nf\nap\np\nli\nca\nn\nt\n\nre\nac\nti\no\nn\ns\nh\nas\n\nad\nv\nan\nce\nd\n\nco\nn\nsi\nd\ner\nab\nly\n\nan\nd\n\nm\nad\ne\nsu\nb\nst\nan\nti\nal\n\nan\nd\n\nm\nea\nn\nin\ng\nfu\nl\n\nco\nn\ntr\nib\nu\nti\no\nn\ns\nto\n\nth\neo\nry\n,\nm\net\nh\no\nd\ns,\nan\nd\n\np\nra\nct\nic\ne\no\nf\n\nre\ncr\nu\nit\nm\nen\nt\nan\nd\n\nse\nle\nct\nio\nn\no\nv\ner\n\nth\ne\nla\nst\n\n1\n5\ny\nea\nrs\n\nN\no\nt sp\nec\nifi\ned\n\nL\nan\ng\ner\n\net\nal\n.\n\n(2\n0\n1\n8\n)\n\nA\nn\nal\ny\nze\ns\nth\ne\nro\nle\n\no\nf\n\nco\nm\np\nu\nte\nr\n\nex\np\ner\nie\nn\nce\n\nan\nd\n\nin\nfo\nrm\n\nat\nio\nn\no\nn\n\nap\np\nli\nca\nn\nt\nre\nac\nti\no\nn\n\nto\nw\nar\nd\ns\nn\no\nv\nel\n\nte\nch\nn\no\nlo\ng\nie\ns\nfo\nr\n\np\ner\nso\nn\nn\nel\n\nse\nle\nct\nio\nn\n\nP\nF\n\nE\nm\np\nir\nic\nal\n-\n\nq\nu\nan\nti\nta\nti\nv\ne;\n\nq\nu\nas\ni-\n\nex\np\ner\nim\n\nen\nta\nl\n\nd\nes\nig\nn\n\nC\no\nm\np\nu\nte\nr\n\nsc\nie\nn\nce\n\nS\nev\ner\nal\n\nse\nle\nct\nio\nn\n\nto\no\nls\n\nS\nel\nec\nti\no\nn\n\nC\no\nm\np\nu\nte\nr\nex\np\ner\nie\nn\nce\n\nd\nid\n\nn\no\nt\naf\nfe\nct\n\nth\ne\n\nca\nn\nd\nid\nat\ne\nre\nac\nti\no\nn\n\nN\no\nt sp\nec\nifi\ned\n\nBusiness Research (2020) 13:795–848 825\n\n123\n\n\n\nT\na\n\nb\nle\n\n3\nco\nn\nti\nn\nu\ned\n\nA\nu\nth\no\nr(\ns)\n,\ny\nea\nr\n\nM\nai\nn\nfo\ncu\ns\n\nB\n/D\n/F\n/P\nF\n\nM\net\nh\no\nd\n\nF\nie\nld\n\no\nf\n\nre\nse\nar\nch\n\nS\ny\nst\nem\n\nR\nec\nru\nit\nm\nen\nt,\n\nse\nle\nct\nio\nn\n,\n\nd\nev\nel\no\np\nm\nen\nt,\n\ntr\nai\nn\nin\ng\n\nK\ney\n\nfi\nn\nd\nin\ng\ns\n\nG\neo\ng\nra\np\nh\ny\n\nL\nee\n\n(2\n0\n1\n8\n)\n\nE\nx\np\nlo\nre\ns\nth\ne\n\np\ner\nce\np\nti\no\nn\ns\no\nf\n\nal\ng\no\nri\nth\nm\nic\n\nm\nan\nag\nem\n\nen\nt\nb\ny\n\nco\nn\nd\nu\nct\nin\ng\nan\n\no\nn\nli\nn\ne\n\nex\np\ner\nim\n\nen\nt\nu\nsi\nn\ng\n\nfo\nu\nr\nm\nan\nag\ner\nia\nl\n\nd\nec\nis\nio\nn\ns\n\nT\nh\ne\nd\nec\nis\nio\nn\n-m\n\nak\ner\n\n(a\nlg\no\nri\nth\nm\nic\n\no\nr\n\nh\nu\nm\nan\n)\nw\nas\n\nm\nan\nip\nu\nla\nte\nd\n,\nan\nd\n\nm\nea\nsu\nre\nd\n\np\ner\nce\niv\ned\n\nfa\nir\nn\nes\ns,\ntr\nu\nst\n,\nan\nd\n\nem\no\nti\no\nn\nal\n\nre\nsp\no\nn\nse\n\nP\nF\n\nE\nm\np\nir\nic\nal\n-\n\nq\nu\nan\nti\nta\nti\nv\ne;\n\nex\np\ner\nim\n\nen\nta\nl\n\nd\nes\nig\nn\n\nC\no\nm\np\nu\nte\nr\n\nsc\nie\nn\nce\n\nG\nen\ner\nal\n\nS\nel\nec\nti\no\nn\n,\n\nd\nev\nel\no\np\nm\nen\nt\n\nP\neo\np\nle\n\np\ner\nce\niv\ne\n\nal\ng\no\nri\nth\nm\nic\n\nd\nec\nis\nio\nn\ns\n\nas\nle\nss\n\ntr\nu\nst\nw\no\nrt\nh\ny\n\nan\nd\nm\no\nre\n\nli\nk\nel\ny\nto\n\nev\no\nk\ne\nn\neg\nat\niv\ne\n\nem\no\nti\no\nn\nfo\nr\nta\nsk\ns\nth\nat\n\np\neo\np\nle\n\nth\nin\nk\nre\nq\nu\nir\ne\n\nu\nn\niq\nu\nel\ny\nh\nu\nm\nan\n\nsk\nil\nls\n\nU\nS\nA\n\nÖ\ntt\nin\ng\nan\nd\nM\nai\ner\n\n(2\n0\n1\n8\n)\n\nE\nx\nam\n\nin\nes\n\nth\ne\n\nef\nfe\nct\ns\no\nf\n\np\nro\nce\nd\nu\nra\nl\nju\nst\nic\ne\n\nan\nd\nth\ne\nty\np\ne\no\nf\n\nd\nec\nis\nio\nn\nag\nen\nt\no\nn\n\nem\np\nlo\ny\nee\n\nb\neh\nav\nio\nr\nan\nd\n\nat\nti\ntu\nd\nes\n\nP\nF\n\nE\nm\np\nir\nic\nal\n-\n\nq\nu\nan\nti\nta\nti\nv\ne;\n\nex\np\ner\nim\n\nen\nta\nl\n\nd\nes\nig\nn\n\nC\no\nm\np\nu\nte\nr\n\nsc\nie\nn\nce\n\nG\nen\ner\nal\n\nD\nev\nel\no\np\nm\nen\nt\n\nS\nig\nn\nifi\nca\nn\nt\nef\nfe\nct\ns\no\nf\n\np\nro\nce\nd\nu\nra\nl\nju\nst\nic\ne\no\nn\n\nem\np\nlo\ny\nee\n\nb\neh\nav\nio\nr\n\nan\nd\nat\nti\ntu\nd\nes\n,\n\nco\nn\nfi\nrm\n\nin\ng\nth\ne\n\nim\np\no\nrt\nan\nce\n\no\nf\n\np\nro\nce\nd\nu\nra\nl\nju\nst\nic\ne\nat\n\nth\ne\nw\no\nrk\np\nla\nce\n\nfo\nr\nb\no\nth\n\nh\nu\nm\nan\n\nan\nd\nsy\nst\nem\n\nd\nec\nis\nio\nn\nag\nen\nts\n\nG\ner\nm\nan\ny\n\n826 Business Research (2020) 13:795–848\n\n123\n\n\n\nT\na\n\nb\nle\n\n3\nco\nn\nti\nn\nu\ned\n\nA\nu\nth\no\nr(\ns)\n,\ny\nea\nr\n\nM\nai\nn\nfo\ncu\ns\n\nB\n/D\n/F\n/P\nF\n\nM\net\nh\no\nd\n\nF\nie\nld\n\no\nf\n\nre\nse\nar\nch\n\nS\ny\nst\nem\n\nR\nec\nru\nit\nm\nen\nt,\n\nse\nle\nct\nio\nn\n,\n\nd\nev\nel\no\np\nm\nen\nt,\n\ntr\nai\nn\nin\ng\n\nK\ney\n\nfi\nn\nd\nin\ng\ns\n\nG\neo\ng\nra\np\nh\ny\n\nK\nai\nb\nel\n\net\nal\n.\n\n(2\n0\n1\n9\n)\n\nA\nn\nal\ny\nsi\ns\no\nf\nth\ne\n\np\ner\nce\np\nti\no\nn\no\nf\n\nal\ng\no\nri\nth\nm\n-b\nas\ned\n\nd\nec\nis\nio\nn\ns\nv\ner\nsu\ns\n\nh\nu\nm\nan\n-b\nas\ned\n\nd\nec\nis\nio\nn\ns\nin\n\nre\ncr\nu\nit\nm\nen\nt\n\nR\no\nle\n\no\nf\n\nin\nte\nri\nn\nd\niv\nid\nu\nal\n\nd\nif\nfe\nre\nn\nce\ns\n\nP\nF\n\nE\nm\np\nir\nic\nal\n-\n\nq\nu\nan\nti\nta\nti\nv\ne;\n\nE\nx\np\ner\nim\n\nen\nta\nl\n\nd\nes\nig\nn\n\nM\nan\nag\nem\n\nen\nt\n\nA\nu\nto\nm\nat\ned\n\nsc\nre\nen\nin\ng\n\nal\ng\no\nri\nth\nm\n,\n\nd\nig\nit\nal\nin\nte\nrv\nie\nw\n\nS\nel\nec\nti\no\nn\n\nA\np\np\nli\nca\nn\nts\np\ner\nce\niv\ned\n\nth\ne\n\nal\ng\no\nri\nth\nm\nic\n\nse\nle\nct\nio\nn\n\nas\nm\no\nre\n\nco\nn\nsi\nst\nen\nt,\n\nle\nss\n\np\ner\nso\nn\nab\nle\n\nT\nh\ne\no\nrg\nan\niz\nat\nio\nn\nal\n\nat\ntr\nac\nti\nv\nen\nes\ns\nis\nlo\nw\ner\n\nw\nit\nh\nal\ng\no\nri\nth\nm\n-b\nas\ned\n\nd\nec\nis\nio\nn\n\nG\ner\nm\nan\ny\n,\n\nU\nS\nA\n\nL\nan\ng\ner\n\net\nal\n.\n\n(2\n0\n1\n9\n)\n\nC\no\nm\np\nar\nis\no\nn\no\nf\n\nh\nig\nh\nly\n\nau\nto\nm\nat\ned\n\nin\nte\nrv\nie\nw\ns\nto\n\na\n\nv\nid\neo\n\nco\nn\nfe\nre\nn\nce\n\nin\nte\nrv\nie\nw\n\nP\nF\n\nE\nm\np\nir\nic\nal\n-\n\nq\nu\nan\nti\nta\nti\nv\ne;\n\nex\np\ner\nim\n\nen\nta\nl\n\nd\nes\nig\nn\n\nP\nsy\nch\no\nlo\ng\ny\n\nA\nsy\nn\nch\nro\nn\no\nu\ns\n\nv\nid\neo\n\nin\nte\nrv\nie\nw\ns\n\nS\nel\nec\nti\no\nn\n\nH\nig\nh\nly\n\nau\nto\nm\nat\ned\n\nin\nte\nrv\nie\nw\ns\nar\ne\nle\nss\n\nac\nce\np\nte\nd\nth\nan\n\nv\nid\neo\n\nco\nn\nfe\nre\nn\nce\n\nin\nte\nrv\nie\nw\ns\n\nfr\no\nm\n\nth\ne\np\ner\nsp\nec\nti\nv\ne\n\no\nf\nap\np\nli\nca\nn\nt\nan\nd\nn\nee\nd\n\nto\nb\ne\nm\no\nre\n\ntr\nan\nsp\nar\nen\nt\n\nG\ner\nm\nan\ny\n\nS\nu\nen\n\net\nal\n.\n(2\n0\n1\n9\n)\n\nIn\nv\nes\nti\ng\nat\nes\n\nth\ne\n\nso\nci\nal\n\nim\np\nac\nts\no\nf\n\nu\nsi\nn\ng\nsy\nn\nch\nro\nn\ny\n\nan\nd\nA\nI\nd\nec\nis\nio\nn\n\nag\nen\nts\nin\n\nv\nid\neo\n\nin\nte\nrv\nie\nw\ns\n\nP\nF\n\nE\nm\np\nir\nic\nal\n-\n\nq\nu\nan\nti\nta\nti\nv\ne;\n\nex\np\ner\nim\n\nen\nta\nl\n\nd\nes\nig\nn\n\nC\no\nm\np\nu\nte\nr\n\nsc\nie\nn\nce\n\nA\nsy\nn\nch\nro\nn\no\nu\ns\n\nv\nid\neo\n\nin\nte\nrv\nie\nw\ns\n\nS\nel\nec\nti\no\nn\n\nJo\nb\nap\np\nli\nca\nn\nts\nh\nad\n\nin\nd\nis\nti\nn\ng\nu\nis\nh\nab\nle\n\nfa\nir\nn\nes\ns\np\ner\nce\np\nti\no\nn\ns\n\nre\ng\nar\nd\nin\ng\nsy\nn\nch\nro\nn\ny\n\nan\nd\nd\nec\nis\nio\nn\nag\nen\nt\n\n(h\nu\nm\nan\n\nv\ns.\nA\nI)\n\nC\nh\nin\na\n\nBusiness Research (2020) 13:795–848 827\n\n123\n\n\n\nT\na\n\nb\nle\n\n3\nco\nn\nti\nn\nu\ned\n\nA\nu\nth\no\nr(\ns)\n,\ny\nea\nr\n\nM\nai\nn\nfo\ncu\ns\n\nB\n/D\n/F\n/P\nF\n\nM\net\nh\no\nd\n\nF\nie\nld\n\no\nf\n\nre\nse\nar\nch\n\nS\ny\nst\nem\n\nR\nec\nru\nit\nm\nen\nt,\n\nse\nle\nct\nio\nn\n,\n\nd\nev\nel\no\np\nm\nen\nt,\n\ntr\nai\nn\nin\ng\n\nK\ney\n\nfi\nn\nd\nin\ng\ns\n\nG\neo\ng\nra\np\nh\ny\n\nL\nec\nle\nrc\nq\n-\n\nV\nan\nd\nel\nan\nn\no\nit\nte\n\n(2\n0\n1\n7\n)\n\nIn\nv\nes\nti\ng\nat\nes\n\nth\ne\n\nm\no\nra\nl\nan\nd\net\nh\nic\nal\n\nim\np\nli\nca\nti\no\nn\ns\no\nf\n\nem\ner\ng\nin\ng\nfo\nrm\n\ns\n\no\nf\nco\nn\ntr\no\nl\nth\nat\n\nh\nav\ne\nd\nev\nel\no\np\ned\n\nal\no\nn\ng\nw\nit\nh\nth\ne\n\nu\nse\n\no\nf\nm\no\nd\ner\nn\n\nu\nb\niq\nu\nit\no\nu\ns\n\nin\nfo\nrm\n\nat\nio\nn\n\nte\nch\nn\no\nlo\ng\ny\nin\n\nth\ne\n\nw\no\nrk\np\nla\nce\n\nN\no\nt sp\nec\nifi\ned\n\nN\no\nn\n-e\nm\np\nir\nic\nal\n;\n\nca\nse\n\nst\nu\nd\ny\n\nM\nan\nag\nem\n\nen\nt\n\nG\nen\ner\nal\n\nD\nev\nel\no\np\nm\nen\nt\n\nE\nth\nic\nal\n\nis\nsu\nes\n\nar\ne\nth\ne\n\nam\nb\niv\nal\nen\nce\n\no\nf\nth\ne\n\nu\nse\n\no\nf\nu\nb\niq\nu\nit\no\nu\ns\nIT\n\nat\n\nw\no\nrk\n,\nsu\nb\ntl\net\ny\no\nf\nth\ne\n\nco\nn\ntr\no\nl\nex\ner\nte\nd\nb\ny\n\nu\nb\niq\nu\nit\no\nu\ns\nIT\n,\n\nin\nv\nas\niv\nen\nes\ns\no\nf\n\nu\nb\niq\nu\nit\no\nu\ns\nIT\n,\nan\nd\n\nse\nlf\n-r\nei\nn\nfo\nrc\nem\n\nen\nt\no\nf\n\nu\nb\niq\nu\nit\no\nu\ns\nIT\n-b\nas\ned\n\nco\nn\ntr\no\nl\n\nF\nra\nn\nce\n\nB\nb\nia\ns,\nD\n\nd\nis\ncr\nim\n\nin\nat\nio\nn\n,\nF\nfa\nir\nn\nes\ns,\nP\nF\np\ner\nce\niv\ned\n\nfa\nir\nn\nes\ns\n\n828 Business Research (2020) 13:795–848\n\n123\n\n\n\nTable 4 Types of AI application, bias, research gaps, and research implications\n\nHR recruitment HR development\n\nRecruitment Selection\n\nHR tools Search engines\n\nRecommender\n\nsystems\n\nAnalysis of CV, résumé, and\n\nreferences\n\nGamification\n\nAlgorithmic video- and\n\ntelephone analysis\n\nData profiling\n\nEvaluation\n\nInterviews\n\nRecommender systems\n\nAI tools Collaborative filtering Text mining, NLP, FEP NLP, FEP, data mining,\n\ncollaborative filtering,\n\nclassification\n\nBias Yes Yes Yes\n\nPerceived\n\nfairness\n\nNo Yes Yes\n\nResearch\n\nimplications\n\nNeed for empirical-\n\nquantitative studies\n\nResearch about the\n\nperceived fairness\n\nResearch on AI in several\n\nsteps of the selection\n\nprocess\n\nResearch on AI as decision\n\nsupport\n\nNeed for empirical-\n\nquantitative studies\n\nResearch on the perceived\n\nfairness\n\nExemplary\n\nresearch\n\nquestions\n\nHow fair do\n\napplicants perceive\n\nsearch engines and\n\nrecommender\n\nsystems?\n\nHow can established selection\n\ntechniques be transformed\n\ninto algorithmic\n\nmeasurements?\n\nTo what extent can\n\nalgorithmic de-bias\n\nstrategies be applied?\n\nWhich type of algorithmic\n\ndecision tool do applicants\n\nprefer?\n\nDoes more information about\n\nthe algorithmic decision-\n\nmaking process influences\n\nthe fairness perception of\n\nthe applicants?\n\nHow do candidates react when\n\nAI is interfered in several\n\nselection process steps?\n\nWhat is the reaction if the\n\nalgorithm only supports the\n\nprocess, but the final\n\ndecision remains human?\n\nWhat is the difference in\n\nreliability and validity\n\nbetween AI decision-makers\n\nand human raters?\n\nTo what extent can\n\nalgorithmic de-bias\n\nstrategies be applied?\n\nWhat are ways to avoid bias?\n\nHow fair do employees\n\nconsider algorithmic\n\ndecision-making?\n\nWhat measures can be taken\n\nto ensure that employees\n\nperceive algorithmic\n\ndecision-making as fair?\n\nCV curriculum vitae, FEP facial expression processing, NLP natural language processing, ML machine\n\nlearning\n\nBusiness Research (2020) 13:795–848 829\n\n123\n\n\n\nwere published in 2019, which stresses the importance of fairness and discrimi-\n\nnation as a recent topic in the management and HRM literature.\n\nOur results suggest there is still room for academic researchers to complement\n\nthe literature and discussion on algorithmic decision-making and fairness. In the\n\nfollowing, we introduce some algorithmic decision tools used in HR recruitment and\n\nHR development and their potential for discrimination.\n\n5 Types of algorithmic decisions and applications in HR\n\n5.1 HR recruitment\n\nIn the following, we present some examples of algorithmic decision-making\n\napplications in HR recruitment and their fairness. We distinguish between\n\nrecruitment (i.e., finding a candidate) and selection (i.e., selecting among these\n\ncandidates), which is considered as part of the recruitment process, because, in these\n\ntwo different stages, companies use different algorithmic decision tools.\n\nFirms increasingly rely on social media platforms and digital services, such as\n\nFacebook, Instagram, LinkedIn, Xing, Monster, and CareerBuilder, to advertise job\n\nvacancies and to find well-fitting candidates (Burke et al. 2018; Chen et al. 2018).\n\nThese digital services are called recommender systems and search engines and use\n\nalgorithmic decision-making tools to recommend suitable candidates to recruiters\n\nand suitable employers to candidates (Chen et al. 2018). To propose individual\n\nrecommendations, recommender systems take advantage of different information\n\nsources. Based on users’ descriptions, prior choices, and the behavior of other\n\nsimilar users, the recommender system proposes ads aiming to match recommen-\n\ndations and user preferences (Burke et al. 2018; Simbeck 2019). However, it is a\n\n0\n\n2\n\n4\n\n6\n\n8\n\n10\n\n12\n\n14\n\n2014 2015 2016 2017 2018 2019 2020\n\nnon-empirical empirical-qualitative empirical-quantitative\n\nFig. 2 Distribution of publications over time and research methods. Data on 2020 research articles are\nbased on our database search until April 2020\n\n830 Business Research (2020) 13:795–848\n\n123\n\n\n\nmultifaceted concept, not only the users (here: job seekers) need to be considered,\n\nbut also stakeholders (Burke et al. 2018). Hiring platforms, such as Xing and\n\nLinkedIn, already implement predictive analytics. Their algorithms go through\n\nthousands of job profiles to find the most eligible candidate for a specific job and\n\nrecommend this candidate to the recruiter (Carey and Smith 2016). Firms also\n\nexamine data about job seekers, analyze them based on past hiring decisions, and\n\nthen recommend only the applications that are a potential match (Kim 2016).\n\nConsequently, firms can more precisely target potential candidates. These predic-\n\ntions based on past decisions can unintentionally lead to companies using job\n\nadvertisements that strengthen gender and racial stereotypes, because if, for\n\nexample, in the past, more males were selected for high position jobs, the\n\nadvertisement is consequently shown to more males (historical bias). Thus, tension\n\nexists between the goals of fairness and those of personalization (Burke et al. 2018).\n\nIn a non-empirical paper analyzing predictive tools in USA, Bogen (2019) gives\n\na prime example of algorithmic discrimination against other genders by demon-\n\nstrating that algorithms extrapolate based on patterns of the provided data. Thus, if\n\nrecruiters contacted males more frequently than females, the recommendation will\n\nbe to show job ads more often to males. An explanation could be that males are\n\nmore likely to click on high-paying job ads, and consequently, the algorithm learns\n\nfrom this behavior (Burke et al. 2018).\n\nAnother example showed that targeted ads on Facebook were predominately\n\nshown to females (85%), while jobs advertised by taxi companies were shown\n\nmainly to males (Bogen 2019). In their field test of how an algorithm delivered ads\n\npromoting job opportunities in the STEM fields, Lambrecht and Tucker (2019)\n\nfound in an empirical-quantitative field test among 191 countries that online job\n\nadvertisements in the science, technology, engineering, and math sector were more\n\nlikely shown to males than females. This gender bias in the delivery of job ads\n\noccurs, because even if the job advertisement should be delivered explicitly gender\n\nneutral, an algorithm that optimizes cost-effectiveness in ad delivery would deliver\n\nads discriminatorily due to crowding out (Lambrecht and Tucker 2019).\n\nPlatforms, such as Google, LinkedIn, and Facebook, offer advertisers the\n\npossibility to target viewers based on sensitive attributes to exclude some job\n\nseekers depending on their attributes (Kim and Scott 2018). For instance, Facebook\n\nlet firms choose among over 100 well-defined attributes (Ali et al. 2019). In this\n\ncase, humans interact and determine the output strategically (intentional discrim-\n\nination). For example, through their selection of personal traits, older potential\n\ncandidates are excluded from seeing the job advertisement. Companies make use of\n\ntargeted ads to attract job seekers who are most likely to have relevant skills, while\n\nrecommender systems can reject a large proportion of applicants (Kim and Scott\n\n2018). Even if companies chose their viewers by relying on attributes that appear to\n\nbe neutral, these attributes can be closely related to protected traits, such as\n\nethnicity, and could allow biased targeting. Often, bias in recommender systems can\n\noccur unintentionally and rely on attributes that are not obvious (Kim and Scott\n\n2018). Kim and Scott (2018) analyzed in an empirical-qualitative paper that due to\n\nspillover effects, it is more costly to serve ads to young females, because women on\n\nFacebook are known to be more likely to click on ads (Kim and Scott 2018). Hence,\n\nBusiness Research (2020) 13:795–848 831\n\n123\n\n\n\nalgorithms that optimize cost efficiency may deliver ads more often to males,\n\nbecause they are less expensive than females (Kim and Scott 2018). In summary,\n\nthese three studies based on non-empirical, empirical-qualitative, and empirical-\n\nquantitative evidence show that historical biases and biases caused by cost-\n\neffectiveness reasons occur in HR recruitment and selection.\n\nWith the help of search engines, recruiters proactively search for candidates who\n\nuse employment services on keywords and filters (Chen et al. 2018). The algorithm\n\nrates applicants; consequently, the recruiter sees and more likely clicks on those at\n\nthe top. These rankings often take demographic features (e.g., name, age, country,\n\nand education level) into account, and this can yield a disadvantage for some\n\ncandidates (Bozdag 2013; Chen et al. 2018). Other features are, for example, the\n\nlocations, previous search keywords, and the recent contacts in a user’s social\n\nnetwork. These service sites do now allow recruiters to filter search results by\n\ndemographics (e.g., gender, age, and ethnicity). Nonetheless, these variables exist\n\nindirectly in other variables, such as years of experience as an indicator of age\n\n(Chen et al. 2018). With the help of statistical tests and data on 855,000 USA job\n\ncandidates (search results for 35 job titles across 20 USA cities), Chen et al. (2018)\n\nrevealed in an empirical-qualitative single case study and review that the search\n\nengines provided by Indeed, Monster, and CareerBuilder discriminate against\n\nfemale candidates to a lesser extent.\n\n5.2 HR selection\n\nStriving for more efficiency due to time and cost pressures and limited resources by\n\nsimultaneously managing a large number of applications are among the main\n\nreasons for the increasing use of algorithmic decision-making in the selection\n\ncontext (Leicht-Deobald et al. 2019). Organizations are increasingly using\n\nalgorithmic decision tools, such as CV and résumé screening, telephone, or video\n\ninterviews, providing an algorithmic evaluation (Lee and Baykal 2017; Mann and\n\nO’Neil 2016) before conducting face-to-face interviews (Chamorro-Premuzic et al.\n\n2016; van Esch et al. 2019).\n\nOne possibility for using algorithmic decision-making in selection is the analysis\n\nof the CV and résumé, with candidates entering their CVs or job preferences online,\n\nand this information is subject to algorithmic analysis (Savage and Bales 2017).\n\nYarger et al. (2019) conceptually analyzed the fairness of talent acquisition software\n\nin the USA and its potential to promote fairness in the selection process for\n\nunderrepresented IT professionals. The authors argue that it is necessary to audit\n\nalgorithms, because they are not neutral. One prominent example is the CV\n\nscreening tool of Amazon, which was trained on biased historical data that led to a\n\npreference for male candidates based on the fact that, in the past, Amazon hired\n\nmore often males as software engineers as females and the algorithm has been\n\ntrained based on these data (historical bias) (Dastin 2018). Yarger et al. (2019)\n\nsuggest removing sources of human bias such as gender, race, ethnicity, religion,\n\nsexual orientation, age, and information that can indicate membership in a protected\n\nclass. Text mining is often the foundation for the screening of CVs and résumés, an\n\napproach to characterize and transform text using the words themselves as the unit\n\n832 Business Research (2020) 13:795–848\n\n123\n\n\n\nof analysis (e.g., the presence or absence of a specific word of interest) (Dreisbach\n\net al. 2019).\n\nBesides words, also certain criteria, such as gender and age, play an important\n\nrole when the training of the algorithm is based on data which has exhibited a\n\npreference for males, females, or younger people in the past. Thus, the algorithm\n\neliminates highly qualified candidates who do not present selected keywords or\n\nphrases or who are of a specific age or gender (Savage and Bales 2017). Applicating\n\nmachine learning and statistical test in an empirical-quantitative setting, Sajjadiani\n\net al. (2019) suggest analyzing and developing interpretable measures that are\n\nintegrated with a substantial body of knowledge already present in the field of\n\nselection and established selection techniques rather than relying on the unique\n\nword application. One example is to pair job titles with job analysts’ rankings of\n\ntask requirements in O*NET to have more valid predictions.\n\nQualifications that cannot be observed through analyzing the résumé can be\n\nanalyzed by means of gamification. Here, applicants take quizzes or play games,\n\nwhich allow an assessment of their qualities, work ethic, problem-solving skills, and\n\nmotivation. Savage and Bales (2017) argue in a non-empirical conceptual paper that\n\nvideo games in initial hiring stages permit a non-discriminatory evaluation of all\n\ncandidates, because it eliminates the human bias, and only the performance in the\n\ngame counts.\n\nAnother application of algorithmic evaluation and widely used by companies is\n\nvideo and telephone analyses (Lee and Baykal 2017). Candidates answer several\n\nquestions via video (HireVue OnDemand 2019) or telephone (Precire 2020;\n\n8andAbove 2020), and their responses are analyzed algorithmically (Guchait et al.\n\n2014). With the help of sensor devices, such as cameras and microphones, human\n\nverbal and nonverbal behavior is captured and analyzed by an algorithm (Langer\n\net al. 2019). AI tools for identifying and managing these spoken texts and facial\n\nexpressions are natural language processing (NLP) and facial expression processing\n\n(FEP). ‘‘[…] NLP is a collection of syntactic and/or semantic rule- or statistical-\n\nbased processing algorithms that can be used to parse, segment, extract, or analyze\n\ntext data’’ (Dreisbach et al. 2019, p. 2). Word counts, topic modeling, and prosodic\n\ninformation, such as pitch intention and pauses, will be extracted by an algorithm,\n\nresulting in the applicant’s personality profile, e.g., Big Five. FEP analyzes facial\n\nexpressions, such as smiles, head gestures, and facial tracking points (Naim et al.\n\n2016).\n\nDuring the asynchronous video interview, applicants record their answers to\n\nspecific questions and upload them to a platform. In the case of telephone\n\ninterviews, the applicant speaks with a virtual agent (Precire 2020). Companies\n\nmake use of ML algorithms to predict which candidate is best suited for a specific\n\njob. For example, HireVue provides a video-based assessment method that uses\n\nNLP and FEP to assess candidates’ stress tolerance, their ability to work in teams, or\n\ntheir willingness to learn. As a result of technological advances, it is now possible to\n\ncreate a complete personal profile. Based on a case study, Raghavan et al. (2020)\n\nanalyzed the claims and practices of companies offering algorithms for employment\n\nassessment and found that the vendors, in general, do not particularly reveal much\n\nabout their practices; thus, there is a lack of transparency in this area.\n\nBusiness Research (2020) 13:795–848 833\n\n123\n\n\n\nTurning the perspective from the employer to the candidates, especially the\n\nperceived fairness of the candidates, plays an essential role in recruitment outcomes\n\n(Gilliland 1993). Using a between-subject online experiment, Lee (2018) discovered\n\nthat people perceive human decisions to be fairer than algorithmic decisions in\n\nhiring tasks. People think that the algorithm lacks the ability to discern\n\nsuitable applicants, because the algorithm makes judgments based on keywords\n\nand does not take qualities that are hard to quantify into account. Participants do not\n\ntrust the algorithm, because it lacks human judgment and human intuition.\n\nContrasting findings are found in Suen et al.’s (2019) empirical-quantitative study\n\ncomparing synchronous videos to asynchronous videos analyzed by means of an AI;\n\nthey conclude that the videos analyzed by means of an AI did not negatively\n\ninfluence perceived fairness in their Chinese sample.\n\nUnlike the other studies, in an online experiment, Kaibel et al. (2019) recently\n\nanalyzed the perceived fairness of two different algorithmic decision tools, namely\n\ninitial screening and digital interviews. Results show that algorithmic decision-\n\nmaking negatively affects personableness and the opportunity to perform during the\n\nselection process, but it does not affect the perceived consistency. These\n\nrelationships are moderated by personal uniqueness and experienced discrimination.\n\n5.3 HR development\n\nResearch on fairness of algorithmic decision-making and HR development is still in\n\nits infancy, since most existing studies focus on the fairness of the recruitment\n\nprocess.\n\nCompanies increasingly rely on algorithmic decision-making to quantify and\n\nmonitor their employees (Leicht-Deobald et al. 2019). Personal records and internal\n\nperformance evaluation are documented in firm systems. Identifying knowledge and\n\nskills is a major aim of algorithmic decision-making in HR development (Simbeck\n\n2019). Other goals are workforce forecasts (retention, leaves) and comprehension of\n\nemployee’s satisfaction indicators (Simbeck 2019; Silverman and Waller 2015).\n\nTypical data stored in HR information systems include information about the\n\nemployees hired, the employee’s pay and benefits, hours worked, and sometimes\n\nvarious performance-related measures (Leicht-Deobald et al. 2019). Personal data,\n\nsuch as the number and age of children, marital status, and health information, are\n\noften available for the HR function (Simbeck 2019). Companies that offer employee\n\nengagement analytics, performance measurement, and benchmarking include, for\n\nexample, IBM (Watson Talent Insights), SAP (Success Factors People Analytics),\n\nand Microsoft (Office 365 Workplace Analytics). These algorithmic decision tools\n\noffer opportunities to organize the employee’s performance more effectively, but\n\nthey also associated with certain risks. Since HR development is about assessing and\n\nimproving the performance of the employees by applying algorithmic decision-\n\nmaking, there are several overlaps with HR recruitment. While HR recruitment\n\nfocuses on predicting the performance of candidates, HR development focuses on\n\ndeveloping existing employees and talents. Nevertheless, the tools used are quite\n\nsimilar.\n\n834 Business Research (2020) 13:795–848\n\n123\n\n\n\nOne of the methods that is used is data profiling, which is a special use of data\n\nmanagement. It aims to discover the meaningful features of data sets. The company\n\nis provided with a broad picture of the data structure, content, and relationships\n\n(Persson 2016). One company, for example, observed that the distance between the\n\nworkplace and home is a strong predictor of job tenure. If a hiring algorithm relied\n\non this aspect, discrimination based on residence occurs (Kim 2016). Additionally,\n\nNLP is also used in the HR development. To identify skills and to support career\n\npaths, some companies conduct interviews with their employees to create a\n\npsychological profile (e.g., personality or cognitive ability) (Chamorro-Premuzic\n\net al. 2016).\n\nAnother approach is evaluation. For example, Rosenblat and Stark (2016)\n\nexamined in a case study the evaluation platform of the American passenger\n\ntransport mediation service company Uber and found that discrimination exists in\n\nthe evaluation of drivers. Uber tracks employees’ GPS positions and has\n\nacceleration sensors integrated into the driver’s version of the Uber app to detect\n\nheavy braking and speeding (Prassl 2018). Females are paid less than males,\n\nbecause they drive slower. Consequently, the algorithm calculates a lower salary\n\ndue to slower driving for the same route.\n\nTo evaluate and promote employees, organizations increasingly rely on\n\nrecommender systems. For example, IBM offers IBM Watson Career Coach,\n\nwhich is a career management solution that advises employees about online and\n\noffline training based on their current job and previous jobs within the company and\n\nbased on the experiences of similar employees (IBM 2020). The pitfalls with respect\n\nto recommender systems, as mentioned earlier, also apply in the development.\n\nRegarding the perceived fairness, in an empirical-quantitative online experiment\n\nLee (2018) analyzed the fairness perception of managerial decisions (using a\n\ncustomer service call center that uses NLP to evaluate the performance), whereby\n\nthe decision-maker was manipulated. Performance evaluations carried out by an\n\nalgorithm are less likely to be perceived as fair and trustworthy, and at the same\n\ntime, they evoke more negative feelings than human decisions.\n\n6 Discussion\n\nThis paper aimed at raising awareness of the potential problems regarding\n\ndiscrimination, bias, and unfairness of algorithmic decision-making in two\n\nimportant HR functions dealing with an assessment of individuals, their potential,\n\nand their fit to the organization. While previous research highlighted the\n\norganizational advantages of algorithmic decision-making, including cost savings\n\nand increased efficiency, the possible downsides in terms of biases, discrimination,\n\nand perceived unfairness have found little attention in HRM, although these issues\n\nare well known in other research areas. By linking these research areas with HR\n\nrecruitment and HR development and identifying important research gaps, we offer\n\nfruitful directions for future research by highlighting areas where more empirical\n\nevidence is needed. Consequently, a major finding that emerges from our literature\n\nBusiness Research (2020) 13:795–848 835\n\n123\n\n\n\nreview is the need for more quantitative research on the potential pitfalls of\n\nalgorithmic decision-making in the field of HRM.\n\nCompanies implement algorithmic decision-making to avoid or even overcome\n\nhuman biases. However, our systematic literature review shows that algorithmic\n\ndecision-making is not a panacea for eliminating biases. Algorithms are vulnerable\n\nto biases in terms of gender, ethnicity, sexual orientation, or other characteristics if\n\nthe algorithm builds upon inaccurate, biased, or unrepresentative input and training\n\ndata (Kim 2016). Algorithms replicate biases if the input data are already biased.\n\nConsequently, there is a need for transparency; employees and candidates should\n\nhave the possibility to understand what happens within the process (Lepri et al.\n\n2018).\n\nMoreover, organizations need to consider the perceived fairness of employees\n\nand applicants when using algorithmic decision-making in HR recruitment and HR\n\ndevelopment. For companies, it is difficult to satisfy both computational fairness\n\nfrom the computer science, which is defined by rules and formulas, and perceived\n\nfairness from the management literature that is subjectively felt by potential and\n\ncurrent employees. To fulfill procedural justice and distributive justice, it is\n\nimportant for organizations to reduce or avoid all types of biases and to achieve\n\nsubjective fairness, such as individual fairness, group fairness (Dwork et al. 2012),\n\nand equal opportunity (Hardt et al. 2016). Companies need to continuously enhance\n\nthe perceived fairness of their HR recruitment and selection and HR training and\n\ndevelopment process to avoid adverse impacts on the organization, such as\n\ndiminishing employer attractiveness, employer image, task performance, motiva-\n\ntion, and satisfaction with the processes (Cropanzano et al. 2007; Cohen-Charash\n\nand Spector 2001; Gilliland 1993).\n\nWith regard to fairness perceptions, it appears to be beneficial that humans make\n\nthe final decision if the decision is about the potential of employees or career\n\ndevelopment (Lee 2018). At first glance, this partially contradicts previous findings\n\nthat the automated evaluation seems to be more valid, since human raters may\n\nevaluate candidates inconsistently or without proper evidence (Kuncel et al. 2013;\n\nWoods et al. 2020). However, while people accept that an algorithmic system\n\nperforms mechanical tasks (e.g., work scheduling), human tasks (e.g., hiring, work\n\nevaluation) should be performed by humans (Lee 2018). Reasons for the lower\n\nacceptance of algorithms in judging people and their potential are multifaceted. The\n\nusage of this new technology in HRM, combined with a lack of knowledge and\n\ntransparency about how the algorithms work, increases emotional creepiness (e.g.,\n\nLanger et al. 2019; Langer and König 2018) and decreases interpersonal treatment\n\nand social interactions (e.g., Lee 2018) as well as fairness perceptions and the\n\nopportunity to perform (e.g., Kaibel et al. 2019). To overcome these adverse\n\nimpacts of algorithmic decision-making in HRM, companies need to promote their\n\nusage of algorithms (van Esch et al. 2019) and make the processes more transparent\n\nof how algorithms are supporting the decisions of humans (Tambe et al. 2019). This\n\nmight help to create HR systems in recruitment and career development that are\n\nboth valid and perceived as fair. Nevertheless, a fruitful research avenue could be to\n\nexamine how companies should communicate or promote their usage of algorithms\n\n836 Business Research (2020) 13:795–848\n\n123\n\n\n\nand whether employees and applicants accept a certain degree of algorithmic aid in\n\nhuman decision-making.\n\nIn summary, companies should not solely rely on the information provided by\n\nalgorithms or even implement automatic decision-making without any control or\n\nauditing by humans. While some biases might be more apparent, implicit\n\ndiscrimination of less apparent personal characteristics might be more problematic,\n\nbecause such implicit biases are more difficult to detect. In the following, we outline\n\ntheoretical and practical implications as well as future research directions.\n\n6.1 Theoretical implications and future research directions\n\nThis review reveals that current knowledge on the possible pitfalls of algorithmic\n\ndecision-making in HRM is still in an early stage, although we recently identified\n\nincreased attention to fairness and discrimination. Thus, the question arises about\n\nwhat the most important future research priorities are (see Table 4 for exemplary\n\nresearch questions). The majority of studies which we found concerning fairness\n\nand discrimination were non-empirical. One reason for the paucity of empirical\n\nresearch could be that algorithmic decision-making is a recent phenomenon in the\n\nfield of HR recruitment and HR development, which has not yet received much\n\nattention from management scholars. Consequently, there is a need for more\n\nsophisticated, theoretically, quantitative studies, especially in HR recruitment and\n\nHR development, but also in HR selection. In this regard, a closer look reveals that\n\nthe majority of current research focuses on HR selection. However, also for HR\n\nselection, only one or two studies per tool addressed fairness or perceived fairness.\n\nIn contrast, fairness perceptions and biases in HR recruitment and HR development\n\nreceive little attention (see Table 3).\n\nThe discussion on what leads to discrimination and its avoidance seems to be a\n\nfruitful research avenue. Notably, the different types of algorithmic bias (see\n\nSect. 2.2) that can lead to (implicit) discrimination and unfairness need to be\n\nconsidered separately. The existing studies mainly discuss bias, unfairness, and\n\ndiscrimination in general, but rarely delve into detail by studying what kind of bias\n\noccurred (e.g., historical bias or technical bias). Similarly, several studies\n\ndistinguished between mathematical fairness and perceived fairness, but did not\n\ntake a closer look at individual fairness, group fairness, or equal opportunity (see\n\nSect. 2.3).\n\nAnother prospective research area focuses on the difference in reliability and\n\nvalidity between AI decision-makers and human raters (Suen et al. 2019). Many\n\nstudies found that an algorithm could be discriminatory, but the question remains\n\nwhether algorithms are fairer than humans are. However, this is important to address\n\nto achieve the fairest possible decision-making process.\n\nAnother research avenue for new tools in HR recruitment and HR development\n\nfocuses on the individuals’ perspective and acceptance of algorithmic decision-\n\nmaking. Only a few studies have examined the subjective fairness perceptions of\n\nalgorithmic decision-making in the HRM context. Thus, the way employees and\n\napplicants perceive decisions made by an algorithm instead of humans is not fully\n\nexploited (Lee 2018). In HR selection, a few studies have analyzed the perceived\n\nBusiness Research (2020) 13:795–848 837\n\n123\n\n\n\nfairness. However, our systematic review underlines the recent calls by Hiemstra\n\net al. (2019) and Langer et al. (2018) for additional research to fully understand the\n\nemotions and reactions of candidates and talented employees when using\n\nalgorithmic decision-making in HR recruitment or HR development processes.\n\nEmotions and reactions can have important negative consequences for organiza-\n\ntions, such as withdrawal from the application process or job turnover (Anderson\n\n2003; Ryan and Ployhart 2000). In general, knowledge about applicants’ reactions\n\nwhen using algorithmic decision-making is still limited (van Esch et al. 2019).\n\nPrevious studies analyzed a single algorithmic decision tool [see Kaibel et al. (2019)\n\nfor a recent exception]. Consequently, there is a need to examine applicants’\n\nacceptance of algorithmic decision-making within the steps of the recruitment and\n\nselection process (e.g., media content and recruitment tools on the employer’s\n\nwebpage, recommender systems in social media, screening and preselection,\n\ntelephone interview, and video interview).\n\nAlthough there is some evidence that candidates react negatively to a decision\n\nmade by an algorithm (i.e., Kaibel et al. 2019; Ötting and Maier 2018; Lee 2018),\n\nmore research is needed on individuals’ acceptance of algorithms if algorithms\n\nsupport the decisions by humans. Moreover, additional insights are needed into\n\nwhether transparency and more information about the algorithmic decision-making\n\nprocess positively influences the fairness perception (Hiemstra et al. 2019). Finally,\n\nwhile we found many studies examining the fairness perception of applicants (i.e.,\n\npotential employees), the perspective of current employees on algorithmic decision-\n\nmaking is still neglected in HRM research. Besides the threat of job loss due to\n\ndigitalization and automation, the question of how algorithms might help to assess,\n\npromote, and retain qualified and talented employees remains important and will\n\nbecome more important in the next decade. Thus, fairness and biases perceived by\n\ncurrent employees offer yet another fruitful research avenue in HR development.\n\n6.2 Practical implications\n\nGiven that in many companies, the HR function has the main responsibility for\n\ncurrent and potential employees, our literature review shows that HR managers need\n\nto be careful about implementing algorithmic decision-making, respecting privacy\n\nand fairness concerns, and monitoring and auditing the algorithms that are used\n\n(Simbeck 2019). This is accompanied by an obligation to inform employees and\n\napplicants about the usage of the data and the potential consequences, for example,\n\nforecasting career opportunities. Since the implementation of algorithmic decision-\n\nmaking in HRM is a social process, employees should actively participate in this\n\nprocess (Leicht-Deobald et al. 2019; Friedman et al. 2013; Tambe et al. 2019).\n\nMoreover, applicants and employees must have the opportunity to not agree with\n\nthe proceedings (Simbeck 2019). A first step would be to implement company\n\nguidelines for the execution and auditing of algorithmic decision-making and\n\ntransparent communication about data usage (Simbeck 2019; Cheng and Hackett\n\n2019).\n\nIf companies implement an algorithm, the responsibility, accountability, and\n\ntransparency need to be clarified in advance. Members of the company need to have\n\n838 Business Research (2020) 13:795–848\n\n123\n\n\n\nsufficient expertise and a sophisticated understanding of the tools to meet the\n\nchallenges that the implementation of algorithmic decision-making might face\n\n(Barocas and Selbst 2016; Cheng and Hackett 2019; Canhoto and Clear 2020).\n\nWhen using algorithmic decision-making tools, there is an immediate need for\n\ntransparency and accountability (Tambe et al. 2019). Concerning transparency, this\n\nmeans generating an understanding of how the algorithm operates (e.g., how the\n\nalgorithm uses data and weighs specific criteria) and disclosing the conditions for\n\nthe algorithmic decision. Transparency comes along with interpretability and\n\nexplainability; that is, how the algorithm interacts with the specific data and how it\n\noperates in a specific context. Therefore, domain knowledge and knowledge about\n\nthe programming are indispensable (see Sect. 2.2). Finally, accountability is the\n\nacceptance of the responsibility for actions and decisions supported or conducted by\n\nalgorithms. Companies should clearly define humans responsible for using the\n\nalgorithmic decision-making tool (Lepri et al. 2018).\n\nFurthermore, HR practitioners must consider the consequences of algorithmic\n\ndecision-making and be aware that there may be a bias in the training data, because\n\nthis is often a reflection of existing stereotypes (Mann and O’Neil 2016). As a first\n\nstep, the company needs to define fairness standards (Canhoto and Clear 2020),\n\nbecause algorithms cannot meet all mathematical and social fairness measures\n\nsimultaneously. Therefore, the algorithms’ vulnerabilities need to be identified to\n\ncorrect mistakes and improve the algorithms (Lindebaum et al. 2019). Additionally,\n\norganizations should write down the exact procedure for the sake of transparency.\n\nCompanies should also seek to achieve the best quality of input data and continuous\n\nupdate of the used data (Persson 2016). Companies should avoid biased training\n\ndata (avoiding historical bias) or that certain groups or personal characteristics of\n\ninterest are underrepresented (avoiding representation bias). Most data sets profit\n\nfrom the renewal of the data to test if the statistical patterns and relationships are\n\nstill accurate. Notably, in the HRM context, the dynamic nature of personal\n\ndevelopment needs to be considered, since employees develop and change over time\n\n(Simbeck 2019). Thus, it is important to verify and audit the whole process on a\n\nregular basis (Kim 2016). Companies should implement a data quality control\n\nprocess to develop quality metrics, collect new data, evaluate data quality, and\n\nremove inaccurate data from the training data set. For example, for CV and résumé\n\nscreening, companies could apply blind hiring, which means removing personally\n\nidentifiable information on the documents (Yarger et al. 2019; Raghavan et al.\n\n2020).\n\nIf the companies use algorithms provided by an external service provider, the\n\nalgorithms’ code and training data are not transparent for the companies (Raghavan\n\net al. 2020; Sánchez-Monedero et al. 2020). Following the company’s standards\n\nmentioned above, HR managers should try to get detailed information about the data\n\nsets, the codes, and the procedures and measures of the service provider to prevent\n\nbiases. Furthermore, HR managers should discuss multiple options that can reduce\n\nbias, such as weighing or removing certain indicators that highly correlate with\n\nattributes (Yarger et al. 2019).\n\nDue to the lack of intuition and subjective judgment skills when an algorithm\n\ndecides about a human, employees perceive the decision made by an algorithm as\n\nBusiness Research (2020) 13:795–848 839\n\n123\n\n\n\nless fair and trustworthy (Lee 2018). Moreover, pure algorithmic decisions evoke\n\nnegative feelings (Lee 2018). An implication to prevent anger among the applicants\n\nor employees is a disclosure of the nature of the decision made by an algorithm\n\n(Cheng and Hackett 2019). A short-term solution to avoid a decrease in the\n\nacceptance could be a balanced approach between algorithmic and human decision-\n\nmaking, which means that the algorithm makes a suggestion, but a human checks or\n\neven makes the final decision. Hence, algorithmic decision-making seems to be an\n\nindispensable tool for assistance in the decision, but human expertise is still\n\nnecessary (Yarger et al. 2019).\n\nOf course, these practical implications are not limited to HR recruitment and HR\n\ndevelopment; other HR functions might benefit from these insights, as well. In other\n\nHR functions, employees should be informed and, if possible, involved in the\n\nalgorithms or AI’s implementation process. Responsibilities and accountability\n\nshould be clarified in advance, privacy should be respected, and the possibility for\n\nemployee voice should be acknowledged. Moreover, they should seek adequate\n\ninput data and implement data quality checks, which goes along with updating the\n\ndata regularly. If an external provider is in charge of programming and providing\n\nthe algorithm, the data and the algorithm should be adapted to the company and\n\nshould not be adopted without knowing the input data, the conditions for the\n\nalgorithmic outcomes, and the potential pitfalls of the algorithms.\n\n7 Conclusion\n\nThis paper aimed at reviewing current research on algorithmic decision-making in\n\nthe HRM context, highlighting ethical issues related to algorithms, and outlining\n\nimplications for future research. The article contributes to a better understanding of\n\nthe existent research field and summarizes the existing evidence and future research\n\navenues in the highly important topic of algorithmic decision-making. Undoubtedly,\n\nthe existing studies advanced our understanding of how companies use algorithmic\n\ndecision-making in HR recruitment and HR development, when, and why unfairness\n\nor biases occur in algorithmic decision-making. However, our review suggests that\n\nthe ongoing debates in computer science on fairness and potential discrimination of\n\nalgorithms require more attention in leading management journals. Since organi-\n\nzations increasingly implement algorithmic decision tools to minimize human bias,\n\nsave costs, and automate their processes, our review shows that algorithms are not\n\nneutral or free of biases, because a computer has generated a certain decision.\n\nHumans should still play a critical and important role in the good governance of\n\nalgorithmic decision-making.\n\nAcknowledgements We thank Maike Giefers, Hannah Kaiser, and Anna Nieter, and Shirin Riazy for\n\ntheir support.\n\nFunding Not applicable for that section.\n\nData availability All material is available upon request.\n\n840 Business Research (2020) 13:795–848\n\n123\n\n\n\nCompliance with ethical standards\n\nConflict of interest The authors declare that they have no conflict of interest.\n\nOpen Access This article is licensed under a Creative Commons Attribution 4.0 International License,\n\nwhich permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as\n\nyou give appropriate credit to the original author(s) and the source, provide a link to the Creative\n\nCommons licence, and indicate if changes were made. The images or other third party material in this\n\narticle are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line\n\nto the material. If material is not included in the article’s Creative Commons licence and your intended\n\nuse is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain\n\npermission directly from the copyright holder. To view a copy of this licence, visit http://\n\ncreativecommons.org/licenses/by/4.0/.\n\nAppendix\n\nList of employed keywords\n\nAlgorithm\n\n– Algorithm*\n\n– ‘‘Algorithmic model*’’\n\n– ‘‘Data-algorithm*’’\n\n– ‘‘Algorithmic decision-making’’, ‘‘algorithmic decision*’’\n\n– ‘‘Artificial intelligence’’\n\n– ‘‘Facial expression tool*’’, ‘‘facial expression processing*’’\n\n– ‘‘Language processing*’’, ‘‘natural language processing*’’\n\n– ‘‘Recommender system*’’\n\n– ‘‘Search engine*’’\n\nDiscrimination\n\n– Discrimination*\n\n– Discriminat*\n\n– Classification*, ‘‘classification problem*’’, ‘‘classification scheme*’’\n\n– ‘‘Algorithmic discrimination*’’, ‘‘algorithmic bias discrimination*’’\n\n– ‘‘Preventing discrimination*’’\n\n– Anti-discrimination*, non-discrimination*\n\n– Gender, age, sex, sexism, origin\n\n– ‘‘Gender-based inequalities’’\n\n– ‘‘Difference* among demographic group*’’\n\n– Ethic*, ‘‘ethical implication*’’\n\n– ‘‘Data mining discrimination*’’\n\n– Favoritism, favouritism\n\n– ‘‘Unfair treatment*’’\n\nBusiness Research (2020) 13:795–848 841\n\n123\n\nhttp://creativecommons.org/licenses/by/4.0/\nhttp://creativecommons.org/licenses/by/4.0/\n\n\nFairness\n\n– Fair*, unfair*\n\n– ‘‘Perceived fairness’’, ‘‘algorithmic fairness’’\n\n– ‘‘Fairness word*’’, ‘‘fairness speech*’’, ‘‘fairness recommendation*’’\n\n– Equal*, equit*, inequal*, ‘‘equal opportunit*’’\n\n– Transparen*\n\n– Legal*, right*\n\n– Truth\n\n– Impartial*\n\n– Correct*\n\n– Justicea\n\n– Adverse impacta\n\nEvaluation\n\n– Evaluat*\n\n– Judgement*, ‘‘algorithmic judgement*’’, ‘‘human judgement*’’, ‘‘mechanical\n\njudgement*’’\n\n– Rank*\n\n– Rate*\n\n– Measure*\n\n– Valuation*\n\nBias\n\n– Bias*\n\n– ‘‘Algorithmic bias*’’, ‘‘national bias*’’, gender-bias*, ‘‘decision-making bias*’’,\n\n‘‘human bias*’’, ‘‘technical bias*’’\n\n– ‘‘Implicit bias* in algorithm*’’\n\n– ‘‘Dealing with bias*’’\n\n– ‘‘Pattern distortion*’’\n\n– Pre-justice*\n\n– Preconception*\n\n– Tendenc*\n\n– Prone*\n\nData mining\n\n– Data*\n\n– ‘‘Data set*’’\n\n842 Business Research (2020) 13:795–848\n\n123\n\n\n\nHRM\n\n– ‘‘Human Resource*’’, ‘‘Human Resource Management’’\n\n– Management\n\n– ‘‘Applicant selection*’’, ‘‘employee selection*’’\n\n– ‘‘Algorithm-based HR decision-making’’\n\n– ‘‘Recruitment process*’’, ‘‘application process*’’, ‘‘selection process*’’\n\n– Recruitment*, online-recruitment*\n\n– ‘‘Personnel decision*’’, ‘‘personnel selection*’’\n\n– ‘‘People analytic*’’, ‘‘HR analytic*’’\n\n– ‘‘Job advertisement*’’\n\n– ‘‘Online personalization*’’\n\naRobustness check.\n\nReferences\n\n8andAbove. 2020. https://www.8andabove.com. Accessed 28 Feb 2020.\n\nAli, Muhammad, Piotr Sapiezynski, Miranda Bogen, Aleksandra Korolova, Alan Mislove, and Aaron\n\nRieke. 2019. Discrimination through optimization: how Facebook’s ad delivery can lead to skewed\n\noutcomes. arXiv preprint arXiv:1904.02095.\nAnderson, Neil. 2003. Applicant and recruiter reactions to new technology in selection: a critical review\n\nand agenda for future research. International Journal of Selection and Assessment 11 (2–3):\n\n121–136.\n\nArrow, Kenneth. 1973. The theory of discrimination. Discrimination in Labor Markets 3 (10): 3–33.\n\nBarfield, Woodrow, and Ugo Pagallo. 2018. Research handbook on the law of artificial intelligence.\nCheltenham: Edward Elgar Publishing.\n\nBarocas, Solon, and Andrew D. Selbst. 2016. Big data’s disparate impact. California Law Review 104:\n\n671.\n\nBauer, Talya N., Donald M. Truxillo, Rudolph J. Sanchez, Jane M. Craig, Philip Ferrara, and Michael A.\n\nCampion. 2001. Applicant reactions to selection: development of the selection procedural justice\n\nscale (SPJS). Personnel Psychology 54 (2): 387–419.\n\nBengio, Yoshua, Ian Goodfellow, and Aaron Courville. 2017. Deep learning. Cambridge: MIT press.\n\nBertrand, Marianne, Dolly Chugh, and Sendhil Mullainathan. 2005. Implicit discrimination. American\nEconomic Review 95 (2): 94–98.\n\nBobko, Philip, and C.J. Bartlett. 1978. Subgroup validities: differential definitions and differential\n\nprediction. Journal of Applied Psychology 63: 12–14.\n\nBogen, Miranda. 2019. All the ways hiring algorithms can introduce bias. Harvard Business Review, May\n6. https://hbr.org/2019/05/all-the-ways-hiring-algorithms-can-introduce-bias.\n\nBozdag, Engin. 2013. Bias in algorithmic filtering and personalization. Ethics and Information\nTechnology 15 (3): 209–227.\n\nBurdon, Mark, and Paul Harpur. 2014. Re-conceptualising privacy and discrimination in an age of talent\n\nanalytics. UNSWLJ 37:679.\n\nBurke, Robin, Nasim Sonboli, and Aldo Ordonez-Gauger. 2018. Balanced neighborhoods for multi-sided\n\nfairness in recommendation. In Conference on fairness, accountability and transparency. http://\nproceedings.mlr.press.\n\nCanhoto, Ana Isabel, and Fintan Clear. 2020. Artificial intelligence and machine learning as business\n\ntools: a framework for diagnosing value destruction potential. Business Horizons 63 (2): 183–193.\n\nCappelli, Peter. 2019. Data science can’t fix hiring (yet). Harvard Business Review 97 (3): 56–57.\n\nCappelli, Peter, Prasanna Tambe, and Valery Yakubovich. 2020. Can data science change human\n\nresources? In The future of management in an AI world, Berlin: Springer: 93–115.\n\nBusiness Research (2020) 13:795–848 843\n\n123\n\nhttps://www.8andabove.com\nhttps://hbr.org/2019/05/all-the-ways-hiring-algorithms-can-introduce-bias\nhttp://proceedings.mlr.press\nhttp://proceedings.mlr.press\n\n\nCarey, Dennis, and Matt Smith. 2016. How companies are using simulations, competitions, and analytics\n\nto hire. Harvard Business Review. https://hbr.org/2016/04/how-companies-are-using-simulations-\n\ncompetitions-and-analytics-to-hire.\n\nCascio, Wayne F., and Herman Aguinis. 2013. Applied psychology in human resource management.\nLondon: Pearson Education.\n\nChalfin, Aaron, Oren Danieli, Andrew Hillis, Zubin Jelveh, Michael Luca, Jens Ludwig, and Sendhil\n\nMullainathan. 2016. Productivity and selection of human capital with machine learning. American\nEconomic Review 106 (5): 124–127.\n\nChamorro-Premuzic, Tomas, Dave Winsborough, Ryne A. Sherman, and Robert Hogan. 2016. New talent\n\nsignals: shiny new objects or a brave new world? Industrial and Organizational Psychology 9 (3):\n\n621–640.\n\nChamorro-Premuzic, Tomas, Reece Akhtar, Dave Winsborough, Ryne A Sherman. 2017. The datafication\n\nof talent: how technology is advancing the science of human potential at work. Current Opinion in\nBehavioral Sciences 18:13–16.\n\nChander, Anupam. 2016. The racist algorithm. Michigan Law Review 115: 1023.\n\nChen, Le, Ruijun Ma, Anikó Hannák, and Christo Wilson. 2018. Investigating the impact of gender on\n\nrank in resume search engines. In Proceedings of the 2018 chi conference on human factors in\ncomputing systems: 1–14. https://doi.org/10.1016/j.hrmr.2019.100698.\n\nCheng, Maggie M., and Rick D. Hackett. 2019. A critical review of algorithms in HRM: definition,\n\ntheory, and practice. Human Resource Management Review 100698.\n\nCitron, Danielle Keats, and Frank Pasquale. 2014. The scored society: due process for automated\n\npredictions. Washington Law Review 89: 1.\n\nCohen-Charash, Yochi, and Paul E. Spector. 2001. The role of justice in organizations: a meta-analysis.\n\nOrganizational Behavior and Human Decision Processes 86 (2): 278–321.\n\nCropanzano, Russell, David E. Bowen, and Stephen W. Gilliland. 2007. The management of\n\norganizational justice. Academy of Management Perspectives 21 (4): 34–48.\n\nCrossan, Mary M., and Marina Apaydin. 2010. A multi-dimensional framework of organizational\n\ninnovation: a systematic review of the literature. Journal of Management Studies 47 (6): 1154–1191.\nDanks, David, and Alex John London. 2017. Algorithmic bias in autonomous systems. In IJCAI: 4691-\n\n4697.\nDastin, Jeffrey. 2018. Amazon scraps secret AI recruiting tool that showed bias against women. San\n\nFransico: Reuters.\n\nDatta, Amit, Michael Carl Tschantz, and Anupam Datta. 2015. Automated experiments on ad privacy\n\nsettings. Proceedings on Privacy Enhancing Technologies 2015 (1): 92–112.\n\nDaugherty, Paul R., and H.J. Wilson. 2018. Human? machine: reimagining work in the age of AI.\nBoston: Harvard Business Press.\n\nDeloitte. 2018. Mensch bleibt Mensch - auch mit algorithmen im recruiting. Wo der Einsatz von\n\nAlgorithmen hilfreich ist und wo nicht. https://www2.deloitte.com/de/de/pages/careers/articles/\n\nalgorithmen-im-recruiting-prozess.html. Accessed 12 Sept 2019.\n\nDeloitte. 2020. State of AI in the enterprise – 3rd edition results of the survey of 200 AI experts on\n\nartificial intelligence in German companies. https://www2.deloitte.com/content/dam/Deloitte/de/\n\nDocuments/technology-media-telecommunications/DELO-6418_State%20of%20AI%202020_KS4.\n\npdf. Accessed 10 Jun 2020.\n\nDeng, Li., and Yu. Dong. 2014. Deep learning: methods and applications. Foundations and Trends� in\nSignal Processing 7 (3–4): 197–387.\n\nDiakopoulos, Nicholas. 2015. Algorithmic accountability: journalistic investigation of computational\n\npower structures. Digital Journalism 3 (3): 398–415.\n\nDreisbach, Caitlin, Theresa A. Koleck, Philip E. Bourne, Suzanne Bakken. 2019. A systematic review of\n\nnatural language processing and text mining of symptoms from electronic patient-authored text data.\n\nInternational Journal of Medical Informatics 125:37–46.\nDwork, Cynthia, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Richard Zemel. 2012. Fairness\n\nthrough awareness. In Proceedings of the 3rd innovations in theoretical computer science\nconference: ACM: 214–226.\n\nFerguson, Christopher J., and Michael T. Brannick. 2012. Publication bias in psychological science:\n\nprevalence, methods for identifying and controlling, and implications for the use of meta-analyses.\n\nPsychological Methods 17 (1): 120.\n\n844 Business Research (2020) 13:795–848\n\n123\n\nhttps://hbr.org/2016/04/how-companies-are-using-simulations-competitions-and-analytics-to-hire\nhttps://hbr.org/2016/04/how-companies-are-using-simulations-competitions-and-analytics-to-hire\nhttps://doi.org/10.1016/j.hrmr.2019.100698\nhttps://www2.deloitte.com/de/de/pages/careers/articles/algorithmen-im-recruiting-prozess.html\nhttps://www2.deloitte.com/de/de/pages/careers/articles/algorithmen-im-recruiting-prozess.html\nhttps://www2.deloitte.com/content/dam/Deloitte/de/Documents/technology-media-telecommunications/DELO-6418_State%20of%20AI%202020_KS4.pdf\nhttps://www2.deloitte.com/content/dam/Deloitte/de/Documents/technology-media-telecommunications/DELO-6418_State%20of%20AI%202020_KS4.pdf\nhttps://www2.deloitte.com/content/dam/Deloitte/de/Documents/technology-media-telecommunications/DELO-6418_State%20of%20AI%202020_KS4.pdf\n\n\nFlorentine, S. 2016. How artificial intelligence can eliminate bias in hiring. CIO Magazine. https://www.\ncio.com/article/3152798/artificial-intelligence/how-artificial-intelligence-can-eliminate-bias-in-\n\nhiring.html. Accessed 03 Mar 2020.\n\nFriedman, Batya, and Helen Nissenbaum. 1996. Bias in computer systems. ACM Transactions on\nInformation Systems 14 (3): 330–347.\n\nFriedman, Batya, Peter H. Kahn, Alan Borning, and Alina Huldtgren. 2013. Value sensitive design and\n\ninformation systems. In Early engagement and new technologies: opening up the laboratory,\nDodrecht: Springer: 27–55.\n\nFrijters, Paul. 1998. Discrimination and job-uncertainty. Journal of Economic Behavior & Organization\n36 (4): 433–446.\n\nGil-Lafuente, Anna Marı́a, and Young Kyun Oh. 2012. Decision making to manage the optimal selection\n\nof personnel in the hotel company applying the hungarian algorithm. The International Journal of\nManagement Science and Information Technology 6-(Oct-Dec): 27–42.\n\nGilliland, Stephen W. 1993. The perceived fairness of selection systems: an organizational justice\n\nperspective. Academy of Management Review 18 (4): 694–734.\n\nGoodfellow, Ian, Y. Bengio, and A. Courville. 2016. Machine learning basics. Deep Learning 1: 98–164.\n\nGough, David, Sandy Oliver, and James Thomas. 2017. An introduction to systematic reviews. London:\nSage.\n\nGuchait, Priyanko, Tanya Ruetzler, Jim Taylor, and Nicole Toldi. 2014. Video interviewing: a potential\n\nselection tool for hospitality managers–a study to understand applicant perspective. International\nJournal of Hospitality Management 36: 90–100.\n\nHardt, Moritz, Eric Price, and Nati Srebro. 2016. Equality of opportunity in supervised learning. In\n\nAdvances in neural information processing systems: 3315–3323.\nHausknecht, John P., David V. Day, and Scott C. Thomas. 2004. Applicant reactions to selection\n\nprocedures: an updated model and meta-analysis. Personnel Psychology 57 (3): 639–683.\n\nHireVue. 2019. https://www.hirevue.com. Accessed 01.Jan 2020.\n\nHiemstra, Annemarie MF., Janneke K. Oostrom, Eva Derous, Alec W. Serlie, and Marise Ph Born. 2019.\n\nApplicant perceptions of initial job candidate screening with asynchronous job interviews: does\n\npersonality matter? Journal of Personnel Psychology 18 (3): 138.\n\nHoffmann, Anna Lauren. 2019. Where fairness fails: data, algorithms, and the limits of antidiscrimination\n\ndiscourse. Information, Communication & Society 22 (7): 900–915.\n\nHorton, John J. 2017. The effects of algorithmic labor market recommendations: Evidence from a field\n\nexperiment. Journal of Labor Economics 35 (2): 345–385.\n\nHuselid, Mark A. 1995. The impact of human resource management practices on turnover, productivity,\n\nand corporate financial performance. Academy of Management Journal 38 (3): 635–672.\n\nIBM. 2020. IBM Watson Career Coach for career management. https://www.ibm.com/talent-\n\nmanagement/career-coach. Accessed 20 Apr 2020.\n\nKaelbling, Leslie Pack, Michael L. Littman, and Andrew W. Moore. 1996. Reinforcement learning: a\n\nsurvey. Journal of Artificial Intelligence Research 4: 237–285.\n\nKahneman, Daniel, Stewart Paul Slovic, Paul Slovic, and Amos Tversky. 1982. Judgment under\nuncertainty: heuristics and biases. Cambridge: Cambridge University Press.\n\nKaibel, Chris, Irmela Koch-Bayram, Torsten Biemann, and Max Mühlenbock. 2019. Applicant\n\nperceptions of hiring algorithms-uniqueness and discrimination experiences as moderators. In\n\nAcademy of Management Proceedings: Academy of Management Briarcliff Manor, NY 10510.\n\nKaplan, Andreas, and Michael Haenlein. 2019. Siri, Siri, in my hand: who’s the fairest in the land? On the\n\ninterpretations, illustrations, and implications of artificial intelligence. Business Horizons 62 (1):\n\n15–25.\n\nKauermann, Goeran, and Helmut Kuechenhoff. 2010. Stichproben: Methoden und praktische Umsetzung\nmit R. Berlin: Springer.\n\nKellogg, Katherine C., Melissa A. Valentine, Angéle Christin. 2020. Algorithms at Work: The New\n\nContested Terrain of Control. Academy of Management Annals 14(1):366–410.\nKim, Pauline T. 2016. Data-driven discrimination at work. William & Mary Law Review 58: 857.\n\nKim, P. T. 2017. Data-Driven Discrimination at Work. William & Mary Law Review, 58(3):857.\n\nKim, Pauline T., and Sharion Scott. 2018. Discrimination in online employment recruiting. Louis ULJ 63:\n93.\n\nKuncel, Nathan R., David M. Klieger, Brian S. Connelly, and Deniz S. Ones. 2013. Mechanical versus\n\nclinical data combination in selection and admissions decisions: a meta-analysis. Journal of Applied\nPsychology 98 (6): 1060.\n\nBusiness Research (2020) 13:795–848 845\n\n123\n\nhttps://www.cio.com/article/3152798/artificial-intelligence/how-artificial-intelligence-can-eliminate-bias-in-hiring.html\nhttps://www.cio.com/article/3152798/artificial-intelligence/how-artificial-intelligence-can-eliminate-bias-in-hiring.html\nhttps://www.cio.com/article/3152798/artificial-intelligence/how-artificial-intelligence-can-eliminate-bias-in-hiring.html\nhttps://www.hirevue.com\nhttps://www.ibm.com/talent-management/career-coach\nhttps://www.ibm.com/talent-management/career-coach\n\n\nLambrecht, Anja, and Catherine Tucker. 2019. Algorithmic bias? An empirical study of apparent gender-\n\nbased discrimination in the display of stem career ads. Management Science 65 (7): 2966–2981.\n\nLanger, Markus, Cornelius J. König, and Andromachi Fitili. 2018. Information as a double-edged sword:\n\nthe role of computer experience and information on applicant reactions towards novel technologies\n\nfor personnel selection. Computers in Human Behavior 81: 19–30. https://doi.org/10.1016/j.chb.\n\n2017.11.036.\n\nLanger, Markus, Cornelius J. König, and Maria Papathanasiou. 2019. Highly automated job interviews:\n\nacceptance under the influence of stakes. International Journal of Selection and Assessment. https://\ndoi.org/10.1111/ijsa.12246.\n\nLeclercq-Vandelannoitte, Aurélie. 2017. An Ethical Perspective on Emerging Forms of Ubiquitous IT-\n\nBased Control. Journal of Business Ethics 142 (1):139–154.\n\nLee, Min Kyung. 2018. Understanding perception of algorithmic decisions: fairness, trust, and emotion in\n\nresponse to algorithmic management. Big Data & Society 5 (1): 2053951718756684.\n\nLee, Min Kyung, and Su Baykal. 2017. Algorithmic mediation in group decisions: fairness perceptions of\n\nalgorithmically mediated vs. discussion-based social division. In Proceedings of the 2017 ACM\nconference on computer supported cooperative work and social computing: ACM: 1035-1048.\n\nLee, In., and Yong Jae Shin. 2020. Machine learning for enterprises: applications, algorithm selection,\n\nand challenges. Business Horizons 63 (2): 157–170.\n\nLeicht-Deobald, Ulrich, Thorsten Busch, Christoph Schank, Antoinette Weibel, Simon Schafheitle,\n\nIsabelle Wildhaber, and Gabriel Kasper. 2019. The challenges of algorithm-based HR decision-\n\nmaking for personal integrity. Journal of Business Ethics 160 (2): 377–392.\n\nLepri, Bruno, Nuria Oliver, Emmanuel Letouzé, Alex Pentland, and Patrick Vinck. 2018. Fair,\n\ntransparent, and accountable algorithmic decision-making processes. Philosophy & Technology 31\n\n(4): 611–627.\n\nLeventhal, Gerald S. 1980. What should be done with equity theory? In Social exchange, New York:\n\nSpringer: 27–55.\n\nLindebaum, Dirk, Mikko Vesa, and Frank den Hond. 2019. Insights from the machine stops to better\n\nunderstand rational assumptions in algorithmic decision-making and its implications for organiza-\n\ntions. Academy of Management Review. https://doi.org/10.5465/amr.2018.0181.\n\nLipsey, Mark W., and David B. Wilson. 2001. Practical meta-analysis. Thousand Oaks: SAGE\n\npublications Inc.\n\nMann, Gideon, and Cathy O’Neil. 2016. Hiring algorithms are not neutral. Harvard Business Review 9.\n\nhttps://hbr.org/2016/12/hiring-algorithms-are-not-neutral.\n\nMcCarthy, Julie M., Talya N. Bauer, Donald M. Truxillo, Neil R. Anderson, Ana Cristina Costa, and Sara\n\nM. Ahmed. 2017. Applicant perspectives during selection: a review addressing ‘‘So what?’’,\n\n‘‘What’s new?’’, and ‘‘Where to next?’’ Journal of Management 43 (6): 1693–1725.\n\nMcColl, Rod, and Marco Michelotti. 2019. Sorry, could you repeat the question? Exploring video-\n\ninterview recruitment practice in HRM. Human Resource Management Journal 29 (4): 637–656.\n\nMcDonald, Kathleen, Sandra Fisher, and Catherine E. Connelly. 2017. e-HRM systems in support of\n\n‘‘smart’’ workforce management: an exploratory case study of system success. Electronic HRM in\nthe Smart Era 87–108. https://doi.org/10.1108/978-1-78714-315-920161004\n\nMeade, Adam W., and Michael Fetzer. 2009. Test bias, differential prediction, and a revised approach for\n\ndetermining the suitability of a predictor in a selection context. Organizational Research Methods\n12 (4): 738–761.\n\nMiller 2015. Can an algorithm hire better than a human. The New York Times. https://www.nytimes.com/\n\n2015/06/26/upshot/can-an-algorithm-hire-better-than-a-human.html. Accessed 13 sep 2019.\n\nMoher, David, Alessandro Liberati, Jennifer Tetzlaff, and Douglas G. Altman. 2009. Preferred reporting\n\nitems for systematic reviews and meta-analyses: the PRISMA statement. Annals of Internal\nMedicine 151 (4): 264–269.\n\nMöhlmann, M., and L. Zalmanson. 2017. Hands on the wheel: navigating algorithmic management and\n\nUber drivers’. In Autonomy’, in proceedings of the international conference on information systems\n(ICIS), Seoul South Korea: 1–17.\n\nMorrison, Andra, Julie Polisena, Don Husereau, Kristen Moulton, Michelle Clark, Michelle Fiander,\n\nMonika Mierzwinski-Urban, Tammy Clifford, Brian Hutton, and Danielle Rabb. 2012. The effect of\n\nEnglish-language restriction on systematic review-based meta-analyses: a systematic review of\n\nempirical studies. International Journal of Technology Assessment in Health Care 28 (2): 138–144.\n\nMurphy, Kevin P. 2012. Machine learning: a probabilistic perspective. Cambridge: MIT press.\n\n846 Business Research (2020) 13:795–848\n\n123\n\nhttps://doi.org/10.1016/j.chb.2017.11.036\nhttps://doi.org/10.1016/j.chb.2017.11.036\nhttps://doi.org/10.1111/ijsa.12246\nhttps://doi.org/10.1111/ijsa.12246\nhttps://doi.org/10.5465/amr.2018.0181\nhttps://hbr.org/2016/12/hiring-algorithms-are-not-neutral\nhttps://doi.org/10.1108/978-1-78714-315-920161004\nhttps://www.nytimes.com/2015/06/26/upshot/can-an-algorithm-hire-better-than-a-human.html\nhttps://www.nytimes.com/2015/06/26/upshot/can-an-algorithm-hire-better-than-a-human.html\n\n\nNaim, Iftekhar, Md Iftekhar Tanveer, Daniel Gildea, and Mohammed Ehsan Hoque. 2016. Automated\n\nanalysis and prediction of job interview performance. IEEE Transactions on Affective Computing 9\n\n(2): 191–204.\n\nÖtting, Sonja K., and Günter. W. Maier. 2018. The importance of procedural justice in human–machine\n\ninteractions: intelligent systems as new decision agents in organizations. Computers in Human\nBehavior 89: 27–39.\n\nPaschen, Ulrich, Christine Pitt, and Jan Kietzmann. 2020. Artificial intelligence: Building blocks and an\n\ninnovation typology. Business Horizons 63 (2): 147–155.\n\nPasquale, Frank. 2015. The black box society. Cambridge: Harvard University Press.\n\nPersson, Anders. 2016. Implicit bias in predictive data profiling within recruitments. In IFIP International\nSummer School on Privacy and Identity Management. Springer.\n\nPetticrew, Mark, and Helen Roberts. 2008. Systematic reviews in the social sciences: a practical guide.\nHoboken: John Wiley & Son.\n\nPodsakoff, Philip M., Scott B. MacKenzie, Daniel G. Bachrach, and Nathan P. Podsakoff. 2005. The\n\ninfluence of management journals in the 1980s and 1990s. Strategic Management Journal 26 (5):\n\n473–488.\n\nPrassl, Jeremias. 2018. Humans as a service: the promise and perils of work in the gig economy. Oxford:\nOxford University Press.\n\nPrecire. 2020. Precire technologies. https://precire.com/. Accessed 03 Jan 2020.\n\nRaghavan, Manish, Solon Barocas, Jon Kleinberg, and Karen Levy. 2020. Mitigating bias in algorithmic\n\nhiring: evaluating claims and practices. In Proceedings of the 2020 conference on fairness,\naccountability, and transparency.\n\nRoscher, Ribana, Bastian Bohn, Marco F. Duarte, and Jochen Garcke. 2020. Explainable machine\n\nlearning for scientific insights and discoveries. IEEE Access 8: 42200–42216.\nRosenblat, Alex, Tamara Kneese, and Danah Boyd. 2014. Networked employment discrimination. Open\n\nSociety Foundations’ Future of Work Commissioned Research Papers.\n\nRosenblat, Alex, and Luke Stark. 2016. Algorithmic labor and information asymmetries: a case study of\n\nUber’s drivers. International Journal of Communication 10: 27.\n\nRoth, Philip L., Huy Le, Oh. In-Sue, Chad H. Van Iddekinge, and Steven B. Robbins. 2017. Who ru?: On\n\nthe (in) accuracy of incumbent-based estimates of range restriction in criterion-related and\n\ndifferential validity research. Journal of Applied Psychology 102 (5): 802.\n\nRussell, Stuart J., and Peter Norvig. 2016. Artificial intelligence: a modern approach. London: Pearson\nEducation Limited.\n\nRyan, Ann Marie, and Robert E. Ployhart. 2000. Applicants’ perceptions of selection procedures and\n\ndecisions: a critical review and agenda for the future. Journal of Management 26 (3): 565–606.\n\nSajjadiani, Sima, Aaron J. Sojourner, John D. Kammeyer-Mueller, and Elton Mykerezi. 2019. Using\n\nmachine learning to translate applicant work history into predictors of performance and turnover.\n\nJournal of Applied Psychology. https://doi.org/10.1037/apl0000405.\nSánchez-Monedero, Javier, Lina Dencik, and Lilian Edwards. 2020. What does it mean to ’solve’ the\n\nproblem of discrimination in hiring? Social, technical and legal perspectives from the UK on\n\nautomated hiring systems. In Proceedings of the 2020 conference on fairness, accountability, and\ntransparency: 458–468.\n\nSavage, David, and Richard A. Bales. 2017. Video games in job interviews: using algorithms to minimize\n\ndiscrimination and unconscious bias. ABA Journal of Labor & Employment Law 32.\n\nSiddaway, Andy P., Alex M. Wood, and Larry V. Hedges. 2019. How to do a systematic review: a best\n\npractice guide for conducting and reporting narrative reviews, meta-analyses, and meta-syntheses.\n\nAnnual Review of Psychology 70: 747–770.\n\nSilverman, Rachel Emma, and Nikki Waller. 2015. The algorithm that tells the boss who might quit.Wall\nStreet Journal. http://www.wsj.com/articles/the-algorithm-that-tells-the-boss-who-might-quit-\n\n1426287935.\n\nSimbeck, K. 2019. HR analytics and ethics. IBM Journal of Research and Development 63 (4/5): 1–9.\n\nStone, Diana L. Deadrick, Kimberly M. Lukaszewski, Richard Johnson. 2015. The influence of\n\ntechnology on the future of human resource management. Human Resource Management Review 25\n\n(2):216–231.\n\nSuen, Hung-Yue., Mavis Yi-Ching. Chen, and Lu. Shih-Hao. 2019. Does the use of synchrony and\n\nartificial intelligence in video interviews affect interview ratings and applicant attitudes? Computers\nin Human Behavior 98: 93–101.\n\nBusiness Research (2020) 13:795–848 847\n\n123\n\nhttps://precire.com/\nhttps://doi.org/10.1037/apl0000405\nhttp://www.wsj.com/articles/the-algorithm-that-tells-the-boss-who-might-quit-1426287935\nhttp://www.wsj.com/articles/the-algorithm-that-tells-the-boss-who-might-quit-1426287935\n\n\nSumser, John. 2017. Artificial intelligence: ethics, liability, ownership and HR. Workforce Solutions\nReview 8 (3): 24–26.\n\nSuresh, Harini, and John V. Guttag. 2019. A framework for understanding unintended consequences of\n\nmachine learning. arXiv preprint arXiv:1901.10002.\nTambe, Prasanna, Peter Cappelli, and Valery Yakubovich. 2019. Artificial intelligence in human\n\nresources management: challenges and a path forward. California Management Review 61 (4):\n\n15–42.\n\nvan Esch, Patrick, J. Stewart Black, and Joseph Ferolie. 2019. Marketing AI recruitment: the next phase\n\nin job application and selection. Computers in Human Behavior 90: 215–222.\nVan Hoye, G. 2014. Word of mouth as a recruitment source: an integrative model. In Yu, K.Y.T. and\n\nCable, D.M. (eds), The Oxford Handbook of Recruitment. Oxford: Oxford University Press:\n\n251–268.\n\nVarghese, Jacob S., James C. Moore, and Andrew B. Whinston. 1988. Artificial intelligence and the\n\nmanagement science practitioner: rational choice and artificial intelligence. Interfaces 18 (4): 24–35.\nVasconcelos, Marisa, Carlos Cardonha, and Bernardo Gonçalves. 2018. Modeling epistemological\n\nprinciples for bias mitigation in AI systems: an illustration in hiring decisions. In Proceedings of the\n\n2018 AAAI/ACM Conference on AI, Ethics, and Society.\n\nVeale, Michael, and Reuben Binns. 2017. Fairer machine learning in the real world: mitigating\n\ndiscrimination without collecting sensitive data. Big Data & Society 4 (2): 2053951717743530.\n\nWalker, Joseph. 2012. Meet the new boss: big data. Wall Street Journal. https://online.wsj.com/article/\n\nSB10000872396390443890304578006252019616768.html. Accessed 13 Mar 2020\n\nWilliams, Betsy Anne, Catherine F Brooks, Yotam Shmargad. 2018. How Algorithms Discriminate\n\nBased on Data They Lack: Challenges, Solutions, and Policy Implications. Journal of Information\nPolicy 8:78–115.\n\nWolpert, David H., and William G. Macready. 1997. No free lunch theorems for optimization. IEEE\nTransactions on Evolutionary Computation 1 (1): 67–82.\n\nWoodruff, Allison, Sarah E Fox, Steven Rousso-Schindler, and Jeffrey Warshaw. 2018. A qualitative\n\nexploration of perceptions of algorithmic fairness. In Proceedings of the 2018 CHI Conference on\n\nHuman Factors in Computing Systems.\n\nWoods, Stephen A., Sara Ahmed, Ioannis Nikolaou, Ana Cristina Costa, and Neil R. Anderson. 2020.\n\nPersonnel selection in the digital age: a review of validity and applicant reactions, and future\n\nresearch challenges. European Journal of Work and Organizational Psychology 29 (1): 64–77.\n\nYarger, Lynette, Fay Cobb Payton, and Bikalpa Neupane. 2019. Algorithmic equity in the hiring of\n\nunderrepresented IT job candidates. Online Information Review. https://doi.org/10.1108/OIR-10-\n2018-033. Accessed 3 Mar 2020.\n\nPublisher’s Note Springer Nature remains neutral with regard to jurisdictional claims in published maps\n\nand institutional affiliations.\n\n848 Business Research (2020) 13:795–848\n\n123\n\nhttps://online.wsj.com/article/SB10000872396390443890304578006252019616768.html\nhttps://online.wsj.com/article/SB10000872396390443890304578006252019616768.html\nhttps://doi.org/10.1108/OIR-10-2018-033\nhttps://doi.org/10.1108/OIR-10-2018-033\n\n\tDiscriminated by an algorithm: a systematic review of discrimination and fairness by algorithmic decision-making in the context of HR recruitment and HR development\n\tAbstract\n\tIntroduction\n\tConceptual background and definitions\n\tDefinition of algorithms\n\tReason for biases\n\tFairness and discrimination in information systems\n\n\tMethods\n\tSearch terms and databases\n\tScreening, eligibility process, and inclusion process\n\tRobustness check\n\tLimitations of the research process\n\n\tDescriptive results\n\tTypes of algorithmic decisions and applications in HR\n\tHR recruitment\n\tHR selection\n\tHR development\n\n\tDiscussion\n\tTheoretical implications and future research directions\n\tPractical implications\n\n\tConclusion\n\tData availability\n\tAppendix\n\tList of employed keywords\n\tAlgorithm\n\tFairness\n\tEvaluation\n\tBias\n\tData mining\n\tHRM\n\n\tReferences\n\n\n\n\n",
      "metadata_storage_path": "aHR0cHM6Ly9jb3Jwb3JhdGV0cmFpbmluZ3N0b3JhZ2UuYmxvYi5jb3JlLndpbmRvd3MubmV0L3BhcGVycy9LJUMzJUI2Y2hsaW5nLVdlaG5lcjIwMjBfQXJ0aWNsZV9EaXNjcmltaW5hdGVkQnlBbkFsZ29yaXRobUFTeXMucGRm0",
      "metadata_author": "Alina Köchling ",
      "metadata_title": "Discriminated by an algorithm: a systematic review of discrimination and fairness by algorithmic decision-making in the context of HR recruitment and HR development",
      "metadata_creation_date": "2020-11-19T15:45:16Z",
      "keyphrases": [
        "systematic review",
        "algorithmic decision-making",
        "HR recruitment",
        "HR development",
        "discrimination",
        "fairness",
        "context"
      ]
    },
    {
      "@search.score": 0.7113445,
      "content": "\nRESEARCH Open Access\n\nA classification method for social\ninformation of sellers on social network\nHaoliang Cui1, Shuai Shao2* , Shaozhang Niu1, Chengjie Shi3 and Lingyu Zhou1\n\n* Correspondence: shaoshuaib@163.\ncom\n2China Information Technology\nSecurity Evaluation Center, Beijing\n100085, China\nFull list of author information is\navailable at the end of the article\n\nAbstract\n\nSocial e-commerce has been a hot topic in recent years, with the number of users\nincreasing year by year and the transaction money exploding. Unlike traditional e-\ncommerce, the main activities of social e-commerce are on social network apps. To\nclassify sellers by the merchandise, this article designs and implements a social\nnetwork seller classification scheme. We develop an app, which runs on the mobile\nphones of the sellers and provides the operating environment and automated\nassistance capabilities of social network applications. The app can collect social\ninformation published by the sellers during the assistance process, uploads to the\nserver to perform model training on the data. We collect 38,970 sellers’ information,\nextract the text information in the picture with the help of OCR, and establish a\ndeep learning model based on BERT to classify the merchandise of sellers. In the\nfinal experiment, we achieve an accuracy of more than 90%, which shows that the\nmodel can accurately classify sellers on a social network.\n\nKeywords: User model, Machine learning, Social e-commerce\n\n1 Introduction\nWith the continuous improvement of social network and mobile payment technology,\n\none kind of commodity trading based on social relations called social e-commerce is in\n\nrapid development. According to the 2019 China social e-commerce industry develop-\n\nment report released by the Internet society of China, the number of employees of so-\n\ncial e-commerce in China is expected to reach 48.01 million in 2019, up by 58.3\n\npercent year on year, and the market size is expected to reach 2060.58 billion yuan, up\n\nby 63.2% year on year. Social e-commerce has become a large scale, and the high\n\ngrowth cannot be ignored. Different from e-commerce platforms such as Taobao, so-\n\ncial e-commerce is at the end of online retail. It carries out trading activities through\n\nsocial software and uses social interaction, user generated content and other means to\n\nassist the purchase and sale of goods. At the same time, sellers on social network use\n\ndifferent social software without uniform registration, have no systematic classification\n\nof products for sale, and there are no standardized terms for product description.\n\nThese bring great difficulty to the accurate classification of user portrait. This paper\n\nproposes a method based on the NLP classification model, which can realize accurate\n\n© The Author(s). 2021 Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which\npermits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the\noriginal author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or\nother third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit\nline to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by\nstatutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a\ncopy of this licence, visit http://creativecommons.org/licenses/by/4.0/.\n\nEURASIP Journal on Image\nand Video Processing\n\nCui et al. EURASIP Journal on Image and Video Processing          (2021) 2021:4 \nhttps://doi.org/10.1186/s13640-020-00545-z\n\nhttp://crossmark.crossref.org/dialog/?doi=10.1186/s13640-020-00545-z&domain=pdf\nhttp://orcid.org/0000-0001-9638-0201\nmailto:shaoshuaib@163.com\nmailto:shaoshuaib@163.com\nhttp://creativecommons.org/licenses/by/4.0/\n\n\nbusiness classification of social e-commerce based on social information of social e-\n\ncommerce. This method analyzes 38,970 sellers on social networks and establishes a\n\ndeep learning model based on BERT to accurately classify the merchandise of sellers.\n\nIn addition, we introduced the OCR algorithm to extract the text information in the\n\npicture and superimposed it on the social content data, which effectively improved the\n\nclassification accuracy. The final experiment shows that the measured accuracy is more\n\nthan 90%.\n\n2 Related work\n2.1 Natural language processing\n\nIn order to analyze e-commerce business classification based on social data of sellers on a\n\nsocial network, the text needs to be analyzed based on the NLP correlation algorithm.\n\nThe rapid development of NLP at the present stage is due to the neural network language\n\nmodel (NNLM) Bengio et al. [1] proposed in 2003. Researchers have been trying to realize\n\nthe end-to-end classification recognition by using a neural network as a classifier in the\n\ntext classification research based on word embedding. Kim first introduces the convolu-\n\ntional neural network (CNN) into the study of text classification. The network structure is\n\na dropout full connection layer and a softmax layer connected after one convolution layer\n\n[2]. Although this algorithm achieves good results in various benchmark tests, it cannot\n\nobtain long-distance text dependency due to the limitation of network structure. There-\n\nfore, Tencent AI Lab proposed DPCNN, which further enhanced the extraction capacity\n\nof long-distance text dependency by deepening CNN [3].\n\nSocial content data includes multimedia text data and picture data. With the help of\n\nOCR, we extract the text in the picture and convert the picture data into text data. Text\n\nis a kind of sequential data, and the classification of it by recurrent neural network\n\n(RNN) has been the focus of long-term research in academia [4]. As a variation of\n\nRNN, long short-term memory (LSTM) adds control units such as forgetting gate, in-\n\nput gate, and output gate on the original basis, which solves the problem of gradient\n\nexplosion and gradient disappearance in the long sequence training of RNN and pro-\n\nmotes the use of RNN [5]. By introducing the sharing information mechanism, Liu\n\net al. further improved the accuracy of the RNN algorithm in the text multi-\n\nclassification task and achieved good results in four benchmark text classifications [6].\n\nHowever, Word vectors cannot be constructed in Word embedding to solve the\n\nproblem of polysemy. Even though different semantic environments are considered\n\nduring training, the result of training is still one word corresponding to one row vector.\n\nConsidering the widespread phenomenon of polysemy, Peters et al. propose embed-\n\ndings from language model (ELMO) to address the impact of polysemy on natural lan-\n\nguage modeling [7]. ELMO uses a feature-based form of pre-training. First, two-way\n\nLSTM is used to pre-train the corpus, and then word embedding resulting from train-\n\ning is adjusted by double-layer two-way LSTM when processing downstream tasks to\n\nadd more grammatical and semantic information according to the context words.\n\nThe ability of ELMO to extract features is limited for choosing LSTM as the feature\n\nextractor instead of Transformer [8], and ELMO’s bidirectional splicing method is also\n\nweak in feature fusion. Therefore, Devlin et al. propose the BERT model, taking Trans-\n\nformer as a feature extractor to pre-train large-scale text corpus [9].\n\nCui et al. EURASIP Journal on Image and Video Processing          (2021) 2021:4 Page 2 of 12\n\n\n\n2.2 User analysis of social networks\n\nUser analysis is an important part of social network analysis. Most existing studies use\n\nuser-generated content or social links between users to simulate users. Wu et al. mod-\n\neled users on the content curation social network (CCSN) in the unified framework by\n\nmining user-generated content and social links [10]. They proposed a potential Bayes-\n\nian model, multilevel LDA (MLLDA), that could represent users of potential interest\n\nfound in social links formed by text descriptions contributed by users and information\n\nsharing. In 2017, Wu et al. proposed a latent model [11], trying to explain how the so-\n\ncial network structure and users’ historical preferences change over time affect each\n\nuser’s future behavior and predict each user’s consumption preferences and social con-\n\nnections in the near future. Malli et al. proposed a new online social network user pro-\n\nfile rating model [12], which solved the problem of large and complicated user data. In\n\nterms of data analysis platform, Chen et al. [13] developed a big data platform for the\n\nstudy of the garlic industry chain. Garlic planting management, price control, and pre-\n\ndiction were realized through data collection, storage, and pretreatment. Ning et al.\n\n[14] designed a ga-bp hybrid algorithm based on the fuzzy theory and constructed an\n\nair quality evaluation model by combining the knowledge of BP neural network, genetic\n\nalgorithm, and fuzzy theory. Yin et al. [15] studied two methods of extracting supervis-\n\nory relations and applied them to the field of English news. One is the combination of\n\nsupport vector machine and principal component analysis, and the other is the combin-\n\nation of support vector machine and CNN, which can extract high-quality feature vec-\n\ntors from sentences of support vector machine. In the social apps, the data we obtain is\n\nmostly image data, so we introduced the OCR technology to identify text information\n\nin images.\n\n3 Data collection\nIn order to analyze the behavior patterns of social e-commerce, we developed an auxil-\n\niary tool for social e-commerce. In this tool, sellers on a social network are provided\n\nwith the independent running environment of social software and the automatic auxil-\n\niary ability, and the information acquisition module of the auxiliary process is used to\n\ncollect the social information published by sellers on a social network, which is\n\nuploaded to the background server for model training. We provided this tool to nearly\n\n10,000 sellers on a social network who participated in the experiment to obtain their\n\nsocial information in their e-commerce activities.\n\n3.1 Overall structure\n\nThe whole data collection scheme is mainly composed of two parts: intelligent space\n\napp and background server. The overall architecture is shown in Fig. 1. Intelligent\n\nspace app is deployed in the mobile phones of sellers on a social network and imple-\n\nmented based on the application layer of the Android platform, providing sellers on a\n\nsocial network with a secure container for the independent operation of social software.\n\nThe app contains the automatic assistant module, which provides the automatic assist-\n\nant capability of various business processes for seller, and collects the social informa-\n\ntion in the auxiliary process through the information grasping module. The collected\n\ninformation is cached and uploaded locally through the information collection service.\n\nCui et al. EURASIP Journal on Image and Video Processing          (2021) 2021:4 Page 3 of 12\n\n\n\nThe background server is responsible for receiving the collected data uploaded by the\n\nintelligent space, preprocessing the data first, and then classifying the social e-\n\ncommerce through the data based on the machine learning classification model, and fi-\n\nnally storing the classification results.\n\n3.1.1 Security container\n\nThe security container is designed to allow social software to run independently with-\n\nout modifying the OS or gaining root privileges. The basic principle of its realization is\n\nto create an independent container process; load APK file of social software dynamic-\n\nally; monitor and intercept process communication interface such as Binder IPC\n\nthrough Libc hook, Java reflection, dynamic proxy, and other technical means; and col-\n\nlect social information through an automatic assistant module. The main part of the\n\ncontainer is composed of an application layer module and a service layer module.\n\nThe application layer module is responsible for the process startup and execution of\n\nsocial software, and its main functions include three parts.\n\n3.1.1.1 Interactive interception The application layer module intercepts the inter-\n\naction between the application process and the underlying system in the container and\n\nmodifies the calling logic. By hook or dynamic proxy of system library API and Binder\n\ncommunication interface, the application layer module blocks all interfaces that interact\n\nwith the system during the execution of social software and controls the process\n\nboundary of interaction between social applications and system services.\n\n3.1.1.2 Social information collection The loading of the automatic auxiliary module\n\nby social software is realized when initializing the process of social application.\n\nThe application layer module injects the corresponding plugins in the automatic\n\nassistant module into the social application process. The automatic assistance mod-\n\nule provides a number of e-commerce auxiliary functions for sellers on a social\n\nnetwork, including customer acquisition, social customer relationship management\n\nLinux Kernel\n\nBinder Mode\n\nIntelligent Space\n\nService Layer Mode\nAMS Proxy PMS Proxy\n\nApplication Layer Mode\nSocial App\n\nInteractive \ninterception\n\nautomatic \nassistance  \nmodule\n\nInformation\nCollection \n\nBinder IPC\n\nBinder IPC\n\nBinder \nIPC Backgroud\n\n Server\n\nInternet\n\nFig. 1 The overall architecture diagram of the data acquisition scheme\n\nCui et al. EURASIP Journal on Image and Video Processing          (2021) 2021:4 Page 4 of 12\n\n\n\n(SCRM), group management, sales assistance, and daily affairs. Sellers on social\n\nnetworks publish social information with commercial attributes through auxiliary\n\nfunctions, then the automatic auxiliary module will automatically collect the social\n\ninformation and send it to the information collection service for processing.\n\n3.1.1.3 Local processing of social information When the information collection ser-\n\nvice receives the social information collected by the automatic auxiliary module, the\n\ndata will be compressed and encrypted in the local cache. The service then uploads the\n\ncollected data to the background server periodically through the timer, and HTTPS is\n\nused to ensure data transmission security.\n\nThe main function of the service layer module is to take over the call logic modified\n\nby the application layer module by simulating the system service modify the parameters\n\nin the communication process and finally call the real system service. The service layer\n\nmodule exists in the container as an independent process. It focuses on the simulation\n\nof activity manager service (AMS) and package manager service (PMS) and realizes the\n\nsupport of system services in the process of launching and running social software.\n\n3.1.2 Background server\n\nThe background server mainly realizes the machine learning model processing of the\n\ncollected social data, including the functions of data preprocessing, data training, classi-\n\nfication, and result storage. The core processing logic will be described in chapter 5.\n\n3.2 Key processes\n\nThere are four key processes in the process of social information collection and pro-\n\ncessing. They are social software process initialization, social software process\n\nIntelligent \nSpace App \nlaunched\n\nProcess Boundaries\n\nUser Process\n\nSocial software process \ninitialization\n\nlaunching social \nsoftware\n\ninject automatic \nauxiliary\n\nSocial software process \nexecution\n\nRun the plug-in\n\nCollect social \ninformation\n\nProcess Boundaries\n\nUser Process\n\nLocal processing of \nsocial information\n\nBatch upload \nprocessed social \n\ninformation\n\nEncrypt, compress \nand store social \n\ninformation\n\nInternet\n\nInformation collecting \nservice process\n\nBackground processing \nof social information\n\nReceiving social \ninformation\n\nPreprocessing social \ninformation\n\nThe Server\n\nMachine learning \ncategorizes social \n\ninformation\n\nStore the \nclassification results\n\nFig. 2 Key flow chart of data acquisition scheme\n\nCui et al. EURASIP Journal on Image and Video Processing          (2021) 2021:4 Page 5 of 12\n\n\n\nexecution, local processing of social information, and background processing of social\n\ninformation. The complete process is shown in Fig. 2.\n\n3.2.1 Social software process initialization\n\nWhen launching social software, the intelligent space will first intercept the callback\n\nfunction of the life cycle of all its components, then realize the process loading of the\n\nautomatic auxiliary module during the process initialization.\n\n3.2.2 Social software process execution\n\nThe process execution is completed by the application layer module and service layer\n\nmodule together. Sellers on a social network use automatic auxiliary modules to\n\ncomplete business activities, trigger information capture module to collect social infor-\n\nmation, and send it to the information collection service for subsequent processing.\n\n3.2.3 Local processing of social information\n\nThe local processing of social information is mainly completed by the information col-\n\nlection service. In order to ensure the safe storage and transmission of the collected so-\n\ncial information, the information collection service first adopts the encryption and\n\ncompression method to realize the local security cache and then adopts the HTTPS se-\n\ncure communication and transmission protocol to upload the data.\n\n3.2.4 Background processing of social information\n\nThe background processing of social information is completed by the background ser-\n\nver. The server first receives the social information uploaded by the intelligent space,\n\nnext decrypts and decompresses the social information, cleans the plaintext data, uses\n\nthird-party OCR technology to identify text information in images, and adds it to the\n\nuser’s social information after simple data processing. Then, the classification of sellers\n\non a social network is realized through the data based on machine learning modeling.\n\nFinally, the classification results are stored in the target database.\n\n4 Methods\nTo classify the business attributes of social e-commerce based on the information of\n\nsellers on a social network, traditional feature matching scheme and classification clus-\n\ntering scheme based on machine learning can be used to establish the model. In this\n\nchapter, we introduce the scheme based on term frequency-inverse document fre-\n\nquency (TF-IDF) clustering and the classification scheme based on BERT.\n\n4.1 Feature classification and TF-IDF clustering\n\n4.1.1 Feature classification\n\nWe randomly select 5000 sellers on a social network from the data collected by the\n\nbackground server and extracted the text data of their social information for analysis.\n\nEach social e-commerce user contains an average of 50 social text data. Based on the\n\ncontent, we manually classify social e-commerce into 11 categories. With the help of e-\n\ncommerce platforms like JD.COM, 50–100 keywords are sorted out for each category,\n\nand these keywords are screened and expanded according to the language habits of\n\nCui et al. EURASIP Journal on Image and Video Processing          (2021) 2021:4 Page 6 of 12\n\n\n\nsellers on a social network. On this basis, we collect all the social information of each\n\nsocial network seller, cut and remove word segmentation, and match the results with\n\nthe keywords of the selected 11 categories. The number of keywords that are matched\n\nis counted as the matching degree. According to the situation of different classification,\n\nthe threshold of matching degree is determined by manual screening of some results,\n\nand then all social e-commerce is classified according to the threshold. After\n\noptimization and verification, the accuracy of the classical feature matching scheme fi-\n\nnally reached 40%. However, due to the simplicity of the rules of the feature matching\n\nscheme, the small optimization space, the high misjudgment rate of the scheme, and\n\nthe large human intervention in the basic word segmentation process, it is difficult to\n\ncover various situations of social e-commerce due to the limitation of these basic key-\n\nwords, thus making it insensitive to the dynamic changes of new hot words of social e-\n\ncommerce.\n\n4.1.2 TF-IDF clustering\n\nTo achieve the goal of accurate classification of social e-commerce, we designed a\n\nscheme based on TF-IDF clustering. Term frequency-inverse document frequency (TF-\n\nIDF) is a commonly used weighted technique for information retrieval and text mining\n\nto evaluate the importance of a single word to a document in a set of documents or a\n\ncorpus. In this scheme, the social information of each social e-commerce user is\n\nmapped as one file set of TF-IDF, and all texts of all sellers on a social network are\n\nmapped as the whole corpus. The words with the highest frequency used by each social\n\ne-commerce user are the most representative words in this document and become key-\n\nwords. Category labels can be generated to calculate the probability that a document\n\nbelongs to a certain category using the naive Bayes algorithm formula. The advantages\n\nof TF-IDF clustering to achieve the classification of sellers on the social network in-\n\nclude the following: (1) clear mapping; (2) emphasize the weight of keywords and lower\n\nthe weight of non-keywords; (3) compared with other machine learning algorithms, the\n\ncharacteristic dimension of the model is greatly reduced to avoid the dimension disas-\n\nter; and (4) while improving the efficiency of classification calculation, ensure that the\n\nclassification effect has a good accuracy and recall rate. The architecture of the entire\n\nsolution is shown in Fig. 3.\n\nIn the text preprocessing stage, the first thing to do is to format the social informa-\n\ntion, mainly including deleting the space, deleting the newline character, merging the\n\nsocial e-commerce text, and so on, and finally getting the text to be processed for word\n\nsegmentation. In this scheme, we choose Jieba’s simplified mode for word segmenta-\n\ntion, then filter out the noise by filtering the stop words (e.g., yes, ah, etc.).\n\nIn the stage of establishing the vector space model, the first step is to load the train-\n\ning set and take the pre-processed social information of each social e-commerce user\n\nas a document. The next step is to generate a dictionary, by adding every word that ap-\n\npears in the training set to it, using the complete dictionary to calculate the TF-IDF\n\nvalue of each document. In this scheme, CountVectorizer and TfidfTransformer in Py-\n\nthon’s Scikit-Learn library are used. CountVectorizer is used to convert words in the\n\ntext into word frequency matrix, TfidfTransformer is used to count the TF-IDF value\n\nof each word in each document, and the top20 words in each document are taken as\n\nCui et al. EURASIP Journal on Image and Video Processing          (2021) 2021:4 Page 7 of 12\n\n\n\nkeywords of sellers on a social network. After this step, the keywords with a large TF-\n\nIDF value in each document are the most representative words in the document, which\n\nbecome the keyword set of the social e-commerce user. Finally, the naive Bayes method\n\nis used to generate the category label, and the document vectors belonging to the same\n\ncategory in the TF-IDF matrix are added to form a matrix of m*n, where m represents\n\nthe number of categories and n represents the number of documents. The weight of\n\neach word is divided by the total weight of all words of the class, to calculate the prob-\n\nability that a document belongs to a certain class.\n\nIn the model optimization stage, we optimize the whole scheme model by adjusting\n\nthe stop word set, adjusting parameters (including CountVectorizer, TfidfTransformer\n\nclass construction parameters), and adjusting the category label generation method.\n\nThe main idea of TFIDF is if a word or phrase appears in an article with a high fre-\n\nquency of TF, and rarely appears in other articles, it is considered that the word or\n\nphrase has a good classification ability and is suitable for classification. TFIDF is actu-\n\nally: TF * IDF, TF is term frequency and IDF is inverse document frequency.\n\nIn a given document, word frequency refers to the frequency of a given word in the\n\ndocument. This number is a normalization of the number of words to prevent it from\n\nbeing biased towards long documents. For the word ti in a particular document, its im-\n\nportance can be expressed as:\n\ntf i; j ¼\nj D j\n\nj j : ti∈d j\n� � j\n\namong them:\n\n|D|: The total number of files in the corpus\n\n∣{j : ti ∈ dj}∣: The number of documents containing the term ti (i.e., the number of\n\ndocuments in ni, j ≠ 0). If the term is not in the corpus, it will cause the dividend to be\n\nzero, so it is generally used 1 + ∣ {j : ti ∈ dj}∣.\n\nand then:\n\n Social e-\ncommerce data\n\nData preparation\n\nFormat processing\n\nFilter stop words\n\nText preprocessing\n\nGenerate directory\n\nBuild the vector space and \nTF-IDF\n\nGenerate category tags\n\nBayesian classifier\n\nText articiple\n\nLoad training set \n\nBuild tf matrix \n\nbuild vector\n\nbuild matrix \n\nConditional probability \nmatrix\n\nModel optimization\n\nFig. 3 TF-IDF scheme framework\n\nCui et al. EURASIP Journal on Image and Video Processing          (2021) 2021:4 Page 8 of 12\n\n\n\ntfidf i; j ¼ tf i; j � idf i\n\nA high word frequency in a particular document and a low document frequency of\n\nthe word in the entire document collection can produce a high-weight TF-IDF. There-\n\nfore, TF-IDF tends to filter out common words and keep important words.\n\n4.2 Classification scheme based on BERT\n\n4.2.1 Data label\n\nWe manually classify and mark the data of sellers on a social network according to the\n\ncharacteristics of the products. Classified labels include 38,970 items and 17 categories\n\nof data, including 3c, dress, food, car, house, beauty, makeup, training, jewelry, promo-\n\ntion, medicine and health, phone charge recharge, finance, card category, cigarettes, es-\n\nsays, and others. The pre-processing phase removes emojis, numbers, and spaces from\n\nthe text through Unicode encoding.\n\n4.2.2 Classification scheme\n\nIn the BERT model, Transformer, as an encoder-decoder model based on attention\n\nmechanism, solves the problem that RNN cannot deal with long-distance dependence\n\nand the model cannot be parallel, improving the performance of the model without re-\n\nducing the accuracy. At the same time, BERT introduced the shading language model\n\n(MLM, masked language model) and context prediction method, further enhance the\n\ntwo-way training of the ability of feature extraction and text. MLM uses Transformer\n\nencoders and bilateral contexts to predict random masked tokens to pre-train two-way\n\ntransformers. This makes BERT different from the GPT model, which can only conduct\n\none-way training and can better extract context information through feature fusion.\n\nAnaphase prediction is more embodied in QA and NLI. Therefore, we choose the\n\nBERT model based on the bidirectional coding technology of pre-training and attention\n\nmechanism to classify sellers on a social network.\n\nWe chose the official Chinese pre-training model of Google as the pre-training model\n\nof the experiment: BERT-Base which is Chinese simplified and traditional, 12-layer,\n\n768-hidden, 12-head, 110M parameters [16]. This pre-training model is obtained by\n\nGoogle’s unsupervised pre-training on a large-scale Chinese corpus. On this basis, we\n\nwill carry out fine-tuning to realize the classification model of sellers on a social net-\n\nwork. When dividing the data set, we divided 38,970 pieces of data into training set\n\nand verification set according to the ratio of 6:4, that is, 23,382 pieces of training set\n\nand 15,588 pieces of verification set.\n\n5 Results and discussion\n5.1 TF-IDF clustering scheme\n\nThe computer used in the experiment is configured with AMD Ryzen R5-4600H CPU,\n\n16G memory, and windows10 64bit operating system. First, the default construction\n\nparameters are used, and the average accuracy of each classification is 45.7%. Next, the\n\nparameters are adjusted through a genetic algorithm, and 100 rounds of genetic algo-\n\nrithm optimization are performed, then the average accuracy reached the highest value\n\nof 52.5%. In the process of genetic algorithm, statistical estimation of algorithm time is\n\nCui et al. EURASIP Journal on Image and Video Processing          (2021) 2021:4 Page 9 of 12\n\n\n\nalso carried out. On average, on this data set, the running time of each round of the\n\nTF-IDF model is about 28 s.\n\nExperiments show that the accuracy of the TF-IDF clustering scheme has been\n\nimproved after optimization, and it has a certain reference value for the classifica-\n\ntion of sellers on a social network, but there is still a big gap from the accurate\n\nclassification. We found three reasons after analyzing the experimental results. (1)\n\nCompared to the feature matching scheme, the TF-IDF-based model is improved\n\nto some extent. However, the input of the model is still the result of direct word\n\nsegmentation, and more information is lost in the word segmentation process, such\n\nas the semantic information of previous and later texts and the repetition fre-\n\nquency of corpus, which are relatively important in the process of natural language\n\nprocessing. (2) The classification problem of sellers on a social network is compli-\n\ncated. This model does not analyze the correlation between words and is essen-\n\ntially an upgraded version of word frequency statistics, which makes it difficult to\n\nimprove the accuracy after reaching a certain value. (3) For the optimization of the\n\nmodel, only the parameters of the intermediate function are adjusted, and the\n\nmethod is not upgraded. Therefore, the machine learning scheme based on TF-IDF\n\nclustering cannot solve the problem of accurate classification of sellers on a social\n\nnetwork. In the next chapter, we will introduce a scheme based on deep learning\n\nto achieve the goal of classifying sellers on a social network.\n\n5.2 Classification scheme based on BERT\n\nText classification fine-tuning is to serialize the preprocessed text information\n\ntoken and input BERT, and select the final hidden state of the first token [CLS] as\n\na sentence vector to output to the full connection layer, and then output the prob-\n\nability of obtaining various labels corresponding to the text through the softmax\n\nlayer. The experimental schematic diagram is shown in Figs. 4 and 5. The max-\n\nimum length of the sequence (ma_seq_length) is set to 256 according to the actual\n\ntext length of the social information data set of the sellers on a social network and\n\nFig. 4 Text message token serialization\n\nFig. 5 Text classification BERT fine-tuning model structure diagram\n\nCui et al. EURASIP Journal on Image and Video Processing          (2021) 2021:4 Page 10 of 12\n\n\n\nthe batch_size and learning rate adopt the official recommended values of 32 and\n\n2e−5. In addition, we also adjust the super parameter num_train_epochs and in-\n\ncrease the number of training epochs (num_train_epochs) from 3 to 9 to improve\n\nthe recognition rate of the model (Table 1). The results are shown in Table 2.\n\nWe select an additional 9500 text data of sellers on social networks and test the\n\nmodel after the same preprocessing. The accuracy rate is 90.5%, which is lower than\n\nthat of the verification set (96.2%). The reason may be that the data of the test set con-\n\ntains a large number of commodity terms not included in the corpus and training set,\n\nand the text description of these commodities is too colloquial. Sellers on a social net-\n\nwork often use colloquial words in the industry to replace the standard product names\n\nwhen releasing product information, such as “Bobo” instead of “Botox,” which to some\n\nextent limits the accuracy of text-based classification in the social e-commerce market\n\nscene.\n\n6 Conclusion\nThe classification model proposes in this paper achieves an accuracy of 90.5% in the\n\ntest data. However, there are still some problems such as non-standard description text.\n\nA corpus with a high correlation with a social e-commerce environment will be estab-\n\nlished in order to further improve the accuracy of social e-commerce classification. At\n\nthe same time, we will use the knowledge distillation technology to compress and refine\n\nthe existing model, so as to improve the model recognition rate while simplifying the\n\nmodel and improving the operational performance [16]. In addition, in view of the high\n\nlabor cost and time cost of large-scale data marking, the next step will be trying to\n\nmake full use of semi-supervised learning to train unlabeled data and labeled completed\n\ndata [17]. The full use of large-scale unlabeled data is conducive to further improving\n\nthe accuracy and generalization ability of the model, as well as the analysis and process-\n\ning of emerging products, providing strong data support for the model landing. Since\n\nthe image data have also been studied to profiling the users in a social network [18]\n\nand perceptual image hashing schemes are proposed [19], we will improve our model\n\nso that the image and text data are combined for analysis.\n\nTable 1 Corresponding table of epoch and accuracy\n\nEpoch eval_accuracy (%)\n\n3 95.84\n\n6 96.05\n\n9 96.2\n\nThe training results are shown in Table 2, and the recognition rate is 96.2%\n\nTable 2 Text information classification results of sellers on social network\n\nResults Value\n\neval_accuracy 96.2%\n\neval_loss 0.25033528\n\nglobal_step 6024\n\nLoss 0.25023073\n\nCui et al. EURASIP Journal on Image and Video Processing          (2021) 2021:4 Page 11 of 12\n\n\n\nAbbreviations\nBERT: Bidirectional Encoder Representations from Transformers; DPCNN: Deep pyramid convolutional neural networks;\nOCR: Optical character recognition\n\nAcknowledgements\nNot applicable\n\nAuthors’ contributions\nHaoliang Cui designed the scheme and carried out the experiments. Shuai Shao gave suggestions on the structure of\nthe manuscript and participated in modifying the manuscript. All authors read and approved the final manuscript.\n\nFunding\nNational Natural Science Foundation of China (Award Number 61370195, U1536121)\n\nAvailability of data and materials\nhttps://github.com/cuihaoliang/User-portraits-of-social-e-commerce\n\nCompeting interests\nThe authors declare that they have no competing interests.\n\nAuthor details\n1Beijing Key Laboratory of Intelligent Telecommunication Software and Multimedia, Beijing University of Posts and\nTelecommunications, Beijing 100876, China. 2China Information Technology Security Evaluation Center, Beijing 100085,\nChina. 3Institute of Information Engineering, Chinese Academy of Sciences, Beijing 100088, China.\n\nReceived: 16 March 2020 Accepted: 25 December 2020\n\nReferences\n1. Y. Bengio, R. Ducharme, P. Vincent, et al., A neural probabilistic language model. J. Mach. Learn. Res. 3, 1137–1155\n\n(2003)\n2. Kim Y. Convolutional neural networks for sentence classification arXiv preprint arXiv:1408.5882, 2014.\n3. R. Johnson, T. Zhang, Deep pyramid convolutional neural networks for text categorization [C]//Proceedings of the 55th\n\nAnnual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) (2017), pp. 562–570\n4. Otter D W, Medina J R, Kalita J K. A survey of the usages of deep learning in natural language processing arXiv preprint\n\narXiv:1807.10854, 2018.\n5. R. Jozefowicz, W. Zaremba, I. Sutskever, An empirical exploration of recurrent network architectures [C]//International\n\nconference on machine learning (2015), pp. 2342–2350\n6. Liu P, Qiu X, Huang X. Recurrent neural network for text classification with multi-task learning arXiv preprint arXiv:1605.\n\n05101, 2016.\n7. Peters M E, Neumann M, Iyyer M, et al. Deep contextualized word representations. arXiv preprint arXiv:1802.05365, 2018.\n8. A. Vaswani, N. Shazeer, N. Parmar, et al., Attention is all you need [C]//Advances in neural information processing systems\n\n(2017), pp. 5998–6008\n9. Devlin J, Chang M W, Lee K, et al. BERT: pre-training of deep bidirectional transformers for language understanding\n\narXiv preprint arXiv:1810.04805, 2018.\n10. L. Wu et al., MLLDA: multi-level LDA for modelling users on content curation social networks. Neurocomputing 236, 73–\n\n81 (2017)\n11. L. Wu et al., Modeling the evolution of users’ preferences and social links in social networking services. IEEE Transact.\n\nKnowledge. Data. Eng. 29.6, 1240–1253 (2017)\n12. M. Malli, N. Said, A. Fadlallah, A new model for rating users’ profiles in online social networks. Comput. Information. Sci.\n\n10.2, 39–51 (2017)\n13. W. Chen et al., Development and application of big data platform for garlic industry chain. Comput. Mater. Continua 58.\n\n1, 229 (2019)\n14. M. Ning et al., GA-BP air quality evaluation method based on fuzzy theory. Comput. Mater. Continua 58.1, 215–227 (2019)\n15. Yin, Libo, et al. Relation extraction for massive news texts. Tech Science Press, CMC,60, no.1(2019), pp.275-285.\n16. Sun S, Cheng Y, Gan Z, et al. Patient knowledge distillation for BERT model compression arXiv preprint arXiv:1908.09355, 2019.\n17. Yalniz I Z, Jégou H, Chen K, et al. Billion-scale semi-supervised learning for image classification. arXiv preprint arXiv:1905.\n\n00546, 2019.\n18. Yaqiong Qiao, Xiangyang Luo, Chenliang Li, et al. Heterogeneous graph-based joint representation learning for users\n\nand POIs in location-based social network, Inf. Process. Manag., 2020, 57, 102151-1~102151-17\n19. Jinwei Wang, Hao Wang, Jian Li, Xiangyang Luo, Yun-Qing Shi, Sunil Kr. Jha, Detecting double JPEG compressed color\n\nimages with the same quantization matrix in spherical coordinates, IEEE Trans. on CSVT, doi: 10.1109/TCSVT.2019.\n2922309.\n\nPublisher’s Note\nSpringer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.\n\nCui et al. EURASIP Journal on Image and Video Processing          (2021) 2021:4 Page 12 of 12\n\nhttps://github.com/cuihaoliang/User-portraits-of-social-e-commerce\n\n\tAbstract\n\tIntroduction\n\tRelated work\n\tNatural language processing\n\tUser analysis of social networks\n\n\tData collection\n\tOverall structure\n\tSecurity container\n\tBackground server\n\n\tKey processes\n\tSocial software process initialization\n\tSocial software process execution\n\tLocal processing of social information\n\tBackground processing of social information\n\n\n\tMethods\n\tFeature classification and TF-IDF clustering\n\tFeature classification\n\tTF-IDF clustering\n\n\tClassification scheme based on BERT\n\tData label\n\tClassification scheme\n\n\n\tResults and discussion\n\tTF-IDF clustering scheme\n\tClassification scheme based on BERT\n\n\tConclusion\n\tAbbreviations\n\tAcknowledgements\n\tAuthors’ contributions\n\tFunding\n\tAvailability of data and materials\n\tCompeting interests\n\tAuthor details\n\tReferences\n\tPublisher’s Note\n\n",
      "metadata_storage_path": "aHR0cHM6Ly9jb3Jwb3JhdGV0cmFpbmluZ3N0b3JhZ2UuYmxvYi5jb3JlLndpbmRvd3MubmV0L3BhcGVycy9zMTM2NDAtMDIwLTAwNTQ1LXoucGRm0",
      "metadata_author": "Haoliang Cui",
      "metadata_title": "A classification method for social information of sellers on social network",
      "metadata_creation_date": "2021-01-12T23:22:39Z",
      "keyphrases": [
        "classification method",
        "social information",
        "social network",
        "sellers"
      ]
    },
    {
      "@search.score": 0.558827,
      "content": "\nMobile marketing recommendation method \nbased on user location feedback\nChunyong Yin1 , Shilei Ding1 and Jin Wang2*\n\nIntroduction\nIn recent years, the e-commerce industry has developed rapidly with the popularization \nof the Internet. At this time, famous e-commerce platforms such as Alibaba and Ama-\nzon were born. E-commerce moved physical store products to a virtual network plat-\nform. On the one hand, it is convenient for users to buy various products without leaving \nthe home. On the other hand, it is also convenient for sellers to sell their own goods \nand reduce costs. However, the various products have made it more difficult for users \nto select products. E-commerce platform can generate a large amount of user location \nfeedback data which contains a wealth of user preference information [1]. It is significant \nto predict the location of the next consumer’s consumption from these behavioral data. \nAt present, most of the recommended methods focus on the user-product binary matrix \nand directly model their binary relationships [2]. The users’ location information and \nshopping location information are considered as the third factor. In this case, you can \nonly use the limited check-in data. The users’ location feedback behavior and the timeli-\nness of behavior are often overlooked.\n\nThe mobile recommendation system takes advantage of the mobile network environ-\nment in terms of information recommendation and overcomes the disadvantages. Filter-\ning irrelevant information by predicting potential mobile user preferences and providing \n\nAbstract \n\nLocation-based mobile marketing recommendation has become one of the hot spots \nin e-commerce. The current mobile marketing recommendation system only treats \nlocation information as a recommended attribute, which weakens the role of users and \nshopping location information in the recommendation. This paper focuses on location \nfeedback data of user and proposes a location-based mobile marketing recommenda-\ntion model by convolutional neural network (LBCNN). First, the users’ location-based \nbehaviors are divided into different time windows. For each window, the extractor \nachieves users’ timing preference characteristics from different dimensions. Next, we \nuse the convolutional model in the convolutional neural network model to train a \nclassifier. The experimental results show that the model proposed in this paper is better \nthan the traditional recommendation models in the terms of accuracy rate and recall \nrate, both of which increase nearly 10%.\n\nKeywords: Location feedback, Mobile marketing, Convolutional neural network, \nSequential behavior\n\nOpen Access\n\n© The Author(s) 2019. This article is distributed under the terms of the Creative Commons Attribution 4.0 International License \n(http://creat iveco mmons .org/licen ses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, \nprovided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and \nindicate if changes were made.\n\nRESEARCH\n\nYin et al. Hum. Cent. Comput. Inf. Sci.            (2019) 9:14  \nhttps://doi.org/10.1186/s13673-019-0177-6\n\n*Correspondence:   \njinwang@csust.edu.cn \n2 School of Computer & \nCommunication Engineering, \nChangsha University \nof Science & Technology, \nChangsha 410004, China\nFull list of author information \nis available at the end of the \narticle\n\nhttp://orcid.org/0000-0001-5764-2432\nhttp://creativecommons.org/licenses/by/4.0/\nhttp://crossmark.crossref.org/dialog/?doi=10.1186/s13673-019-0177-6&domain=pdf\n\n\nPage 2 of 17Yin et al. Hum. Cent. Comput. Inf. Sci.            (2019) 9:14 \n\nmobile users with results that meet users’ individual needs gradually become an effec-\ntive means to alleviate “mobile information overload” [3]. Mobile users have different \npreferences in different geographical locations. For this problem, how to use location \ninformation to obtain mobile users’ preferences and provide accurate personalized \nrecommendations has become a hot topic in mobile recommendation research [4]. \nAlthough there are many researches based on location recommendation, they mainly \nfocus on service resources without positional relevance. To solve the shortcomings of \nresearch on location relevance of service resources is few [5], Zhu et  al. [6] proposed \nthe method which is based on the user’s context information to analyze the user’s pref-\nerences and retrograde. Their approach is to derive user preferences by proposing two \ndifferent assumptions and then recommending user models based on preference analy-\nsis. Yin et al. [7] proposed LA-LDA. The method is a location-aware based generation \nprobability model, which uses scoring based on location to model user information and \nrecommend to users. However, these methods only treat location information as an \nattribute without considering the spatial information of users or items and weaken loca-\ntion information’s role in the recommendation. There are some studies determine user \npreferences by the distance between the mobile user and the merchant [8], but only set \nthe area based on the proximity of the distance and ignore the spatial activities of the \nmobile user [9]. However, these methods were limited to the analysis of user informa-\ntion and product information, and did not carefully consider the importance of user and \nbusiness location information. Therefore, the user preference model based on location \nrecommendation they created has some gap.\n\nConsidering the core of mobile marketing recommendation is location movement, \nLian et al. [10] proposed an implied feature-based cognitive feature collaborative filter-\ning (ICCF) framework, which avoids the impact of negative samples by combining con-\nventional methods and semantic content. In terms of algorithms, the author proposed \nan improved algorithm that can expand according to data size and feature size. To deter-\nmine the relevance of the project to user needs, Lee et al. [11] developed context infor-\nmation analysis and collaborative filtering methods for multimedia recommendations in \nmobile environments. Nevertheless, these methods only used small-scale training data \nand could not achieve accurate prediction of long-term interest for users. In this paper, \ndeep learning and time stamps are used to compensate for these shortcomings.\n\nWith great achievements in visual and speech tasks, the Deep Learning (DL) model \nhas become a novel field of study [12]. Because of the interventional optimization of \ndeep learning algorithms, artificial intelligence has made great breakthroughs in many \naspects. It is well known that models obtained through deep learning and machine learn-\ning models have very similar effects, which learns advanced abstract features from the \noriginal input features by simulating the network structure of the human nervous sys-\ntem. Experiments show that the deep model can express the characteristics of the data \nbetter than the shallow model [13]. Weight sharing by convolution makes CNN similar \nto biological neural networks, which reduces the difficulty of network structure and the \nnumber of weights. The structure of CNN is roughly divided into two layers. It is well \nknown that the first layer is a convolutional layer. Each neuron’s input is connected to the \nprevious layer through a convolution kernel and the local features are extracted. Next \nlayer is a pooling layer. In this layer, the neurons in the network are connected through \n\n\n\nPage 3 of 17Yin et al. Hum. Cent. Comput. Inf. Sci.            (2019) 9:14 \n\na convolution kernel to extract the overall features. Convolutional neural networks have \ngreat advantages in processing two-dimensional features [14], such as images.\n\nBased on our detailed comparative analysis, this paper proposes a location-based \nmobile marketing recommendation model by convolutional neural network (LBCNN). \nFirstly, we use user-product information as a training sample, and treat this problem as \na two-class problem. The category of the problem is divided into the purchase behav-\nior and the purchase behavior of the product at the next moment. In order to capture \nthe user’s timing preference characteristics, we divide the behavior of the merchandise \naccording to a certain length of time window and dig deeper into the behavior charac-\nteristics of each time window. Secondly, we consider the users’ timing preferences and \noverall preferences for the product. Then, the features of time window are used to train \nconvolutional neural network models. Finally, we input the sample features of the test \nset into the model and generate the Top-K sample as the location-based purchase fore-\ncast results [15].\n\nRemain of the paper is divided into four sections. Related work is shown in “Related \nwork” section. Necessary definitions and specific implementation of the location-based \nmobile marketing recommendation model by convolutional neural network (LBCNN) \nare shown in “Location-based mobile marketing recommendation model by CNN” sec-\ntion. In “Experimental analysis” section, experimental analysis is introduced. “Conclu-\nsion” section summarizes the strengths and weaknesses of the paper and proposes plans \nfor future progress.\n\nRelated work\nIn the current chapter, we will review existing methods for recommending systems \nthat can be broadly divided into three parts: content filtering, collaborative filtering \nand hybrid methods. We also discuss the establishment of feature models based on \ntime series to clearly represent the differences between our research and other existing \nmethods.\n\nTraditional recommendation method\n\nIn the general products recommendation system, the similarity between users is calcu-\nlated by the user’s interest feature vector. Then, the system recommends some products \nwith similarity greater than a certain threshold or the similar Top-N products to the tar-\nget user. This is a traditional recommendation algorithm based on content and the rec-\nommendation is based on comparing users.\n\na. Content‑based recommendation method\n\nContent-based information filtering has proven to be an effective application for \nlocating text documents related to topics. In particular, we need to focus on the \napplication of content-based information filtering in the recommendation system. \nContent-based methods allow for accurate comparisons between different texts \nor projects, so the recommended results are similar to the historical content of the \nuser’s consumption. The content-based recommendation algorithm involves the fol-\nlowing aspects. User description file describes the user’s preferences, which can be \nfilled by the user and dynamically updated based on the user’s feedback information \n\n\n\nPage 4 of 17Yin et al. Hum. Cent. Comput. Inf. Sci.            (2019) 9:14 \n\n(purchasing, reading, clicking, etc.) during the operation of the system. The project \nprofile describes the content characteristics of each project, which constitutes the \nfeature vector of the project. In addition, the similarity calculation is the similarity \nbetween the user’s description file and the item feature vector.\n\nThe similarity calculation of the content-based recommendation algorithm usually \nadopts the cosine similarity algorithm. The algorithm needs to calculate the similarity \nbetween the feature vector of user u and the feature vector of item i. The calculation \nformula is as shown in Formula (1).\n\nwhere ⇀u denotes the user feature vector, \n⇀\n\ni  denotes the project feature vector, \n⇀\n\n|u| is the \nmodulus of the user feature vector and \n\n⇀\n\n|i| is the model of the project feature vector.\nRepresentative content-based recommendation systems mainly include Lops, \n\nGemmis, and Semeraro [16]. Compared to other methods, content-based recom-\nmendations have no cold-start issues and recommendations are easy to understand. \nHowever, the content filtering based recommendation method has various draw-\nbacks, such as strongly relying on the availability of content and ignoring the context \ninformation of the recommended party. The content-based recommendation method \nalso has certain requirements for the format of the project. Besides, it is difficult to \ndistinguish the merits of the project. The same type of project may have the same type \nof features, which are difficult to reflect the quality of the project.\n\nb. Collaborative filtering method\n\nThe recommendation based on collaborative filtering solves the recommendation \nproblem by using the information of similar users in the same partition to analyze and \nrecommend new content that has not been scored or seen by the target user.\n\nRegarding the traditional collaborative filtering method based on memory, we \nunderstand that this method is based on the different relationships between users and \nprojects. According to expert research, the traditional collaborative filtering method \nbased on memory should be divided into the following three steps.\n\nStep 1: collection of user behavior data, this step represents the user’s past behav-\nior with a m * n matrix R. The matrix  Umn represents the feedback that the user m \nhas on the recommended object n. Rating is a range of values and different values \nrepresent how much the user likes the recommended object.\n\nStep 2: establishment of a user neighbor: establish mutual user relationships by \nanalyzing all user historical behavior data.\n\n(1)sim(u, i) =\n\n⇀\nu ·\n\n⇀\n\ni\n\n⇀\n\n|u|\n⇀\n\n|i|\n\nU =\n\n\n\n\n\n\n\nU11 U12 . . . U1n\n\nU21 U22 . . . U2n\n\n. . . . . . . . . . . .\n\nUm1 Um2 . . . Umn\n\n\n\n\n\n\n.\n\n\n\nPage 5 of 17Yin et al. Hum. Cent. Comput. Inf. Sci.            (2019) 9:14 \n\nStep 3: generate recommendation results: find the most likely N objects from the rec-\nommended items selected by similar user sets.\n\nTherefore, recommendations are made by mining common features in similar users’ pref-\nerence information [17]. The normal methods in this classification include k-nearest neigh-\nbor (k-NN), matrix decomposition, and semi-supervised learning. According to the survey, \nAmazon uses an item-by-item collaborative filtering method to recommend personalized \nonline stores for each customer.\n\nCompared to other method, collaborative filtering has the ability to filter out informa-\ntion that can be automatically recognized by the machine and effectively use feedback from \nother similar users. However, collaborative filtering requires more ratings for the project, \nso it is affected by the issue of rating sparsity. In addition, this method does not provide a \nstandard recommendation for new users and new projects, which is called a cold start issue.\n\nc. Hybrid recommendation method\n\nThe hybrid recommendation method combines the above techniques in different ways to \nimprove the recommended performance and optimize the shortcomings of the conven-\ntional method. Projects that cannot be recommended for collaborative filtering are gener-\nally addressed by combining them with content-based filtering [18].\n\nThe core of this method is to independently calculate the recommendation results of the \ntwo types of recommendation algorithms, and then mix the results. There are two specific \nhybrid methods. One method is to mix the predicted scores of the two algorithms linearly. \nAnother hybrid method is to set up an evaluation standard, compare the recommended \nresults of the two algorithms, and take the recommendation results of the higher evaluation \nalgorithms. In general, the hybrid recommendation achieves a certain degree of compensa-\ntion between different recommendation algorithms. However, the hybrid recommendation \nalgorithm still needs improvement in complexity.\n\nd. Recommendation based on association rules\n\nThe association rule algorithm is a traditional data mining method that has been widely \nused in business for many years. The core idea is to analyze the rules of user historical \nbehavior data to recommend more similar behavioral items [19]. Rules can be either user-\ndefined or dynamically generated by using rule algorithms. The effect of the algorithm \ndepends mainly on the quantity and quality of the rules so the focus of the algorithm is on \nhow to develop high quality rules.\n\nDefine N as the total number of transactions, R is the total project and U and V are two \ndisjoint sets of items (U∩V ≠ ∅, U∈R, V∈R). The association rule is essentially an IF–Then \nstatement, here is expressed by U → V. The strength of the association rule U → V can be \nmeasured by two criteria: support and confidence. S is the ratio containing U and V data \nwhich both represent the number of transactions, which is shown in Formula (2).\n\nC is the ratio of U, V data to the only U data which represents the number of transac-\ntions, as shown in Formula (3)\n\n(2)S(U → V ) =\nN (U ∪ V )\n\nN\n.\n\n\n\nPage 6 of 17Yin et al. Hum. Cent. Comput. Inf. Sci.            (2019) 9:14 \n\nThe recommendation process of the algorithm is shown in below.\nFirstly, according to the items of interest to the user, the user’s interest in other \n\nunknown items is predicted by rules. Secondly, compare the support of the rules. Finally, \nthe recommended items of TOP-N are obtained to the user.\n\nThe recommendation system based on association rules includes three parts: the key-\nword, the presentation and the user interface. The keyword layer is a set of keyword \nattributes and dependencies between keywords. The description layer connects the \nkeyword layer and the user layer and the main function is to describe the user and the \nresource. The user interface layer is the layer that interacts directly with the user. How-\never, the system becomes more and more difficult to manage as the rules increasing. In \naddition, there is a strong dependence on the quality of the rules and a cold start prob-\nlem is existed.\n\nMost of the recommendation systems use collaborative filtering algorithm to recom-\nmend for users. However, the traditional algorithm can only analyze ready-made data \nsimply, and most systems simply preprocess the data. In our method, we preprocess the \ndataset by extending the time information of the data to a time label. The next section is \nan explanation of the specific implementation.\n\nConstruction of time series behavior’s preference features\n\nThe timing recommendation model is based primarily on the Markov chain. This model \nmakes full use of timing behavior data to predict the next purchase behavior based on \nthe user’s last behavior. The advantage of this model is that it can generate good recom-\nmendations by timing behavior.\n\nAs shown in Fig. 1, the prediction problem of product purchase can be expressed as \npredicts the user’s purchase behavior at time T by a user behavior record set D before \ntime T [20]. Different actions occur at different times. For example, user1 visit location \na and b when user1 purchasing b and c at T − 3. We need to predict T-time consumer \nbehavior based on different timing behavior characteristics.\n\nAccording to relevant professional research, we divide the data sets of user behav-\nior into three groups in a pre-processing manner. By the feature statistics method, the \n\n(3)C(U → V ) =\nN (U ∪ V )\n\nN\n.\n\nFig. 1 The time series of user position feedback\n\n\n\nPage 7 of 17Yin et al. Hum. Cent. Comput. Inf. Sci.            (2019) 9:14 \n\nfeatures are divided into two types, as shown in Table 1. “True” indicates that the feature \ngroup has corresponding features. Conversely, “False” means no such feature. Next we \nexplain these features.\n\na. Counting feature\n\nFor each feature statistics window, we use the behavioral counting feature and the de-\nduplication counting feature. The behavior count is a cumulative measure of the num-\nber of behaviors that occurred in and before the current window. For the location visit \nbehavior, it represents the number of visits to the product location by the user, the total \nnumber of visits by the user and the total number of visits to the merchandise. The de-\nduplication count feature is similar to the behavioral count, but only the number of non-\nrepetitive behavioral data is counted.\n\nb. Mean feature\n\nIn order to describe the activity of the user and the popularity of the product better, \nthis article derives a series of mean-type features based on the counting features. Take \nthe location visit behavior as an example, the user characteristics group includes the \nuser’s average number of visiting to the product. The average number of visiting to \nthe product by user i is calculated as shown in Formula (4).\n\nc. Ratio feature\n\nThe ratio of user-product behavior to the total behavior of the user and the product \nis also an aspect affecting the user’s degree of preference for the product. In the time \nwindow t, the method to calculate the ratio of the user’s visit to the products’ total \nvisit is shown in Formula (5).\n\nOur work presents a mobile marketing recommendation model is trained by adding \nthe time axis to the user position features. Contrary to current research, it is highly \nusable and low difficulty of achievement for real-world work applications. Consider-\ning the speed of calculation, we study the method of directly embedding time series \ninformation into the collaborative filtering calculation process to improve the recom-\nmendation quality. Specific information will be covered in the following sections.\n\n(4)avgui(t, i, visit) =\naction_count(t,U ,Ui, visit)\n\nuser_unique_item(t,U ,Ui, visit)\n.\n\n(5)rate_ui_in_u(t, i, j, visit) =\naction_count(t,UI ,Ui, Ij, visit)\n\naction_count(t,U ,Ui, visit)\n.\n\nTable 1 Characteristic system diagram (True/False)\n\nFeature group Counting feature Mean feature Ratio feature\n\nUser-product True False True\n\nUser feature True True False\n\nProduct feature True True False\n\n\n\nPage 8 of 17Yin et al. Hum. Cent. Comput. Inf. Sci.            (2019) 9:14 \n\nLocation‑based mobile marketing recommendation model by CNN\nCreating the model is one of the most important aspects, which is an evaluation crite-\nrion to make sure correctness of the next step. This section mainly describes the rel-\nevant definitions of LBCNN that are shown in “Relevant definitions of the LBCNN” \nsection, and specific implementation of the model is shown in “Specific implementa-\ntion of the model” section.\n\nRelevant definitions of the LBCNN\n\nIn order to get better feature expression, we consider the user’s timing sensitivity of the \nproduct preferences and the user’s overall preferences comprehensively. This paper uses a \nconvolutional neural network as the basis to build location-based mobile marketing recom-\nmendation model. In the next step, we give the relevant definition.\n\na. Definition 1 (Model framework): based on the above analysis and user’s timing behav-\nior preference feature. We use the convolutional neural network model shown in Fig. 2. The \nmodel is divided into four layers that are input layer, multi-window convolution layer, pool-\ning layer and output layer. The input layer is a well-constructed input feature which trans-\nforms the input features into a two-dimensional plane by time series. Each time window is \nexpressed as an eigenvector. The multi-window convolutional layer convolves the input fea-\nture plane through different lengths of time windows to obtain different feature maps. The \npooling layer reduces the dimension of the feature map to obtain a pooled feature vector. \nThe output layer and the pooling layer are fully connected network structures.\n\nb. Definition 2 (Convolution layer): assume that there are N time windows of the feature \nand each time window has K user preference feature for the commodity. Then input sam-\nple × can be expressed as a matrix of T × K. The feature map in the convolutional layer is \ncalculated by the input layer and the convolution kernel. The window length of the convolu-\ntion kernel is h. xi,i+j represents the eigenvector added by time window i and time window \ni + j. The convolution kernel w can be expressed as a vector of h × K. Feature map f = [f1, f2, \n…, fT−h+1]. The i-th feature fi is calculated according to Formula (6):\n\n(6)fi = σ(w · xi,i+h−1 + b)\n\nFig. 2 The framework of the LBCNN\n\n\n\nPage 9 of 17Yin et al. Hum. Cent. Comput. Inf. Sci.            (2019) 9:14 \n\nwhere b is an offset term and a real number. σ(x) is a nonlinear activation function. This \npaper uses ReLu and Tanh as an activation function. Relu is shown in Formula (7):\n\nc. Definition 3 (Max-pooling): the pooling layer is to scale the feature map while reduc-\ning the complexity of the network. The maximum features of the convolution kernel can \nbe obtained according to the maximum pooling operation. The feature map obtained \nat the kth product of the convolutional kernel is fk = [fk,1, fk,2, …, fk,T−h +1]. The pooling \noperation can be expressed as Formula (8):\n\nd. Definition 4 (Probability distribution): there are M convolution kernels and the output \nlayer has C categories [19]. The weight parameter θ of the output layer is a C × M matrix. \nThe pooled feature f̂  of x is an M-dimensional vector. The probability that x belongs to \nthe i-th category can be expressed as Formula (9):\n\nwhere  bk represents the k-th offset of the fully connected layer. The loss function of the \nmodel can be obtained by the likelihood probability value, as shown in Formula (10):\n\nwhere T is the training data set,  yi is the real category of the i-th sample, xi is the charac-\nteristic of the i-th sample and θ is the model’s parameters. We learn model parameters \nby minimizing the loss function. The training method adopts the improved gradient \ndescent method proposed by Zeiler. In addition, we have adopted Dropout process-\ning on the convolutional layer to prevent over-fitting of the trained model [21]. The \nDropout method randomizes the neurons in the convolutional layer to 0 with a certain \nprobability.\n\ne. Definition 5 (Latent factor): the value of the latent factor vector is true [22]. Whether \nan item belongs to a class is determined entirely by the user’s behavior. We assume that \ntwo items are liked by many users at the same time, then these two items have a high \nprobability of belonging to the same class. The weight of an item in a class can also be \ncalculated by itself. The implicit semantic model calculates the user’s (u) interest in the \nitem (i) are shown in Formula (11):\n\n(7)\nReLu = max(0, x).\n\nTanh(x) =\nex − e−x\n\nex + e−x\n.\n\n(8)Pool_feature(j) = down(fi).\n\n(9)p(i|x, θ) =\ne(θi·\n\n⌢\nf +bi)\n\n∑C\nk−1 e\n\n(θk ·\n⌢\nf +bk )\n\n(10)J (θ) = −\n\nk\n∑\n\ni=1\n\nlog(p(yi|x, θ))\n\n(11)R(u, i) = rui = pTu qi =\n\nF\n∑\n\nf=1\n\npu,kqi,k\n\n\n\nPage 10 of 17Yin et al. Hum. Cent. Comput. Inf. Sci.            (2019) 9:14 \n\nwhere p is the relationship between the user interest and the kth implicit class. q is the \nrelationship between the kth implicit class and the item i. F is the number of hidden \nclasses, and r is the user’s interest in the item.\n\nSpecific implementation of the model\n\nWe can draw from Fig. 3 that the proposed model is divided into two processes. The first \nprocess is the training process and includes two parts. The top module shows how to gener-\nate CNN inputs and outputs from historical data. The other module in the training process \nshows that the traditional CNN parameters are trained by provided data. The second pro-\ncess finished a new location-based marketing resources recommendation. The recommen-\ndation process can work through the CNN parameters provided by the training process.\n\nTo achieve the features of users and location-based mobile marketing resources, the \nlatent factor model (LFM) is used. In traditional LFM, L2-norm regularization is often used \nto optimize training results. However, using L2-norm regularization often leads to excessive \nsmoothing problems. In our model, LFM results are used to represent the characteristics of \nthe training data. In this kind of thinking, we can learn from the training method of regres-\nsion coefficient in regression analysis, and construct a loss function. Therefore, it is more \nreasonable to use sparseness before the specification results. Based on these analyses, we \npropose an improved matrix decomposition method and try to normalize the solution by \n\nFig. 3 Location-based mobile marketing recommendation model by convolutional neural network\n\n\n\nPage 11 of 17Yin et al. Hum. Cent. Comput. Inf. Sci.            (2019) 9:14 \n\nusing the premise of verifying the sparseness of the matrix. The model is presented as For-\nmula (12):\n\nThe next question is how to calculate these two parameters p and q. For the calculation \nof this linear model, this paper uses the gradient descent method. In the Formula (12), \n puk is a user bias item that represents the average of a user’s rating.  qik is an item offset \nitem that represents the average of an item being scored. The offset term is an intrinsic \nproperty that indicates whether the item is popular with the public or a user is harsh \non the item. For positive samples, we specify  ru,i = 1 based on experience and negative \nsample  ru,i = 0, which is shown in Formula (11). The latter λ is a regularization term to \nprevent overfitting.\n\na. Description of the training section\n\nIn Fig. 3, If you want to train CNN, the first thing you need to solve is its input and out-\nput problems. For input, a language model is usually used.\n\nIn terms of output, we propose an improvement in model training by LFM, which is \nconstrained by the regularization of the L1-norm [23]. LFM training data is a historical \nscore between the user and the location-based marketing resources. The rating score can \nbe explicit because it is based on a user tag or an implied tag and it is predicted from the \nuser’s behavior. In this model, in order to ensure that the trained model is representative, \nthe training data we input is to select the existing authoritative standard training set.\n\nb. Description of the recommended part\n\nOnce the LBCNN model structure is established and the model parameters are trained \nusing the training data set, the recommended real-time performance can be achieved. \nThe real-time performance is based on the update of network model parameters in the \nbackground, and it uses some past behavior data and information of the recommended \npeople and products.\n\nUser information and product information can be obtained in advance and digitized. \nIn the offline training model phase, digitized user information, product information, and \nbehavior information are utilized [24]. The same model is trained for the same type of \nusers, and the parameters of the model are periodically updated within a certain period \nof time. In the real-time recommendation stage, real-time recommendation can be real-\nized only by integrating the collected behavior data with the previous data and inputting \nit into the model.\n\nExperimental analysis\nIn order to verify the advantages of convolutional neural network in capturing user’s \ntiming preferences for product and mining users’ temporal behavior characteristics, \nwe compare several commonly used classification models under the same conditions of \ntraining features. They are Linear Logistic Regression Classification Model (LR), Support \n\n(12)J (U ,V ) =\n∑\n\nu,i∈K\n\n(\n\nru,i −\n\nk\n∑\n\nk=1\n\npu,kqi,k\n\n)2\n\n+ ��puk�\n2 + ��qik�\n\n2.\n\n\n\nPage 12 of 17Yin et al. Hum. Cent. Comput. Inf. Sci.            (2019) 9:14 \n\nVector Machine (SVM), Random Forest Model (RF) and Gradient Boosting Regression \nTree Model (GBDT) [25]. We also compare the products that have been visited for the \nlast 8 h. Experimental tool is sklearn kit. The hyper parameter settings for each model \nduring the experiment are:\n\na. LR: select L2 regular and the regularization coefficient is 0.1.\nb. SVM: choose radial basis kernel function (RBF) and gamma of kernel function is \n\n0.005.\nc. RF: the number of trees is 200, the entropy is selected as the feature segmentation \n\nstandard and the random feature ratio is 0.5.\nd. GBDT: the number of trees is 100, the learning rate is 0.1 and the maximum depth of \n\nthe tree is 3.\n\nDescription of the data set\n\nThe experiment in our paper uses the dataset disclosed according to the Alibaba Group’s \nmobile recommendation algorithm contest held in 2015. This data set contains 1 month \nof user behavior data and product information. The user’s behavior data includes 10 mil-\nlion users’ various behaviors on 2,876,947 items. Behavior types include clicks, shopping \ncarts and purchases. In addition, each behavior record identifies behavior time that is \naccurate to the hour. The product information includes product category information, \nand identifies whether the product is an online to offline type. In a real business sce-\nnario, we often need to build a personalized recommendation model for a subset of all \nproducts. In the process of completing this task, we not only need to take advantage of \nthe user’s behavior data on this subset of goods, but also need to use more abundant user \nbehavior data. We need to define the following symbols: U (User collection), I (Product \ncollection), P (Product subset, P ⊆ I), D (User behavior data collection for the complete \nset of products). Our goal is to use D to construct a recommendation model for users in \nU to products in P.\n\nThe data mainly consists of two parts. The first part is the mobile behavior data (D) of \n10 million users on the product collection, including the following fields, as shown in \nTable 2.\n\nFor example, “141278390, 282725298, 1, 95jnuqm, 5027, 2014-11-18 08” is one of \nthe data. The Behavior_type and the Time in these fields contain the largest amount \n\nTable 2 The mobile behavior data of the Ali mobile recommendation data set\n\nField Field description Extraction instruction\n\nUser_id User differentiation Sampling and data masking\n\nItem_id Product differentiation Data masking\n\nBehavior_type The type of behavior of the user on the \nproduct\n\nIncluding browsing, collecting, adding shop-\nping carts, and purchasing, the values are 1, 2, \n3, 4 respectively\n\nUser_geoinfo The spatial reference identifier of the user’s \nlocation\n\nFormed by latitude and longitude data through \na secret algorithm\n\nItem category Product classification identifier Field masking\n\nTime Action time Accurate to hour level\n\n\n\nPage 13 of 17Yin et al. Hum. Cent. Comput. Inf. Sci.            (2019) 9:14 \n\nof information. The User_geohash field is basically unusable due to too many missing \nvalues.\n\nThe second part is the product subset (P), which contains the following fields, as \nshown in Table 3.\n\nSimilar to the above, “117151719, 96ulbnj, 7350” is one of the product information. \nThe training data contains the mobile behavior data (D) of a sample of a certain user \nwithin 1 month (11.18–12.18). The scoring data is the purchase data of the product sub-\nset (P) by these users 1 day (12.19) after this 1 month. We should be training the data \nmodel to output the predicted results of the user’s purchase behavior on the next day.\n\nData preprocessing\n\nWe found that there are some users have a lot of page views (maximum of 2 million), which \nis beyond reasonable levels. We analyze that these users may be crawler users, so the behav-\nior of these users on the goods is not the basis for predicting the user’s purchase. At the \nsame time, we predict the user product pairs that have appeared in all historical records. \nThe existence of these users will undoubtedly increase our forecasting amount and interfere \nwith our normal model training. Therefore, we choose to filter out these users, the filtering \nrules are shown as Fig. 4.\n\nTable 3 The product subset of the Ali mobile recommendation data set\n\nField Field description Extraction instruction\n\nItem_id Product differentiation Sampling and data masking\n\nItem_geohash Spatial information of the product location, \nwhich can be empty\n\nFormed by latitude and longi-\ntude data through a secret \nalgorithm\n\nItem_category Product classification identifier Data masking\n\nFig. 4 Data filtering rules\n\n\n\nPage 14 of 17Yin et al. Hum. Cent. Comput. Inf. Sci.            (2019) 9:14 \n\nEvaluation index\n\nThe purpose of the proposed method is to predict the user’s purchased business in the next \nposition based on the user’s historical behavior record. Therefore, we evaluate the model \nwith the data of the last day. The sample construction of time series method is shown in \nFig.  1. F1-score can be viewed as a harmonic mean of accuracy and recall. At present, \nF1-score has been widely used in the evaluation of the recommendation system.\n\nwhere Formula (13) is the calculation method of the accuracy rate, Formula (14) is the \ncalculation method of the recall rate, and Formula (15) is the calculation method of \nF1-score. Prediction_set is the predicted purchase of the user-item. Answer_set is a real-\npurchased user-item collection.\n\nThe distribution of positive and negative samples used in this experiment is extremely \nunbalanced, and negative samples contain more noise. In order to make the model more \nsuitable for learning under unbalanced data, we perform under sampling on negative \nsamples. The model training process adopts AdaDelta Update Rule to adjust the param-\neters by using the stochastic gradient descent method. Hyper Parameters of the model \nare described in Table 4. The value in the table is the final hyper parameter when the \nerror of the validation set is minimal. Convolution time window in convolution kernel \nis 2 and 3. The number of convolution kernels for two different length windows is 200. \nIn this experiment, the training process needs to iterate ten times. To achieve the con-\nvergence of the model, we observe the accuracy of the training set every iteration in the \nmodel training process.\n\nIn Fig. 5, the abscissa indicates the number of iterations, and the ordinate indicates the \naccuracy of the sample. As we can see from the figure, the accuracy of the training set \nhas been increasing and the verification set accuracy has declined after the fifth iteration \nof the model [26]. This situation shows that the model training has been overfitting after \n\n(13)precision =\n\n∣\n\n∣prediction_set ∩ answer_set\n∣\n\n∣\n\n∣\n\n∣prediction_set\n∣\n\n∣\n\n(14)Recall =\n\n∣\n\n∣prediction_set ∩ answer_set\n∣\n\n∣\n\n|answer_set|\n\n(15)F1− score =\n2× precision× recall\n\nprecision+ recall\n\nTable 4 Parameter settings of convolutional neural networks\n\nParameter name Parameter value\n\nActivation function of convolution kernel Tanh\n\nSize of convolution kernel window [2, 3]\n\nNumber of convolution kernel 400\n\nDropout ratio 0.5\n\nBatch size 64\n\nEpoch 5\n\n\n\nPage 15 of 17Yin et al. Hum. Cent. Comput. Inf. Sci.            (2019) 9:14 \n\nthe 5th iteration. In addition, we found that the test set accuracy is higher than the train-\ning set and verification set.\n\nExperimental results and comparison\n\nThe experimental results obtained using the above parameters are shown in Table 5. As \ncan be seen from Table  5, the machine learning model using the features designed in \nthis paper is superior to the traditional method. Our model achieves an 80% accuracy \nin predicting the accuracy of user behavior, which is significantly better than traditional \nmodels at least 10%. In terms of recall rate, LBCNN reached 8.14%, which is at least 2% \nhigher than the traditional method. Similarly, our model is up to 8.07% in F1-score.\n\nThis result shows that the user’s time-series behavior preference model is reasonable. \nThis solution works well for improving the accuracy and quality of recommendations. In \na single model, the LBCNN model works best. Since the linear model assumes that each \nfeature is independent, it is impossible to excavate the intrinsic relationship between \nfeatures. The proposed method can mine the intrinsic link between user timing prefer-\nence features better. The experimental results show that the user preferences we build \nare more accurate and convolutional neural networks have strong capabilities of feature \nextraction and model generalization.\n\nFig. 5 Training process of the LBCNN\n\nTable 5 Comparing the experimental results of each model (%)\n\nModel Accuracy Recall rate F1-score\n\nTraditional method 31.4 5.60 4.02\n\nLR 75.0 7.63 7.57\n\nSVM 70.0 7.12 7.06\n\nRF 57.5 5.85 5.80\n\nGBDT 62.5 6.36 6.13\n\nLBCNN 80.0 8.14 8.07\n\n\n\nPage 16 of 17Yin et al. Hum. Cent. Comput. Inf. Sci.            (2019) 9:14 \n\nConclusion\nThe current mobile marketing recommendation system only treats location informa-\ntion as a recommended attribute, which weakens the role of the location information in \nthe recommendation. For the implicit feedback behavior of users, this paper proposes \na location-based mobile marketing method by convolutional neural network. First, we \ndivide the user location-based behaviors into several time windows according to the \ntimestamp of these behaviors, and model the user preference in different dimensions \nfor each window. Then we utilize the convolutional neural network to train a classifier. \nFinally, the experimental process of this paper is introduced, and a good prediction effect \nis obtained on effective data sets. The final experimental results express that the pro-\nposed method has different feature extraction perspectives from other models. Because \nof using convolutional neural networks, the proposed method has stronger capability \nof feature extraction and generalization. This method helps to change the accuracy and \nquality of the recommendation system and user satisfaction.\n\nThe work introduced here is to show the prospects for further research. The method \nproposed in this paper has a certain dependence on the user’s geographical location \ninformation during the training process of the user preference model. In addition, the \nrecommendation system will encounter a cold-start problem with sparse user infor-\nmation. For dealing with these discovered issues, we plan to use the hot start case to \nimprove the recommended cold start problem. Meanwhile, we are investigating new \nmethod which uses a better big data framework (such as Hadoop MapReduce) to ensure \nthe efficiency of training large data sets. In the future, we will show recommended meth-\nods to improve performance in other applications.\nAuthors’ contributions\nCY conceptualized the study and analyzed all the data. SD performed all experiments and wrote the manuscript. JW \nadvised on the manuscript preparation and technical knowledge. All authors read and approved the final manuscript.\n\nAuthor details\n1 School of Computer and Software, Jiangsu Engineering Center of Network Monitoring, Nanjing University of Informa-\ntion Science & Technology, Nanjing 210044, China. 2 School of Computer & Communication Engineering, Changsha \nUniversity of Science & Technology, Changsha 410004, China. \n\nAcknowledgements\nIt was supported by the Priority Academic Program Development of Jiangsu Higher Education Institutions (PAPD), Post-\ngraduate Research & Practice Innovation Program of Jiangsu Province (KYCX18_1032).\n\nCompeting interests\nThe authors declare that they have no competing interests.\n\nAvailability of data and materials\nWe declared that materials described in the manuscript will be freely available to any scientist wishing to use them for \nnon-commercial purposes.\n\nFunding\nThis work was supported by the National Natural Science Foundation of China (61772282, 61772454, 61811530332, \n61811540410).\n\nPublisher’s Note\nSpringer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.\n\nReceived: 25 September 2018   Accepted: 4 April 2019\n\nReferences\n 1. Fernández-Tobías I, Braunhofer M, Elahi M, Ricci F, Cantador I (2016) Alleviating the new user problem in collabora-\n\ntive filtering by exploiting personality information. User Model User Adap Inter 26(2–3):221–255\n\n\n\nPage 17 of 17Yin et al. Hum. Cent. Comput. Inf. Sci.            (2019) 9:14 \n\n 2. Koohi H, Kiani K (2016) User based collaborative filtering using fuzzy C-means. Measurement 91:134–139\n 3. Xu X, Fu S, Qi L, Zhang X, Liu Q, He Q, Li S (2018) An IoT-oriented data placement method with privacy preservation \n\nin cloud environment. J Netw Comput Appl 124:148–157\n 4. Yingyuan X, Pengqiang A, Ching-Hsien H, Hongya W, Xu J (2015) Time-ordered collaborative filtering for news \n\nrecommendation. China Commun 12(12):53–62\n 5. Kaminskas M, Ricci F (2011) Location-adapted music recommendation using tags. In: International conference on \n\nuser modeling, adaptation, and personalization. pp 183–194\n 6. Zhu H, Chen E, Xiong H, Yu K, Cao H, Tian J (2015) Mining mobile user preferences for personalized context-aware \n\nrecommendation. ACM Trans Intell Syst Technol TIST 5(4):58\n 7. Yin H, Cui B, Chen L, Hu Z, Zhang C (2015) Modeling location-based user rating profiles for personalized recommen-\n\ndation. ACM Trans Knowl Discov Data TKDD 9(3):19\n 8. Li X, Xu G, Chen E, Li L (2015) Learning user preferences across multiple aspects for merchant recommendation. In: \n\n2015 IEEE international conference on data mining (ICDM). pp 865–870\n 9. Yin C, Xi J, Sun R, Wang J (2018) Location privacy protection based on differential privacy strategy for big data in \n\nindustrial internet-of-things. IEEE Trans Industr Inf 14(8):3628–3636\n 10. Lian D, Ge Y, Zhang F, Yuan NJ, Xie X, Zhou T, Rui Y (2015) Content-aware collaborative filtering for location recom-\n\nmendation based on human mobility data. In: 2015 IEEE international conference on data mining. pp 261–270\n 11. Lee WP, Tseng GY (2016) Incorporating contextual information and collaborative filtering methods for multimedia \n\nrecommendation in a mobile environment. Multimedia Tools Appl 75(24):16719–16739\n 12. Bengio Y (2009) Learning deep architectures for AI. Found Trends Mach Learn 2(1):1–127\n 13. LeCun Y, Bengio Y, Hinton G (2015) Deep learning. Nature 521(7553):436–444\n 14. Yuan C, Li X, Wu QJ, Li J, Sun X (2017) Fingerprint liveness detection from different fingerprint materials using convo-\n\nlutional neural network and principal component analysis. Comput Mater Continua 53(4):357–372\n 15. Yin C, Wang J, Park JH (2017) An improved recommendation algorithm for big data cloud service based on the trust \n\nin sociology. Neurocomputing 256:49–55\n 16. Längkvist M, Karlsson L, Loutfi A (2014) A review of unsupervised feature learning and deep learning for time-series \n\nmodeling. Pattern Recogn Lett 42:11–24\n 17. Tu Y, Lin Y, Wang J, Kim JU (2018) Semi-supervised learning with generative adversarial networks on digital signal \n\nmodulation classification. Comput Mater Continua 55(2):243–254\n 18. Nilashi M, Bin Ibrahim O, Ithnin N (2014) Hybrid recommendation approaches for multi-criteria collaborative filter-\n\ning. Expert Syst Appl 41(8):3879–3900\n 19. Zeng D, Dai Y, Li F, Sherratt RS, Wang J (2018) Adversarial learning for distant supervised relation extraction. Comput \n\nMater Continua 55(1):121–136\n 20. Yin C, Xia L, Zhang S, Sun R, Wang J (2018) Improved clustering algorithm based on high-speed network data \n\nstream. Soft Comput 22(13):4185–4195\n 21. Krizhevsky A, Sutskever I, Hinton GE (2012) Imagenet classification with deep convolutional neural networks. In: \n\nAdvances in neural information processing systems, pp 1097–1105\n 22. Li X, Yao C, Fan F, Yu X (2017) A text similarity measurement method based on singular value decomposition and \n\nsemantic relevance. J Inf Process Syst 13(4):863–875\n 23. Li CN, Shao YH, Deng NY (2015) Robust L1-norm two-dimensional linear discriminant analysis. Neural Networks \n\n65:92–104\n 24. Fattah MA (2017) A novel statistical feature selection approach for text categorization. J Inf Process Syst \n\n13(5):1397–1409\n 25. Wang Y, Feng D, Li D, Chen X, Zhao Y, Niu X (2016) A mobile recommendation system based on logistic regression \n\nand Gradient Boosting Decision Trees. In: International joint conference on neural networks. pp 1896–1902\n 26. Yin C, Zhang S, Xi J, Wang J (2017) An improved anonymity model for big data security based on clustering algo-\n\nrithm. Concurr Comput Pract Exp 29(7):e3902\n\n\n\tMobile marketing recommendation method based on user location feedback\n\tAbstract \n\tIntroduction\n\tRelated work\n\tTraditional recommendation method\n\ta. Content-based recommendation method\n\tb. Collaborative filtering method\n\tc. Hybrid recommendation method\n\td. Recommendation based on association rules\n\n\tConstruction of time series behavior’s preference features\n\ta. Counting feature\n\tb. Mean feature\n\tc. Ratio feature\n\n\n\tLocation-based mobile marketing recommendation model by CNN\n\tRelevant definitions of the LBCNN\n\tSpecific implementation of the model\n\ta. Description of the training section\n\tb. Description of the recommended part\n\n\n\tExperimental analysis\n\tDescription of the data set\n\tData preprocessing\n\tEvaluation index\n\tExperimental results and comparison\n\n\tConclusion\n\tAuthors’ contributions\n\tReferences\n\n\n\n\n",
      "metadata_storage_path": "aHR0cHM6Ly9jb3Jwb3JhdGV0cmFpbmluZ3N0b3JhZ2UuYmxvYi5jb3JlLndpbmRvd3MubmV0L3BhcGVycy9zMTM2NzMtMDE5LTAxNzctNi5wZGY1",
      "metadata_author": "Chunyong Yin ",
      "metadata_title": "Mobile marketing recommendation method based on user location feedback",
      "metadata_creation_date": "2019-04-05T10:16:31Z",
      "keyphrases": [
        "Mobile marketing recommendation method",
        "user location feedback"
      ]
    },
    {
      "@search.score": 0.28004232,
      "content": "\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 \nDOI 10.1186/s40493-015-0019-z\n\nRESEARCH Open Access\n\nToward a testbed for evaluating\ncomputational trust models: experiments\nand analysis\nPartheeban Chandrasekaran and Babak Esfandiari*\n\n*Correspondence:\nbabak@sce.carleton.ca\nDepartment of Systems and\nComputer Engineering, Carleton\nUniversity, 1125 Colonel By Drive,\nOttawa, Ontario K1s5B6, Canada\n\nAbstract\nWe propose a generic testbed for evaluating social trust models and we show how\nexisting models can fit our tesbed. To showcase the flexibility of our design, we\nimplemented a prototype and evaluated three trust algorithms, namely EigenTrust,\nPeerTrust and Appleseed, for their vulnerabilites to attacks and compliance to various\ntrust properties. For example, we were able to exhibit discrepancies between\nEigenTrust and PeerTrust, as well as trade-offs between resistance to slandering attacks\nversus self-promotion.\n\nKeywords: Trust testbed; Reputation; Multi-agent systems\n\nIntroduction\nMotivation\n\nWith the growth of online community-based systems such as peer-to-peer file-sharing\napplications, e-commerce and social networking websites, there is an increasing need to\nprovide computational trust mechanisms to determine which users or agents are honest\nand which ones are malicious. Many models calculate trust by relying on analyzing a\nhistory of interactions. The calculations can range from the simple averaging of ratings\non eBay to flow-based scores in the Advogato website. Thus for a researcher to evaluate\nand compare his or her latest model against existing ones, a comprehensive test tool is\nneeded. However, our research shows that the tools that exist to assist researchers are not\nflexible enough to include different trust models and their evaluations. Moreover, these\ntools use their own set of application-dependent metrics to evaluate a reputation system.\nThis means that a number of trust models cannot be evaluated for vulnerabilities against\ncertain types of attacks. Thus, there is still a need for a generic testbed to evaluate and\ncompare computational trust models.\n\nOverview of our solution and contributions\n\nIn this paper, we present a model and a testbed for evaluating a family of trust algo-\nrithms that rely on past transactions between agents. Trust assessment is viewed as a\nprocess consisting of a succession of graph transformations, where the agents form the\nvertices of the graph. The meaning of the edges depends on the transformation stage,\n\n© 2015 Chandrasekaran and Esfandiari. Open Access This article is distributed under the terms of the Creative Commons\nAttribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution,\nand reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to\nthe Creative Commons license, and indicate if changes were made.\n\nhttp://crossmark.crossref.org/dialog/?doi=10.1186/s40493-015-0019-z-x&domain=pdf\nmailto: babak@sce.carleton.ca\nhttp://creativecommons.org/licenses/by/4.0/\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 2 of 27\n\nand can refer to the presence of transactions between the two agents or the existence\nof a trust relationship between them. Our first contribution is to show that with this\nview, existing reputation systems can be adopted under a single model, but they work at\ndifferent stages of the trust assessment workflow. This allows us to present a new classi-\nfication scheme for a number of trust models based on where they fit in the assessment\nworkflow. The second contribution of our work is that this workflow can be described\nformally, and by doing this, we show that it is possible to model a variety of attacks\nand evaluation schemes. Finally, out of the larger number of systems we classified, we\nselected three reputation systems, namely EigenTrust [1], PeerTrust [2] and Appleseed\n[3], to exemplify the range and variety of reputation systems that our testbed can accom-\nmodate. We evaluated these three systems in our testbed against simple attacks and\nwe validated their compliance to basic trust properties. In particular, we were able to\nexhibit differences in the way EigenTrust and PeerTrust rank the agents, we observed\nthe subtle interplay between slandering and self-promoting attacks (higher sensitivity\nto one attack can lead to lower sensitivity to the other), and we verified that trust\nweakens along a friend-of-a-friend chain and that it is more easily lost than gained\n(as it should be).\n\nOrganization\n\nThis article is organized as follows: section ‘Background and literature review’ provides\nbackground and state of the art on trust models, attacks against them, and existing\ntestbeds for evaluation. Section ‘Problem description and model’ formulates the research\nproblem of this article and proposes our model for a testbed. Section ‘Classifying and\nchaining algorithms’ shows how some of existing trust algorithms can fit our model, and\nhow one can combine or compare them using our model and testbed. Section ‘Results and\ndiscussion’ describes the implementation details of our testbed prototype and presents\nevaluation results of three different trust algorithms, namely EigenTrust, PeerTrust, and\nAppleseed. Section ‘Conclusions’ concludes this article and summarizes the contributions\nand limitations of our work.\n\nBackground and literature review\nSocial trust models\n\nTrust management systems aid agents in establishing and assessing mutual trust. How-\never, the actual mechanisms used in these systems vary. For example, public key infras-\ntructures [4] rely on certificates whereas reputation-based trust management systems are\nbased on experiences of earlier direct and indirect interactions [5].\nIn this paper we will focus on social trust models based on reputation. The trust model\n\nshould provide a means to compare the trustworthiness of agents in order to choose a\nparticular agent to perform an action. For instance, on an e-commerce website like eBay,\nwe need to be able to compare the trustworthiness of sellers in order to pick the most\ntrustworthy one to buy a product from.\nSocial trust models rely on past experiences of agents to produce trust assertions. That\n\nis, the agents in the system interact with each other and record their experiences, which\nare then used to determine whether a particular agent is trustworthy. This model is self-\nsufficient because it does not rely on a third party to propagate trust, like it would in\ncertificate authority-based PKI trust models. However, there are drawbacks to having no\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 3 of 27\n\nroot of trust. For instance, agents evaluating the trustworthiness of agents with whom\nthere has been no interaction must use recommendations from others and, in turn,\nevaluate the trustworthiness of the recommenders. Social trust models must address this\nproblem.\n\nNature of input\n\nVarious inputs are used by social trust algorithms to measure the trustworthiness of\nagents. In EigenTrust [1], PeerTrust [2], TRAVOS [6] and Beta Reputation System (BRS)\n[7], agents rate their satisfaction after a transaction (e.g., downloading a file in a P2P\nfile-sharing network). These ratings are used to obtain a trust score that represents the\ntrustworthiness of the agent. In Aberer and Despotovic’s system [5]1, agents may file com-\nplaints (can be seen as dissatisfaction) about each other after a transaction. In Advogato\n[8], whose goal is to discourage spam on its blogging website, users explicitly certify\neach other as belonging to a particular level in the community. Trust algorithms may\nalso directly use trust scores among agents to compute an aggregated trustworthiness\nof agents, as in TidalTrust [9] and Appleseed [3]. In the specific context of P2P file-\nsharing, Credence [10] uses the votes on file authenticity to calculate a similarity score\nbetween agents and uses it to measure trust. The trust score is then used to recommend\nfiles.\n\nDirect vs. indirect trust\n\nThe truster may use some or all of its own and other agents’ past experiences with the\ntrustee to obtain a trust score. Trust algorithms often use gossiping to poll agents with\nwhom the truster has had interactions in the past.\nThe trust score calculated using only the experiences from direct interactions is\n\ncalled the direct trust score, while the trust score calculated using the recommenda-\ntions from other agents is called the indirect trust score [11]. As mentioned earlier,\nreputation systems use different inputs (satisfaction ratings, votes, certificates, etc.) to\ncalculate direct trust scores and indirect trust scores. PeerTrust uses satisfaction ratings\nto calculate both direct and indirect trust scores, whereas EigenTrust and TRAVOS\nuse satisfaction ratings to calculate direct trust scores, which they then use to calcu-\nlate indirect trust scores. Therefore, we can categorize the trust algorithms based on\nthe input required. But how do trust algorithms calculate the trust scores of agents\nusing the above information? It again varies from algorithm to algorithm. For instance,\nPeerTrust, EigenTrust, and Aberer use simple averaging of ratings, TRAVOS and BRS\nuse the beta probability density function, and Appleseed uses the Spreading Activation\nmodel.\n\nGlobal vs. local trust\n\nThe trust algorithm may output a global trust score or a local trust score [3, 12]. A global\ntrust score is one that represents the general trust that all agents have on a particular\nagent, whereas local trust scores represents the trust from the perspective of the truster\nand thus each truster may trust an agent differently. In our survey, we found PeerTrust,\nEigenTrust, and Aberer to be global trust algorithms whereas TRAVOS, BRS, Credence,\nAdvogato, TidalTrust, Appleseed, Marsh [13] and Abdul-Rahman [14] are local trust\nalgorithms.\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 4 of 27\n\nTo trust or not to trust\n\nOnce the trust score is calculated, it can be used to decide whether to trust the agent. It\ncan be as simple as comparing the trust score against a threshold: if the trust score is above\na certain threshold, then the agent is trusted. Marsh [13], and Aberer [5] use thresholding\ntechniques. If the trust algorithm outputs normalized trust scores of agents as in Eigen-\nTrust, then the trust scores of agents are ranked. In this case, one may consider a certain\npercentage of the top ranked agents as trustworthy. In Appleseed, a graph is first obtained\nwith trust scores of agents as edge weights, and then, the truster agent is “injected” with\na value called the activation energy. This energy is spread to agents with a spreading fac-\ntor along the edges in the graph and the algorithm ranks the agents according to their\ntrust scores. Trust decisions can also be flow-based such as in Advogato, which calculates\na maximum “flow of trust” in the trust graph to determine which agents are trustworthy\nand which are not.\nIn short, social trust models focus on the following:\n\n1. What is the input to calculate the trust score of an agent?\n2. Does the trust algorithm use only direct experience or does it also rely on third\n\nparty recommendations?\n3. Is the trust score of an agent global or local?\n4. How does one decide whether to trust an agent?\n\nGiven the above discussion, and to assess the scope of our testbed, we propose tomodel,\nevaluate and compare three algorithms from fairly different families. The next sections\nprovide detailed descriptions of the trust models we selected and that we implemented in\nour testbed. The details are given to help understand the output of our experiments, but\nreaders familiar with EigenTrust, PeerTrust and/or AppleSeed may skip those respective\nsections.\n\nPeerTrust\n\nIn PeerTrust, agents rate each other in terms of the satisfaction received. These ratings\nare weighted by trust scores of the raters, and a global trust score is computed recursively\nusing Eq. 2.1, where:\n\n• T(u) is the trust score of agent u\n• I(u) is the set of transactions that agent u had with all the agents in the system\n• S(u, i) is the satisfaction rating on u for transaction i\n• p(u, i) is the agent that provided the rating.\n\nT(u) =\nI(u)∑\ni=1\n\nS(u, i) × T(p(u, i))∑I(u)\nj=1 T(p(u, j))\n\n(2.1)\n\nPeerTrust also provides a method for calculating local trust scores. In both local and\nglobal trust score computations, the trust score is compared against a threshold to decide\nwhether to trust or not.\n\nEigenTrust\n\nAgents in EigenTrust rate transactions as satisfactory or unsatisfactory [1]. These trans-\naction ratings are used as input, to calculate a local direct trust score, from which a global\ntrust score is then calculated.\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 5 of 27\n\nAn agent i calculates the normalized local trust score of agent j, as shown in Eq. 2.2,\nwhere tij ∈ {+1,−1} is the transaction rating, and sij is the sum of ratings.\n\nsij =\n∑\nTij\n\ntrij\n\ncij = max(sij, 0)∑\nk max(sik , 0)\n\n(2.2)\n\nNote that we cannot use sij as the local trust score without normalizing, because mali-\ncious agents can arbitrarily assign high local trust values to fellow malicious agents and\nlow local trust values to honest agents.\nTo calculate the global trust score of an agent, the truster queries his friends for their\n\ntrust scores on the trustee. These local trust scores are aggregated, as shown in Eq. 2.3.\n\ntik =\n∑\nj\ncijcjk (2.3)\n\nIf we let C be the matrix containing cij elements, �ci be the local trust vector for i (each\nelement corresponds to the trust that i has in j), and �ti the vector containing tik , then,\n\n�ti = CT �ci (2.4)\n\nBy asking a friend’s friend’s opinion, Eq. 2.4 becomes �ti = (CT )2 �ci. If an agent keeps\nasking the opinions of its friends of friends, the whole trust graph can be explored, and\nEq. 2.4 becomes Eq. 2.5, where n is the number of hops from i.\n\n�t = (CT )n �ci (2.5)\n\nThe trust scores of the agents converge to a global value irrespective of the trustee.\nBecause EigenTrust outputs global trust scores (normalized over the sum of all agents),\n\nagents are ranked according to their trust scores (unlike PeerTrust). Therefore, an agent\nis considered trustworthy if it is within a certain rank.\n\nAppleseed\n\nAppleseed is a flow-based algorithm [3]. Assuming that we are given a directed weighted\ngraph with agents as nodes, edges as trust relationships, and the weight of an edge as\ntrustworthiness of the sink, we can determine the amount of trust that flows in the graph.\nThat is, given a trust seed, an energy in ∈ R\n\n+\n0 , spreading factor decay ∈[ 0, 1], and conver-\n\ngence threshold Tc, Appleseed returns a trust score of agents from the perspective of the\ntrust seed.\nThe trust propagation from agent a to agent b is determined using Eq. 2.6, where the\n\nweight of edge (a, b) represents the amount of trust a places in b, and in(a) and in(b)\nrepresent the flow of trust into a and b, respectively.\n\nin(b) = decay ×\n∑\n\n(a,b)∈E\nin(a) × weight(a, b)∑\n\n(a,c)∈E weight(a, c)\n(2.6)\n\nThe trust of an agent b (trust(b)) is then updated using Eq. 2.7, where the decay factor\nensures that trust in an agent decreases as the path length from the seed increases.\n\ntrust(b) := trust(b) + (1 − decay) × in(b) (2.7)\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 6 of 27\n\nGenerally, trust graphs have loops, which makes Eq. 2.7 recursive. Thus a termination\ncondition like the one below is required, where Ai ⊆ A is the set of nodes that were\ndiscovered until step i and trusti(x) is the current trust scores for all x ∈ Ai:\n\n∀x ∈ Ai : trusti(x) − trusti−1(x) ≤ Tc (2.8)\n\nAfter Eq. 2.7 terminates, the trust scores of agents are ranked. Since this set is ranked\nfrom the perspective of the seed, Appleseed is a local trust algorithm.\nAs our brief survey shows, the trust models vary in terms of their input, output, and\n\nthe methods they use. To evaluate and compare them, testbeds are needed. In the next\nsection we take a look at existing testbeds.\n\nTestbeds\n\nWe investigated two testbed models, namely Guha’s [15] andMacau [16], and two testbed\nimplementations, namely ART [17] and TREET [18], which are used to evaluate trust\nalgorithms. This section provides details of our investigation.\n\nGuha\n\nGuha [15] proposes a model to capture document recommendation systems, where trust\nand reputation play an important role. The model relies on a graph of agents where the\nedges can be weighted based on their mutual ratings, and a rating function for documents\nby agents. Guha then discusses how trust can be calculated based on those ratings, and\nevaluates a few case studies of real systems that can be accommodated by the model.\nGuha’s model can capture trust systems that take a set of documents and their ratings\n\nas input (such as Credence [10]), but it cannot accommodate systems where the only\ninput consists of direct feedbacks between agents, such as in PeerTrust (global) [2] or\nEigenTrust [1]. Also, the rating of documents is itself an output of Guha’s model, and that\nis often not the purpose or output of many more general-purpose trust models.\nIn short, document recommendation systems can be viewed as a specialization or\n\nsubclass of more general trust systems, and Guha’s model is suitable for that subclass.\n\nMacau\n\nHazard and Singh’s Macau [16] is a model for evaluating reputation systems. The authors\ndistinguish two roles for any agent: a rater that evaluates a target. Transactions are viewed\nas a favor provided by the target to the rater. The target’s reputation, local to each rater-\ntarget pairing, is updated after each transaction and depends on the previous reputation\nvalue. The target’s payoff in giving a favor is also dependent on its current reputation but\nalso on its belief of the likelihood that the rater will in turn return the favor in the future.\nBased on the above definitions, the authors define a set of desirable properties for a\n\nreputation system:\n\n• Monotonicity: given two different targets a and b, the computed reputation of a\nshould be higher than that of b if the predicted payoff of a transaction with a is\nhigher than with b.\n\n• Unambiguity and convergence: the reputation should converge over time to a single\nfixpoint, regardless of its initial value.\n\n• Accuracy: this convergence should happen quickly, thus minimizing the total\nreputation estimation errors in the meantime.\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 7 of 27\n\nMacau thus captures an important stage in trust assessment, i.e. the update of one-to-\none trustworthiness based on past transactions. It has been used to evaluate, in terms of\ntheir compliance to the properties defined above, algorithms such as TRAVOS [6] and the\nBeta Reputation System (BRS) [7] that model positive and negative experiences as ran-\ndom variables following a beta probability distribution. The comparison of trust models\nrelying on the beta distribution and their resilience to various attacks has also recently\nbeen explored in [19].\n\nART\n\nThe Agent Reputation and Trust testbed (ART) [17] provides an open-source message-\ndriven simulation engine for implementing and comparing the performance of reputation\nsystems. ART uses art painting sales as the domain.\nEach client has to sell paintings belonging to a particular era. To determine their\n\nmarket values, clients refer to agents for appraisals for a fee. Because each agent\nis an expert only in a specific era, it may not be able to provide appraisals for\npaintings from other eras and therefore refers to other agents for a fee. After such\ninteractions, agents record their experiences, calculate their reputation scores, and\nuse them to choose the most trustworthy agents for future interactions. The goal\nof each agent is to finish the simulation with the highest bank balance, and, intu-\nitively, the winning agent’s trust mechanism knows the right agents to trust for\nrecommendations.\nThe ART testbed provides a protocol that each agent must implement. The protocol\n\nspecifies the possible messages that agents can send to each other. Themessages are deliv-\nered by the simulation engine, which loops over each agent at every time interval. The\nengine is also responsible for keeping track of the bank balance of the agents, and assign-\ning new clients to agents. All results are collected and stored in a database and displayed\non a graphical user interface (GUI) at runtime.\nART is best suited for evaluating trust calculation schemes from a first person point\n\nof view. It is not meant as a platform for testing trust management as a service provided\nby the system. For example, to evaluate EigenTrust in ART, one would either need to\nconsiderably modify ART itself (for the centralized version of EigenTrust) or to require\ncooperation from the participating agents and an additional dedicated distributed infras-\ntructure (for the distributed version). Furthermore, as also pointed out in [16] and [20],\nthe comparison of the performance of different agents is not necessarily based on their\ncorrect ability to assess the reputation of other agents, but rather based on how well they\nmodel and exploit the problem domain.\n\nTREET\n\nThe Trust and Reputation Experimentation and Evaluation Testbed (TREET) [18] mod-\nels a general marketplace scenario where there are buyers, sellers, and 1,000 different\nproducts with varying prices, such that there are more inexpensive items than expensive\nones. The sale price of the products is fixed, to avoid the influence of market competition.\nThe cost of producing an item is 75% of the selling price, and the seller incurs this cost.\nTo lower this cost and increase profit, a seller can cheat by not shipping the item. Each\nproduct also has a utility value of 110% of the selling price, which encourages buyers to\npurchase.\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 8 of 27\n\nAgents join or exit after 100 simulation days or after a day with a probability of 0.05,\nbut to keep the number of buyers and sellers constant, an agent is introduced for each\ndeparting agent. At initialization, each seller is assigned a random number of products\nto sell. Buyers evaluate the offers from each seller and pick a seller. Sellers are informed\nof the accepted offers and are paid. Fourteen days after a sale, the buyer knows whether\nhe has been cheated or not, depending on whether he receives the purchased item. The\nbuyer then provides feedback based on his experience of the transaction. The feedback is\nin turn used to choose sellers for future transactions.\nTREET evaluates the performance of various reputation systems under Reputation Lag\n\nattack, Proliferation attack, and Value Imbalance attack using the following metrics:\n\n1. cheater sales over honest sales ratio\n2. cheater profit over honest profit ratio\n\nMultiple seller accounts are needed to orchestrate a Proliferation Attack, but TREET\ndoes not consider attacks such as White-Washing and Self-Promoting, which require\ncreating multiple buyer accounts.\nTREET addresses many of ART’s limitation in a marketplace scenario. To name a\n\nfew [21], TREET supports both centralized and decentralized trust algorithms, allows\ncollusion attacks to be implemented, and does not put a restriction on trust score rep-\nresentation. However, like ART, the evaluation metrics in TREET are tightly coupled to\nthe marketplace domain. It is unclear how ART or TREET can be used to evaluate trust\nmodels used in other systems, such as P2P file-sharing networks, online product review\nwebsites and others that use trust. To our knowledge, there is no testbed that provides\ngeneric evaluation metrics and that is independent of the application domain.\n\nSummary\n\nTrust is a tool used in the decision-making process and it can be computed. There are\nmanymodels based on social trust that attempt to aid agents in making rational decisions.\nHowever, these models vary in terms of their input and output requirements. This makes\nevaluations against a common set of attacks difficult.\n\nProblem description andmodel\nOur goal is to have a testbed that is generic enough to accommodate as many trust\nmanagement systems and models as possible. Our requirements are:\n\n1. A model that provides an abstraction layer for developers to incorporate existing\nand new systems that match the input and output of the model.\n\n2. An evaluation framework to measure and compare the performance of trust models\nagainst trust properties and attacks independently of the application domain.\n\nIn this section, we introduce an abstract model for trust management systems. This\nmodel will be the foundation of our testbed. Our model is essentially based on the\nfollowing stages:\n\n1. In stage 1 of the trust assessment process, the feedback provided by agents on other\nagents is represented as a feedback history graph.\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 9 of 27\n\n2. In stage 2, a reputation graph is produced, where the weight of an arc denotes the\nreputation of the target agent. “Reputation” here follows [14], as “an expectation\nabout an individual’s behavior based on information about or observations of its\npast behavior”. It is viewed as an estimation of trustworthiness based on a\ncombination of direct and indirect feedback.\n\n3. In the final stage, a trust graph is produced, where the existence of an arc implies\ntrust in the target agent. We take “trust” here to mean the “belief by agent A that\nagent B is trustworthy” [2, 22], and so it is boolean and subjective in our model.\n\nIn the rest of this section, we define the aforementioned graphs in stages.\n\nStage 1—obtain feedback history graph\n\nWe first define a feedback, f (a, b) ∈ R as an assessment made by agent a of an action or\ngroup of actions performed by agent b, where a and b belong to the set A of all the agents\nin the system. The list of n feedbacks by a on b, FHG(a, b), is called a feedback history,\nrepresented as follows:\n\nFHG(a, b) �→ (f1(a, b), f2(a, b), . . . , fn(a, b)) (3.1)\n\nThe feedback fi(a, b) indicates the ith satisfaction received by a from b’s action. For\nexample, in a file-sharing network, the feedback by a downloader may indicate the sat-\nisfaction received from downloading a file from an uploader in terms of a value in R.\nExisting trust models use different ranges of values for feedback, and letting the feedback\nvalue be in R allows us to include these reputation systems in our testbed.\nIf A is the set of agents, E is the set of labelled arcs (a, b), and the label is FHG(a, b)\n\nwhen FHG(a, b) \t= ∅, then the feedback histories for all agents in A are represented in a\ndirected and labelled graph called Feedback History Graph (FHG)2, FHG = (A,E):\n\nFHG : A × A → R\nN\n\n∗\n(3.2)\n\nNote that we have not included timestamps associated with each feedback (which would\nbe useful for, among other things, running our testbed as a discrete event simulator), but\nour model can be expanded to accommodate it.\nOnce the feedback history graph is obtained, the next step is to produce a reputation\n\ngraph.\n\nStage 2—obtain reputation graph\n\nA Reputation Graph (RG), RG = (A,E′\n), is a directed and weighted graph, where the\n\nweight on an arc, RG(a, b), is the trustworthiness of b from a’s perspective:\n\nRG : A × A → R (3.3)\n\nThe edges are added by computing second and nth-hand trust via transitive closure of\nedges in E. That is: if (a, b) ∈ E and (b, c) ∈ E ⇒ (a, b), (b, c), and (a, c) ∈ E′ (the value of\nthe weight of the edges, however, depends on the particular trust algorithm).\nReputation algorithms may also exhibit the reflexive property by adding looping arcs to\n\nindicate that the truster trusts itself to a certain degree for a particular task [1–3].\nThe existing literature categorizes reputation algorithms into two groups: local and\n\nglobal (Figs. 1(a) and (b), respectively) [3, 5]. Global algorithms assign a single reputa-\ntion score to each agent. Therefore, if a global algorithm is used, then the weights of the\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 10 of 27\n\nFig. 1 Examples of reputation graphs output respectively by a local and global algorithm\n\nincoming arcs of an agent should be the same, as shown in Fig. 1(b) (although for clar-\nity’s sake we will often present the graph simply as a ranking of agents in the rest of this\narticle). There is no such property for local algorithms.\nReputation algorithms may also differ in how the graphs is produced. One method is\n\nto first calculate one-to-one scores of agents using direct feedbacks and then use them\nto calculate the trustworthiness of agents previously unknown to the truster (e.g., Eigen-\nTrust). This is shown as 1a and 1b in Fig. 2. The other method (#2 in Fig. 2) skips the\nintermediate graph in the aforementioned method and produces a reputation graph (e.g.,\nPeerTrust).\n\nStage 3—obtain trust graph\n\nThe graph obtained in stage 2 contains information about the trustworthiness of agents.\nBut to use this information to make a decision about a transaction in the future, agents\nmust convert trustworthiness to boolean trust (see [23] for an example), which can also\nbe expressed as a graph. We refer to this directed graph as the Trust Graph (TG) TG =\n(A, F), where a directed edge ab ∈ F represents agent a trusting agent b.\nTo summarize ourmodel, we can represent the stages as part of a workflow as illustrated\n\nin Fig. 3.\n\nFig. 2 Two methods to obtain a reputation graph\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 11 of 27\n\nFig. 3 Overview of the stages in our model\n\nIn the next section, we see at what stages in our model do various algorithms fit, and\ndescribe criteria for chaining different algorithms.\n\nClassifying and chaining algorithms\nBy refactoring the trust models according to the stages presented in the above sections,\nwe start to see a new classification scheme. Let us take EigenTrust, PeerTrust, and Apple-\nseed as examples and describe them using our model. EigenTrust takes an FHG with\nedge labels in {0, 1}∗ as input and outputs an RG with edge labels in [ 0, 1]. PeerTrust,\non the other hand, takes an FHG with edge labels in [ 0, 1]∗ as input and outputs an\nRG with edge labels in [ 0, 1]. Meanwhile, Appleseed requires an RG with edge labels in\n[ 0, 1] as input and outputs another RG′ in the same codomain. It is also possible for an\nalgorithm to skip some stages. For example, according to our model, Aberer [5] skips\nstage 2 and does not output a reputation graph. One can also represent simple mecha-\nnisms to generate a trust graph by applying a threshold on reputation values (as output\nfor example by EigenTrust), or by selecting the top k agents. This stage transitions of\nalgorithms are depicted3 in Fig. 4. In addition to the existing classification criteria in the\nstate of the art, trust algorithms can now be classified according to their stage transi-\ntions (i.e., from one stage to another as well as transitioning within a stage) as shown in\nTable 1.\nIt is important to note that although these three algorithms output a reputation\n\ngraph with continuous reputation values between 0 and 1, the semantics of these val-\nues are different. EigenTrust outputs relative (among agents) global reputation scores,\nPeerTrust outputs an absolute global reputation score, and Appleseed produces relative\nlocal reputation scores. In other words, EigenTrust and Appleseed are ranking algorithms\n(global and local, respectively), whereas PeerTrust is not.\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 12 of 27\n\nFig. 4 Stage transitions of Trust algorithms\n\nAs we can see, each step of the trust assessment process can be viewed as a\ngraph transformation function, and we can use this functional view to easily describe\nevaluation mechanisms as well. Suppose an experimenter wants to compare PeerTrust\nand EigenTrust. The inputs and outputs of these algorithms are semantically different.\nTo match the input, we can use a function that discretizes continuous feedback values\n(f (a, b)) in [0, 1] to {-1, 1}, using some threshold t:\n\nTable 1 A classification for trust models\n\nStage Global or\nAbsolute or\n\nTrust Algorithm\nTransitions\n\nInput\nLocal\n\nRelative\nReputation Scores\n\nEigenTrust 0 → 2\nsatisfaction\n\nglobal relativeratings\n\nPeerTrust 0 → 2\nsatisfaction\n\nglobal absoluteratings\n\nAppleSeed 2 → 2\nreputation\n\nlocal absolutescores\n\nAberer & Despotovic 0 → 3 complaints global N/A\n\nAdvogato 3 → 3 certificates local N/A\n\nTRAVOS 0 → 2\nsatisfaction\n\nlocal absoluteratings\n\nRanking 2 → 3\nreputation\n\nN/A relativescores\n\nThresholding 2 → 3\nreputation\n\nN/A absolutescores\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 13 of 27\n\ndiscretizet : [ 0, 1] → {−1, 1}\n\nx �→ discretizet(x) =\n{\n\n−1 if x ≤ t\n1 if x > t\n\n(4.1)\n\nTo lighten the notations, in what follows we will adopt a default threshold of 0.5 and drop\nt. We will also, in an abuse of notation, actually use discretize : FHG→ FHG, which applies\nthe function defined in 4.1 to every feedback of every edge of the graph.\nLet us turn to the output now. Recall that the output of EigenTrust is a relative global\n\nscore while PeerTrust’s is also global but absolute. To make the outputs more directly\ncomparable, we can use a normalization function on PeerTrust’s output, ensuring that the\nsum of outgoing weights for each agent is 1. It takes a reputation graph RG2 with edge\nlabels in [ 0, 1] as input, and outputs another reputation graph RG3 with edge labels in\n[ 0, 1], but where the reputation scores are relative to one another. This is achieved using\nEq. 4.2, where N(a) is the set of agents adjacent to a via outgoing edges.\n\nnormalize : A × A →[ 0, 1]\n\n(a, b) �→ normalize(a, b) = RG(a, b)∑\nc∈N(a) RG(a, c)\n\n(4.2)\n\nAgain, in an abuse of notation we will also refer in what follows to normalize as the func-\ntion in RG→ RG that applies 4.2 to every edge of the graph. Note again that normalization\nisn’t strictly speaking a necessary step if all one is concerned about is the ranking of the\nagent, and not the values attached to each agent, especially since the semantics of these\nvalues are still ultimately attached to the algorithm that is computing them. Normaliza-\ntion does not affect the ranking. Either way, Spearman’s rank correlation coefficient [24]\ncan finally be used to compare the rankings output by global trust functions such as Eigen-\nTrust and PeerTrust. This metric ∈[−1, 1] specifies the degree to which the ranking order\nof the outputs match, where 1 means a perfect match and -1 means no match: spearman:\nRG × RG → [−1, 1].\nThe choice of discretization and normalization methods are important and they may\n\nintroduce a bias when comparing two algorithms. For the purpose of demonstrating our\nmodel, we will assume that our choices are good enough.\nBy combining these algorithms, we can represent the workflow as shown in Fig. 5.\nTo more clearly capture trust management algorithms as a process consisting of graph\n\ntransformation operations, and to be able to express them in our experiments as such,\nwe introduce named functions that make these transformations explicit. Here is an\nillustration of the convention we will follow: the function that captures EigenTrust’s trans-\nformation from an FHG to an RGwill be named f 2reigentrust , where “f ” stands for FHG and\n“r” for RG. Hence, in functional programming terms, the experiment comparing Eigen-\nTrust and PeerTrust using a given feedback history graph FHG0 can be specified very\nsimply as follows:\n\nspearman(f 2reigentrust(f 2fdiscretize(FHG0)), r2rnormalize(f 2rpeertrust(FHG0)))\n\nIn the current implementation of our testbed, we assume that the pre-condition checks\nas per Table 1 are enforced by the algorithms rather than the testbed. However, this can\nbe modified easily in the future.\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 14 of 27\n\nFig. 5 Comparing EigenTrust and PeerTrust\n\nIn the next section, we present simple experiments that we ran to analyze trust\nalgorithms using the model described in this section.\n\nResults and discussion\nUsing the prototype testbed that we implemented following the model presented in\nthe previous section, we conducted several experiments and analyzed their results on\nthree trust algorithms, namely EigenTrust, PeerTrust, and Appleseed. The experiments\nthat we present in this section are grouped into two categories: vulnerability assess-\nments and trust properties assessments. But first we give a general description of the\nimplementation.\n\nImplementation\n\nA prototype was designed and built in Java to test the model described in Section ‘Prob-\nlem description and model’. The two main components of the testbed are graphs and\nalgorithms. A Graph can be a feedback history graph, a reputation graph or a trust graph.\nThese graphs follow our model as described in the previous section.\nThe graphs can be populated either programatically or by providing a file following\n\nthe Attribute-Relation File Format (ARFF) used in the Weka machine learning toolkit\n(ARFF was chosen for its simplicity, but other formats could obviously be accommodated\nas well in the future if needed). For instance, a feedback history graph is populated with\na file containing a list of relations, each containing 3 attributes: source agent identifier,\nsink agent identifier and the feedback value. An example of a ARFF file for populating a\nfeedback history graph is given in Listing 1:\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 15 of 27\n\nListing 1 An example ARFF file for populating a feedback history graph\n\n@relation feedback\n@attribute assessorID string\n@attribute assesseeID string\n@attribute feedbackValue numeric\n@data\n0,1,0.6\n0,1,0.7\n0,1,0.2\n\nIn our prototype, even though the algorithms are implemented using object-orientation,\nthey are ultimately presented to the experimenter as functions that take a graph as input\nand return a graph as the output, to fully conform to the model we have presented, and\nto make the experiments simple and intuitive to express. Other utility functions, such as\nevaluation, discretization and comparison, are also provided. See Listing 2 for an example.\n\nListing 2 How to create a simple experiment in our testbed\n\nimport static trust.Algorithms.*;\nFHG fhg = new FHG(\"ex.arff\");\neigentrust(discretize(fhg)); //the experiment!\n\nThe testbed’s source code is open and is available on Google Code4. To ensure that our\nalgorithm implementationsmatch the authors’ intentions and our own understanding, we\nalso provide a set of unit tests taken from examples found in the literature as well as our\nown additional scenarios.\n\nVulnerability assessments\n\nThe security of trust algorithms is measured by their resistance to attacks. In this section,\nwe subject them to attacks and assess their vulnerabilities. We will purposely try to come\nup with the simplest attack scenarios that can exhibit the properties we are looking for.\nThirunarayan et al. [19] follows a similar approach but restricted to trust algorithms\nrelying on the beta probability distribution.\n\nNormalization-based attack\n\nSetup In this first experiment, we want to exhibit whether two different trust algorithms\n(in this case, EigenTrust vs PeerTrust) may output different rankings given the same input.\nFor this we investigate how reputation is affected by the number of good feedbacks versus\nthe bad feedbacks. Suppose we were given FHG0 in Fig. 6(a) and FHG1 in Fig. 6(b). Since\nthere are more good feedbacks on agent 2 in FHG0 than FHG1, it is reasonable to expect\nagent 2’s reputation in RG1 to be lower than in RG2.\nWe normalize the output of PeerTrust simply to make the scale of the reputation num-\n\nbers similar to EigenTrust (we do not claim that the semantics are the same). And as\nEigenTrust requires feedbacks to be either positive (+1) or negative (-1), we first need to\nconvert the 1.0 values in the FHGs to +1 and the 0.0 values to -1, hence the use of the\ndiscretizer function in the experiment specifications below:\n\nspearman\n(\nf 2reigentrust\n\n(\nf 2fdiscretize(FHG0)\n\n)\n, f 2reigentrust\n\n(\nf 2fdiscretize(FHG1)\n\n))\nspearman\n\n(\nf 2rpeertrust(FHG0), f 2rpeertrust(FHG1)\n\n)\nspearman\n\n(\nf 2reigentrust\n\n(\nf 2fdiscretize(FHG0)\n\n)\n, f 2rpeertrust(FHG0)\n\n)\nspearman\n\n(\nf 2reigentrust\n\n(\nf 2fdiscretize(FHG1)\n\n)\n, f 2rpeertrust(FHG1)\n\n)\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 16 of 27\n\nFig. 6 Normalization-based Discrepancy\n\nResults Comparing the rankings in Table 2, we note that EigenTrust reports no change\nin agent 2’s rank, whereas in PeerTrust its rank has changed from 1 to 2 (Spearman’s\ncoefficient = 0.83).\nWhy did agent 2’s rank not change in the EigenTrust experiment? During the initial cal-\n\nculation of its normalized local trust values (used for the calculation of the reputation\ngraph) for a given agent, Eigentrust essentially calculates the difference between positive\nand negative feedbacks for each neighbour and then it normalizes it over all its neigh-\nbours. In our case, agent 1 only has agent 2 as its neighbour and so the normalization\nprocess leads to a loss of information, namely the number of positive feedbacks.\nThus, if an agent has interacted with a malicious agent only, then the malicious agent\n\ncan get the victim to trust him fully, as long as the number of positive feedbacks that the\nmalicious agent received is greater than the number of negative feedbacks. This prob-\nlem is acknowledged by EigenTrust’s authors [1]. But PeerTrust does not suffer from this\nproblem, because it does not attempt to perform a sum of positive and negative feedbacks\nin this fashion.\n\nSelf-promoting attack\n\nSetup Suppose the least trustworthy agent rates a newcomer (i.e., one that had received\nno feedback yet) highly. If the newcomer becomes more trustworthy than before the\n\nTable 2 Rankings before and after slandering in retort (reputations in brackets)\n\nAgent 0 Agent 1 Agent 2 Agent 3\n\nEigenTrust(FHG0) 3 (0.16) 2 (0.29) 1 (0.39) 3 (0.16)\n\nEigenTrust(FHG1) 3 (0.16) 2 (0.29) 1 (0.39) 3 (0.16)\n\nPeerTrust(FHG0) 3 (0.11) 1 (0.44) 1 (0.44) 4 (0.00)\n\nPeerTrust(FHG1) 3 (0.13) 1 (0.52) 2 (0.35) 4 (0.00)\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 17 of 27\n\nFig. 7 Self-promoting attack – EigenTrust\n\nrating, then this can be exploited maliciously, paving the way to collusive self-promoting\nattacks [12]. Conversely, if the newcomer becomes less trustworthy than before, then the\nnewcomer is vulnerable to a slandering attack. Consider FHG1 in Fig. 7(b) which is based\non FHG0 in Fig. 7(a), after agent 3 rates agent 0 highly. The experiment set-up is therefore\nas follows:\n\nspearman\n(\nf 2reigentrust\n\n(\nf 2fdiscretize(FHG0)\n\n)\n, f 2reigentrust\n\n(\nf 2fdiscretize(FHG1)\n\n))\nand the output can be seen in Fig. 7(c).\n\nResults Looking at Table 3, we see that agent 0’s reputation relative to agent 3 increased.\nNote that it is possible that agent 3 genuinely rated agent 0 highly, in which case Eigen-\nTrust’s output is a good assessment, otherwise it might have missed a case of collusive\nself-promoting attack. It is also worth noting that this experiment breaks PeerTrust, due\nto a division-by-0 problem in an equation. Indeed, when calculating agent 0’s reputa-\ntion score, the feedbacks provided by agent 3 and its reputation score must be taken into\naccount. In this case, agent 3’s reputation score is 0, due to the fact that it received only\n0-valued feedbacks. The division by agent 3’s reputation is the problem here.\n\nSlandering attack, scenario 1\n\nSetup When the least trustworthy agent (agent 3) gives a newcomer (agent 0) a very\nlow rating, it can either be a genuine rating or a slandering attempt [12]. The reputation\nalgorithm may resist slandering by not decreasing agent 0’s reputation, but the risk or\ntradeoff would be the possibility of ignoring a genuine assessment. The inputs for this\nexperiment are FHG0 and FHG1 as shown in Fig. 8, and the experiment is again therefore\nspecified as follows:\n\nspearman\n(\nf 2reigentrust\n\n(\nf 2fdiscretize(FHG0)\n\n)\n, f 2reigentrust\n\n(\nf 2fdiscretize(FHG1)\n\n))\n\nTable 3 Ranking before and after low feedback to newcomer (reputations in brackets)\n\nAgent 0 Agent 1 Agent 2 Agent 3\n\nEigenTrust(FHG0) 3 (0.16) 2 (0.29) 1 (0.39) 3 (0.16)\n\nEigenTrust(FHG1) 3 (0.22) 2 (0.3) 1 (0.36) 4 (0.12)\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 18 of 27\n\nFig. 8 Slandering attack scenario 1 – EigenTrust\n\nResults Comparing the rankings in Table 4, we observe that agent 0’s reputation and\nglobal rank has not changed. If agent 3 has indeed provided a dishonest negative feedback,\nthen we can say that EigenTrust output is a correct assessment. However, it is also possible\nthat agent 3 is the one being slandered (by agent 2) and has provided a genuine negative\nfeedback, in which case, we would expect agent 0’s rank to decrease. Thus, we can only\nsay that EigenTrust is insensitive to bad feedbacks and therefore resists the slandering of\na newcomer. Note that again PeerTrust would produce invalid results for the same reason\nas previously.\n\nSlandering attack, scenario 2\n\nSetup Now going back to the initial situation (Fig. 9(a)), what happens if, as shown\nin FHG1 in Fig. 9(b), agent 3 decides to direct its bad feedbacks to agent 2\ninstead of agent0? Looking purely at the feedbacks, one can make the following\nguesses:\n\n• Agent 3 rated agent 2 negatively to cover its malicious acts (a slandering attack).\n• Agent 2 cheated agent 3 and thus obtained negative feedbacks but acted honestly\n\nwith agent 1 to keep its reputation high (a white-washing attack).\n\nHaving received more positive feedbacks than agent 3, if agent 2’s reputation is not\naffected, then the algorithm is said to be resistant to a slandering attack but it is vulnerable\n\nTable 4 Ranking before and after high feedback to newcomer (reputations in brackets)\n\nAgent 0 Agent 1 Agent 2 Agent 3\n\nEigenTrust(FHG0) 3 (0.16) 2 (0.29) 1 (0.39) 3 (0.16)\n\nEigenTrust(FHG1) 3 (0.16) 2 (0.29) 1 (0.39) 3 (0.16)\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 19 of 27\n\nFig. 9 Slandering attack scenario 2 – EigenTrust\n\nto a white-washing attack. Both EigenTrust and PeerTrust can be used to run this\nexperiment, which is specified as follows:\n\nspearman\n(\nf 2reigentrust\n\n(\nf 2fdiscretize(FHG0)\n\n)\n, f 2reigentrust\n\n(\nf 2fdiscretize(FHG1)\n\n))\nspearman\n\n(\nf 2rpeertrust(FHG0), f 2rpeertrust(FHG1)\n\n)\nspearman\n\n(\nf 2reigentrust\n\n(\nf 2fdiscretize(FHG1)\n\n)\n, r2rnormalize\n\n(\nf 2rpeertrust(FHG1)\n\n))\n\nResults The rankings in Table 5 show that both EigenTrust and PeerTrust are resis-\ntant to this kind of slandering attack, but, as mentioned earlier, they are vulnerable to\nwhite-washing attacks (because the negative feedbacks by agent 3 did not lower agent 2’s\nranking).\n\nSlandering + Sybil attack for local trust algorithms\n\nSetup We now turn to finding out how many malicious agents it takes to slander\neffectively. In a Sybil attack, a malicious agent introduces a number of Sybils (i.e, accom-\nplices or pseudonyms), whose purpose is to slander a victim in the system [12]. Suppose\nwe are given the reputation graph shown in Fig. 10. Let agent 0 be a malicious agent that\nslanders agent 1. Assuming this agent has unlimited resources (e.g., an unlimited and\n\nTable 5 Rankings before and after slandering in retort (reputations in brackets)\n\nAgent 0 Agent 1 Agent 2 Agent 3\n\nEigentrust(FHG0) 3 (0.16) 2 (0.29) 1 (0.39) 3 (0.16)\n\nEigentrust(FHG1) 3 (0.16) 2 (0.29) 1 (0.39) 3 (0.16)\n\nPeerTrust(FHG0) 3 (0.25) 1 (1.00) 1 (1.00) 4 (0.00)\n\nPeerTrust(FHG1) 3 (0.11) 1 (0.44) 1 (0.44) 4 (0.00)\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 20 of 27\n\nFig. 10 Slandering attack using a feedback history graph\n\nlow-cost ability to create pseudonyms), it may introduce an unlimited number of Sybils\nto collectively slander agent 1. In such a scenario, it is useful to study how r(0, 1), i.e. the\nreputation of Agent 1 from the point of view of Agent 0, changes with respect to other\nagents. If r(0, 1) changes such that it is less than r(0, 2), then we can conclude that the slan-\ndering attack was successful and we would measure the effectiveness of the attack based\non the number of Sybils required. However, as explained in Section ‘Slandering attack,\nscenario 2’, one can also interpret this scenario as a white-washing attack. Thus, if an\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 21 of 27\n\nFig. 11 FHG after adding 10 sybils and slander edges\n\nalgorithm is resistant to a slandering attack, then it may be vulnerable to white-washing\nattacks.\nTo measure Appleseed’s attack resistance with the graph in Fig. 10, we first verify\n\nwhether the victim’s reputation is less than that of an agent in the attacker’s possession\n(in this case, we wish to check if r(0, 1) < r(0, 2)). If it is false, the result is updated and a\nSybil agent x is created. Edges (2, x, 1.0) and (x, 1, 0) are also added to the FHG and Apple-\nseed is run again (AppleSeed normally needs a reputation graph as input, but in this case\nsince each FHG edge has a singleton feedback, the value of the feedback can be directly\nused as reputation). This process continues and Sybils are added for a certain number of\niterations or until the attack succeeds (Fig. 11).\n\nResults Appleseed resists this type of attack well. Table 6 summarizes the values of\nr(0, 1) and r(0, 2) in RG after adding 1, 10, 50 and 100 Sybils and slander edges to\nthe FHG. We observe that r(0, 1) > r(0, 2). This confirms the attack resistance prop-\nerty of Appleseed described in [3]. This is not the case of global trust algorithms\nsuch as EigenTrust, since the addition of sybils simply dilutes the reputation values of\nagents.\n\nTrust properties assessments\n\nIn this section, trust algorithms are evaluted for their adherence to trust proper-\nties, namely: (a) weak transitivity and (b) the fact that trust is more easily lost than\ngained.\n\nWeak transitivity\n\nSetup Trustworthiness obtained via the transitive closure of trust paths should decrease\nas the length of the trust path increases [9, 25]. We subjected Appleseed and EigenTrust\nto simple tests to verify this basic rule. Even though the input and output graphs are of\ndifferent types for these two algorithms, the same assertions can be applied to test the\n\nTable 6 Reputation scores by Appleseed\n\nNo. of slandering edges added r(0, 1) r(0, 2)\n\n1 0.36 0.15\n\n10 0.34 0.15\n\n50 0.34 0.14\n\n100 0.34 0.14\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 22 of 27\n\ntransitive rules, as they do not depend on the semantics of the weight of edges or whether\nthe reputation scores are local or global.\n\nResults Table 7 presents the test cases (the \"Input FHG/RG\" column), expected results\n(the \"Output RG\" column represents the transitive closure resulting from the graph trans-\nformation, along with question marks on the edges where the weak transitivity property\nis tested) and actual results. Both Appleseed and EigenTrust passed our transitive tests.\n\nDynamic evolution of global trust\n\nAccording to Marsh [13], “When considering a simple trusting agent (i.e., one who does\nuse rules of reciprocation), the trust he has in a trustee will ordinarily increase if coop-\neration occurs, and decrease otherwise”. That is, if trust exists between two parties, then\ncooperation between them reinforces trust by increasing some trust score. If there was\nno trust, then cooperation builds trust. Furthermore, “a sudden defection from a trusted\nfriend can result in a drastic reduction of trust, to the extent that a lot of work is neces-\nsary to build that trust up again” [13]. That is, if cooperation does not ensue, then trust is\nlost at a rate higher that it was gained. Adherence to this property prevents white-washing\natttacks where attackers cheat periodically while maintaining a high reputation.\nWe propose the following method to evaluate this property.\nLet fi(∗, b) be the i’th feedback on b in feedback history FHG(∗, b), which is the list of\n\nfeedbacks on b by all agents in the system and ri(b) be b’s global reputation score following\ni’th feedback.\n\nTable 7 Transitivity tests and results\n\nExp Input FHG/RG Output RG Expectation Results\n\nEigenTrust Appleseed\n\n1 r(0, 1) >= r(0, 2)\n\nr(0, 2) == r(0, 3) true true\n\n2 r(0, 5) >= r(0, 2)\n\nr(0, 5) >= r(0, 3) true true\n\n3 r(0, 3) >= r(0, 2)\n\ntrue true\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 23 of 27\n\nAssuming both reputation scores and feedback values are on the same scale and r(b)\nis a function of the feedback history FHG(∗, b), then trust must evolve according to con-\nditions 5.1 and 5.2, where we define, for agent b and for any consecutive “instants” i − 1\nand i:\n\n• δf := fi(∗, b) − ri−1(b) (the ith feedback is compared to the reputation at instant i-1)\n• δr := ri(b) − ri−1(b) where ri(b) is obtained after feedback fi(∗, b)\n• δr\n\nδf\n+ := δr\n\nδf if\nδr\nδf ≥ 0, and δr\n\nδf\n− otherwise\n\n0 ≤ δr\nδf\n\n+\n≤ 1 (5.1)\n\n| δr\nδf\n\n+\n| ≤ | δr\n\nδf\n\n−\n| (5.2)\n\nThat is:\n\n1. Condition 5.1 verifies that if there is a positive change in feedback, then the change\nin reputation is also positive, but the change in reputation is less than the change in\nfeedback.\n\n2. Condition 5.2 verifies that the magnitude of the rate of change in reputation due to\npositive feedbacks is always less than the magnitude of the rate of change in\nreputation due to negative feedbacks.\n\nSetup and results We set up two scenarios to investigate the behaviour of PeerTrust. In\nthe first scenario, there are only two agents a and b, and the feedback history FHG(a, b) is\nhandcrafted such that a is typically satisfied with b, except once, where f (a, b) is set to 0.\nIn this scenario, we determine whether trust loss is greater than trust gain. In the second\nscenario, we introduce a third agent c and we investigate the impact of r(c, a) on r(a, b)\nand whether the above conditions are still held in this scenario.\n\nScenario 1: evolution due to direct interactions only Consider the feedback histories\nbetween two agents a and b in Table 8, which shows agent a was dissatisfied with b only\nonce. One could argue that b mounted a white-washing attack in which it behaved hon-\nestly in order to cheat once in a while, or it is also possible that a is concealing a slandering\nattack, where it unfairly rated b. Even though information such as the intention of an agent\nthus cannot be extracted from the feedback history alone, we can use the above condi-\ntions to characterize a trust algorithm’s behaviour as to whether reputation evolves as it\nshould.\nAssuming that all agents are pre-trusted equally (i.e., r0(∗, b) = 0.5), Table 8 and\n\nFig. 12 show the evolution of r0(∗, b). When f3(a, b) (a negative feedback) occurred, r(∗, b)\n\nTable 8 Evolution due to direct interactions only—Scenario 1\n\ni Assessor Assessee f r δf δr\n\n1 a b 1.0 1.0 0.5 0.5\n\n2 a b 1.0 1.0 0 0\n\n3 a b 0 0.66 −1.0 −0.33\n\n4 a b 1.0 0.75 0.33 0.08\n\n5 a b 1.0 0.8 0.25 0.05\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 24 of 27\n\nFig. 12 Evolution of reputation w.r.t feedback – Scenario 1\n\ndecreased but it increased at a slower rate when f4(a, b) (a positive feedback) occured.\nThus, PeerTrust has respected conditions 5.1 and 5.2.\nIn a separate experiment, we also noted that if there were two consecutive negative\n\nfeedbacks on b, then r(∗, b) decreased to 0.5. This suggests that an attacker can know\nexactly how many positive feedbacks are required in order to restore his lost reputation\nafter misbehaving.\n\nScenario 2: evolution due to direct and indirect interactions In this experiment, we use\nthe feedback history provided in Table 9. Initially, agent c provided a positive feedback to\na (f1), but later provides a negative feedback (f4). Because b’s reputation score is dependent\non a’s reputation score, a negative change in a’s reputation should affect b’s reputation.\nHowever, results show that it is unaffected. We explain the reason in what follows.\nIf we compare the reputation values shown in Table 10, we note that r(a) changed from\n\n1 to 0.5. However, this change did not affect r(b) after adding f5. This is because of the\nnormalization technique used by PeerTrust to calculate b’s reputation.\nThus, PeerTrust did not propagate trust as one would have expected (i.e., if c does not\n\ntrust a, it should not trust b either) and this can be easily exploited by attackers. For\nexample, if agents a and b both are part of a collusive group, then agent c cannot recognize\nthis and therefore cannot break away from a collusive group of attackers.\n\nTable 9 Evolution due to direct and indirect interactions\n\ni Assessor Assessee f r\n\n1 c a 1.0 0\n\n2 a b 0.9 0.9\n\n3 a b 0.9 0.9\n\n4 c a 0 0.9\n\n5 a b 1.0 0.93\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 25 of 27\n\nTable 10 Reputation output by PeerTrust\n\ni Assessor Assessee f r(∗, b)\n1 c a 1.0 0\n\n2 a b 0.9 0.9\n\n3 a b 0.9 0.9\n\n4 c a 0 0.9\n\n5 a b 1.0 0.93\n\nLimitations\n\n1. By definition, the global trust of an agent reflects the impact of feedbacks by all\nother agents in the system. To verify the conditions presented at the beginning of\nthis section, we only need to know the order of feedbacks for an agent, regardless of\nthe assessor. However, verifying the evolution of local trust scores according to the\nabove conditions is subjective. Suppose we obtained Table 11 from a local trust\nalgorithm. If we only consider direct experience between a and b, then we observe\nthat r(a, b) increased from 0.1 to 0.3 despite a negative feedback (f6), but this\nincrease may have been contributed by f5 and the fact that r(a, c) = 0.9. That is,\nr(a, b) is an aggregated score obtained through direct and indirect experiences and,\ndepending on the algorithm, different weights may be given to direct versus\nindirect experience [26].\n\nConclusions\nWe provided details of our prototype and evaluated trust algorithms for vulnerabili-\nties to attacks and adherence to trust properties. We were able to show that our model\ncould indeed accommodate various algorithms, and that the specification of experiments\nin terms of the model was straightforward and easy to express programmatically. The\nexperiments that we ran allowed us to make the following observations:\n\n• We were able to exhibit discrepancies between the outputs of EigenTrust and\nPeerTrust due to the way the initial normalized local trust values are calculated in\nEigenTrust; EigenTrust ignores the excess positive feedbacks once they outnumber\nnegative feedbacks;\n\n• There are tradeoffs between sensitivity to self-promotion and sensitivity to\nslandering. For example, an algorithm that is overly sensitive to slandering might take\ntoo long to incorporate bad feedback, and this allows bad behavior to go unnoticed\nfor a while. In general, the difficulty is that one cannot always detect an attack just by\nlooking at feedback history, since multiple interpretations are always possible.\n\nTable 11 Local reputation example\n\ni Assessor Assessee f r(a, b) r(a, c) r(c, b)\n\n1 a c 0.9 - 0.9 -\n\n2 a b 0.6 0.6 0.9 -\n\n3 a b 0.7 0.65 0.9 -\n\n4 a b 0.2 0.1 0.9 -\n\n5 c b 0.9 - 0.9 0.4\n\n6 a b 0 0.3 0.9 0.4\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 26 of 27\n\nClarification may come with the accumulation of feedback data, but multi-agent\nsystems might not be able to survive to see that accumulation, unless a certain\nnumber of pre-trusted nodes can be provided to bootstrap the system.\n\n• We were able to express and verify basic trust properties, such as weak transitivity\nand the fact that trust is more easily lost than gained. These should be building blocks\nupon which more complex properties could be expressed.\n\nWe have identified the following limitations and future work:\n\n• Since the feedback history graph limits itself to agent-to-agent transaction ratings,\nrecommender systems such as Credence [10] that use agent-to-object ratings cannot\nbe included in the testbed.\n\n• Trust systems that rely on different agent types (advisors, trusters, trustees, etc.) such\nas in [17] cannot be accommodated in our model.\n\n• Our framework cannot accommodate trust algorithms, such as REGRET [27] or FIRE\n[28], that use inputs other than feedback history.\n\n• Different agents might have different reputations in different contexts. Our testbed\ndoes not explicitly represent this context. One would have to create separate graphs\nfor each context (thus making the assumption that the contexts are independent\nfrom one another), and this might be an oversimplification in cases where trust in\none context partially influences trust in another context. We note however that in\nmost of the trust algorithms we have classified the notion of context is not explicitly\ntaken into account either.\n\n• Agent behavior simulation: it would be desirable to use agent simulations to\nautomatically generate feedback history graphs (stage 1 of the workflow). Such a\nfeature would be useful for designing large-scale experiments with each agent acting\nin a different manner.\n\n• Support for distrust: distrust indicates how much an agent is not trusted (opposite of\ntrustworthiness) and algorithms such as the distrust-aware version of Appleseed\ncompute both trust and distrust propagation. Because our reputation graphs do not\ninclude distrust information, such algorithms cannot be evaluated using our testbed.\n\nIn addition to addressing the above limitations in our model, future work involves\nimplementing more trust algorithms, building a user interface for our testbed and\nperforming large-scale experiments. In particular, experiments using large datasets from\nwebsites such as Epinions, Advogato, and Facebook can yield interesting results.\n\nEndnotes\n1In the remainder of the paper we will simply refer to the trust systems or models that\n\nhave no specific name by the name of the first author of the paper we are citing, so [5]\nwill be referred to as “Aberer”.\n\n2in what follows we will use the graph name and the labelling functions\ninterchangeably to reduce extraneous notations\n\n3Note that in this figure, we have included “0” in A × A �→ {0, 1} for a trust graph for\nclarity but in reality, it indicates that there is no edge.\n\n4http://code.google.com/p/repsystestbed/\n\nCompeting interests\nThe authors declare that they have no competing interests.\n\nhttp://code.google.com/p/repsystestbed/\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 27 of 27\n\nAuthors’ contributions\nPC did the implementation and ran the experiments, and participated in the formalization, the state of the art work and\nthe write-up. BE participated in the formalization, the state of the art work and the write-up. Both authors read and\napproved the final manuscript.\n\nReceived: 24 November 2014 Accepted: 3 July 2015\n\nReferences\n1. Kamvar SD, Schlosser MT, Garcia-Molina H (2003) The eigentrust algorithm for reputation management in p2p\n\nnetworks. In: WWW ’03 Proceedings of the 12th International Conference on World Wide Web. ACM, Budapest,\nHungary. pp 640–651. http://doi.acm.org/10.1145/775152.775242\n\n2. Xiong L, Liu L (2004) Peertrust: Supporting reputation-based trust for peer-to-peer electronic communities. IEEE\nTrans Knowl Data Eng 16(7):843–857\n\n3. Ziegler CN (2005) Chap. On propagating interpersonal trust in social networks. In: Computing with Social Trust.\nSpringer, London. pp 133–166\n\n4. Zimmermann PR (1995) The Official PGP User’s Guide. MIT Press, Cambridge, MA, USA\n5. Aberer K, Despotovic Z (2001) Managing trust in a peer-2-peer information system. In: CIKM ’01 Proceedings of the\n\nTenth International Conference on Information and Knowledge Management. ACM, Atlanta, GA. pp 310–317\n6. Teacy WTL, Patel J, Jennings N, Luck M (2006) Travos: Trust and reputation in the context of inaccurate information\n\nsources. Autonomous Agents Multi-Agent Syst 12(2):183–198. doi:10.1007/s10458-006-5952-x\n7. Jøsang A, Ismail R (2002) The beta reputation system. In: Proceedings of the 15th Bled Electronic Commerce\n\nConference. pp 41–55\n8. Levien R (2009) Chap. Attack-resistant Trust Metrics. In: Computing with Social Trust. Springer, London. pp 121–132\n9. Golbeck JA (2005) Computing and applying trust in web-based social networks. PhD thesis, University of Maryland\n\nat College Park\n10. Walsh K, Sirer EG (2006) Experience with an object reputation system for peer-to-peer filesharing. In: NSDI’06\n\nProceedings of the 3rd Conference on Networked Systems Design and Implementation. Usenix, Berkeley, USA\n11. Jøsang A, Pope S (2005) Semantic constraints for trust transitivity. In: Proceedings of the 2nd Asia-Pacific Conference\n\non Conceptual Modelling - Volume 43. APCCM ’05, Australian Computer Society, Inc., Darlinghurst, Australia,\nAustralia. pp 59–68. http://dl.acm.org/citation.cfm?id=1082276.1082284\n\n12. Hoffman K, Zage D, Nita-Rotaru C (2009) A survey of attack and defense techniques for reputation systems. ACM\nComput Surv 42:1–1131\n\n13. Marsh SP (1994) Formalising trust as a computational concept. PhD thesis, University of Stirling\n14. Abdul-Rahman A, Hailes S (2000) Supporting trust in virtual communities. In: HICSS ’00: Proceedings of the 33rd\n\nHawaii International Conference on System Sciences-Volume 6. IEEE Computer Society, Washington, DC, USA. p 6007\n15. Guha R (2004) Open rating systems. In: Proceedings of the 1st Workshop on Friends of a Friend, Social Networking\n\nand the Semantic Web. FOAF Galway, Galway, Ireland. http://www.w3.org/2001/sw/Europe/events/foaf-galway/\npapers/fp/open_rating_systems/wot.pdf. Accessed 31-Aug-2012\n\n16. Hazard CJ, Singh MP (September August 3) Macau: A basis for evaluating reputation systems. In: Rossi F (ed). IJCAI\n2013, Proceedings of the 23rd International Joint Conference on Artificial Intelligence, Beijing, China. AAAI\nPublications, Palo Alto, CA, USA. IJCAI/AAAI. http://www.aaai.org/ocs/index.php/IJCAI/IJCAI13/paper/view/6854\n\n17. Fullam K, Klos TB, Muller G, Sabater J, Schlosser A, Topol Z, Barber KS, Rosenschein JS, Vercouter L, Voss M (Unknown\nMonth July 25) A specification of the agent reputation and trust (ART) testbed: experimentation and competition for\ntrust in agent societies. In: Dignum F, Dignum V, Koenig S, Kraus S, Singh MP, Wooldridge M (eds). 4th International\nJoint Conference on Autonomous Agents and Multiagent Systems (AAMAS 2005). ACM, Utrecht, The Netherlands.\npp 512–518. doi:10.1145/1082473.1082551, http://doi.acm.org/10.1145/1082473.1082551\n\n18. Kerr R, Cohen R (2009) Smart cheaters do prosper: defeating trust and reputation systems. In: Proceedings of The 8th\nInternational Conference on Autonomous Agents and Multiagent Systems - Volume 2. AAMAS ’09. International\nFoundation for Autonomous Agents and Multiagent Systems, Richland, SC. pp 993–1000. http://portal.acm.org/\ncitation.cfm?id=1558109.1558151\n\n19. Thirunarayan K, Anantharam P, Henson C, Sheth A (2014) Comparative trust management with applications:\nBayesian approaches emphasis. Future Generation Comput Syst 31:182–199\n\n20. Yann Krupa JFH, Vercouter L (2009) Extending the Comparison Efficiency of the ART Testbed. In: Paolucci M (ed).\nProceedings of the First International Conference on Reputation: Theory and Technology - ICORE 09, Gargonza, Italy\n\n21. Kerr R, Cohen R (2010) Treet: the trust and reputation experimentation and evaluation testbed. Electron Commer\nRes 10:271–290\n\n22. O’Hara K (2012) A general definition of trust. http://eprints.soton.ac.uk/273193/\n23. Ceolin D, Nottamkandath A, Fokkink W (2014) Efficient semi-automated assessment of annotations trustworthiness.\n\nJ Trust Manag 1(1):1–31\n24. Myers JL, Well AD (2003) Research Design and Statistical Analysis. Lawrence Erlbaum Associates, New Jersey\n25. Jøsang A Trust and reputation systems. In: Aldini A, Gorrieri R (eds). Foundations of Security Analysis and Design IV,\n\nFOSAD 2006/2007 Tutorial Lectures. Lecture Notes in Computer Science. Springer, Berlin Vol. 4677. pp 209–245.\nhttp://dx.doi.org/10.1007/978-3-540-74810-6_8\n\n26. Guha R, Kumar R, Raghavan P, Tomkins A (2004) Propagation of trust and distrust. In: Proceedings of the 13th\nInternational Conference on World Wide Web, WWW ’04. ACM, New York, NY, USA. pp 403–412.\ndoi:10.1145/988672.988727, http://doi.acm.org/10.1145/988672.988727\n\n27. Sabater J, Sierra C (2001) Regret: A reputation model for gregarious societies. In: Fourth Workshop on Deception\nFraud and Trust in Agent Societies Vol. 70\n\n28. Dong-Huynha T, Jennings N, Shadbolt N (2004) Fire: An integrated trust and reputation model for open multi-agent\nsystems. In: 16th European Conference on Artificial Intelligence, Valencia, Spain. IOS Press, Amsterdam. pp 18–22\n\nhttp://doi.acm.org/10.1145/775152.775242\nhttp://dx.doi.org/10.1007/s10458-006-5952-x\nhttp://dl.acm.org/citation.cfm?id=1082276.1082284\nhttp://www.w3.org/2001/sw/Europe/events/foaf-galway/papers/fp/open_rating_systems/wot.pdf\nhttp://www.w3.org/2001/sw/Europe/events/foaf-galway/papers/fp/open_rating_systems/wot.pdf\nhttp://www.aaai.org/ocs/index.php/IJCAI/IJCAI13/paper/view/6854\nhttp://dx.doi.org/10.1145/1082473.1082551\nhttp://doi.acm.org/10.1145/1082473.1082551\nhttp://portal.acm.org/citation.cfm?id=1558109.1558151\nhttp://portal.acm.org/citation.cfm?id=1558109.1558151\nhttp://eprints.soton.ac.uk/273193/\nhttp://dx.doi.org/10.1007/978-3-540-74810-6_8\nhttp://dx.doi.org/10.1145/988672.988727\nhttp://doi.acm.org/10.1145/988672.988727\n\n\tAbstract\n\tKeywords\n\n\tIntroduction\n\tMotivation\n\tOverview of our solution and contributions\n\tOrganization\n\n\tBackground and literature review\n\tSocial trust models\n\tNature of input\n\tDirect vs. indirect trust\n\tGlobal vs. local trust\n\tTo trust or not to trust\n\tPeerTrust\n\tEigenTrust\n\tAppleseed\n\n\tTestbeds\n\tGuha\n\tMacau\n\tART\n\tTREET\n\n\tSummary\n\n\tProblem description and model\n\tStage 1—obtain feedback history graph\n\tStage 2—obtain reputation graph\n\tStage 3—obtain trust graph\n\n\tClassifying and chaining algorithms\n\tResults and discussion\n\tImplementation\n\tVulnerability assessments\n\tNormalization-based attack\n\tSetup\n\tResults\n\n\tSelf-promoting attack\n\tSetup\n\tResults\n\n\tSlandering attack, scenario 1\n\tSetup\n\tResults\n\n\tSlandering attack, scenario 2\n\tSetup\n\tResults\n\n\tSlandering + Sybil attack for local trust algorithms\n\tSetup\n\tResults\n\n\n\tTrust properties assessments\n\tWeak transitivity\n\tSetup\n\tResults\n\n\tDynamic evolution of global trust\n\tSetup and results\n\tScenario 1: evolution due to direct interactions only\n\tScenario 2: evolution due to direct and indirect interactions\n\n\tLimitations\n\n\n\n\tConclusions\n\tEndnotes\n\tCompeting interests\n\tAuthors' contributions\n\tReferences\n\n\n\n",
      "metadata_storage_path": "aHR0cHM6Ly9jb3Jwb3JhdGV0cmFpbmluZ3N0b3JhZ2UuYmxvYi5jb3JlLndpbmRvd3MubmV0L3BhcGVycy9zNDA0OTMtMDE1LTAwMTktei5wZGY1",
      "metadata_author": "Partheeban Chandrasekaran",
      "metadata_title": "Toward a testbed for evaluating computational trust models: experiments and analysis",
      "metadata_creation_date": "2015-09-04T09:59:41Z",
      "keyphrases": [
        "computational trust models",
        "testbed",
        "experiments",
        "analysis"
      ]
    },
    {
      "@search.score": 0.2457758,
      "content": "\nQER: a new feature selection method \nfor sentiment analysis\nTuba Parlar1* , Selma Ayşe Özel2 and Fei Song3\n\nIntroduction\n“What other people think” has always been an important piece of information for most \nof us during the decision making process [1]. The Internet and social media provide a \nmajor source of information about people’s opinions. Due to the rapidly-growing num-\nber of online documents, it becomes both time-consuming and hard to obtain and ana-\nlyze the desired opinionated information. Turkey is among the top 20 countries with the \nhighest numbers of Internet users according to the Internet World Stats.1 The exploding \ngrowth in the Internet users is one of the main reasons that sentiment analysis for differ-\nent languages and domains becomes an actively-studied area for many researchers \n[2–6].\n\nSentiment analysis (SA) is a natural language processing task that classifies the senti-\nments expressed in review documents as “positive” or “negative”. In general, SA is con-\nsidered as a two-class classification problem. However, some researchers use “neutral” as \n\n1 http://www.internetworldstats.com/.\n\nAbstract \n\nSentiment analysis is about the classification of sentiments expressed in review docu-\nments. In order to improve the classification accuracy, feature selection methods are \noften used to rank features so that non-informative and noisy features with low ranks \ncan be removed. In this study, we propose a new feature selection method, called \nquery expansion ranking, which is based on query expansion term weighting meth-\nods from the field of information retrieval. We compare our proposed method with \nother widely used feature selection methods, including Chi square, information gain, \ndocument frequency difference, and optimal orthogonal centroid, using four classi-\nfiers: naïve Bayes multinomial, support vector machines, maximum entropy model-\nling, and decision trees. We test them on movie and multiple kinds of product reviews \nfor both Turkish and English languages so that we can show their performances for \ndifferent domains, languages, and classifiers. We observe that our proposed method \nachieves consistently better performance than other feature selection methods, and \nquery expansion ranking, Chi square, information gain, document frequency difference \nmethods tend to produce better results for both the English and Turkish reviews when \ntested using naïve Bayes multinomial classifier.\n\nKeywords: Sentiment analysis, Feature selection, Machine learning, Text classification\n\nOpen Access\n\n© The Author(s) 2018. This article is distributed under the terms of the Creative Commons Attribution 4.0 International License \n(http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, \nprovided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and \nindicate if changes were made.\n\nRESEARCH\n\nParlar et al. Hum. Cent. Comput. Inf. Sci.  (2018) 8:10 \nhttps://doi.org/10.1186/s13673-018-0135-8\n\n*Correspondence:   \ntparlar@mku.edu.tr \n1 Department \nof Mathematics, Mustafa \nKemal University, Antakya, \nHatay, Turkey\nFull list of author information \nis available at the end of the \narticle\n\nhttp://orcid.org/0000-0002-8004-6150\nhttp://www.internetworldstats.com/\nhttp://creativecommons.org/licenses/by/4.0/\nhttp://crossmark.crossref.org/dialog/?doi=10.1186/s13673-018-0135-8&domain=pdf\n\n\nPage 2 of 19Parlar et al. Hum. Cent. Comput. Inf. Sci.  (2018) 8:10 \n\nthe third class label. There are a number of studies about sentiment analysis that use dif-\nferent approaches for data preprocessing, feature selection, and sentiment classification \n[1, 3, 4, 6–10]. The statistical methods such as Chi square (CHI2) and information gain \n(IG) are used to eliminate unnecessary or irrelevant features so that the classification \nperformance can be improved [11]. Supervised learning methods including naïve Bayes \n(NB), support vector machines (SVM), decision trees (DT), and maximum entropy mod-\nelling (MEM) are used to classify the sentiments of the reviews.\n\nAlthough SA can be considered as a text classification task, it has some differences \nfrom the traditional topic-based text classification. For example, instead of saying: “This \ncamera is great. It takes great pictures. The LCD screen is great. I love this camera” in a \nreview document, people are more likely to write: “This camera is great. It takes breath-\ntaking pictures. The LCD screen is bright and clear. I love this camera.” [8]. As can be \nseen, sentiment-expressing words like “great” are not so frequent within a particular \nreview, but can be more frequent across different reviews, and a good feature selection \nmethod for SA should take this observation into account.\n\nIn this paper, we propose a new feature selection method, called query expansion rank-\ning (QER) which is especially developed for reducing dimensionality of feature space of \nSA problems. The aim of this study is to show that our proposed method is effective for \nSA from review texts written in different languages (e.g., Turkish, English) and domains \n(e.g., movie reviews, book reviews, kitchen appliances reviews, etc.). QER is based on \nquery expansion term weighting methods used to improve the search performance of \ninformation retrieval systems [12, 13] and to evaluate its effectiveness as a feature selec-\ntor in SA, we compare it with other common feature selection methods, including CHI2, \nIG, document frequency difference (DFD), and optimal orthogonal centroid (OCFS), \nalong with four text classifiers: naïve Bayes multinomial (NBM), SVM, DT, and MEM, \nover ten different review documents datasets. Our goal is to examine whether these fea-\nture selection methods can reduce the feature sizes and improve the classification accu-\nracy of sentiment analysis with respect to different document domains, languages, and \nclassifiers.\n\nThe rest of the paper is organized as follows. “Related work” reviews the related work \non sentiment analysis. “Methods” presents the methods that we used for our study, \nincluding the new feature selection method we proposed. “Experiments and results” \ndescribes the experimental settings, datasets, performance measures, and testing results. \nFinally, “Conclusion” concludes the paper.\n\nRelated work\nSA is an important topic in Natural Language Processing and Artificial Intelligence. \nAlso known as opinion mining, SA mines people’s opinions, sentiments, evalua-\ntions, and emotions about entities such as products, services, organizations, individu-\nals, issues, and events, as well as their related attributes. This kind of analysis has many \nuseful applications. For example, it determines a product’s popularity according to \nthe user’s reviews. If the overall sentiments are negative, further analysis may be per-\nformed to identify which features contribute to the negative ratings so companies can \nreshape their businesses. Numerous studies have been done for sentiment analysis in \ndifferent domains, languages, and approaches [3–5, 8–10, 14–17]. Among these studies, \n\n\n\nPage 3 of 19Parlar et al. Hum. Cent. Comput. Inf. Sci.  (2018) 8:10 \n\nthe machine learning approaches are more popular since the models can be automati-\ncally trained and improved with the training datasets. Pang et al. [4] apply supervised \nmachine learning methods such as NB and SVM to sentiment classification. NB, SVM, \nMEM, and DT are some of the commonly used machine learning approaches [4, 7–9, \n14]. Feature selection methods are used to rank features so that non-informative features \ncan be removed to improve the classification performance [18]. Some researchers have \ninvestigated the effects of feature selection for sentiment analysis [3, 8–10, 19–25]. For \nexample, Yang and Yu [3] examine IG for feature selection and evaluate its performance \nusing NB, SVM, and C4.5 (popular implementation for DT) classifiers. Nicholls et al. [8] \ncompare their proposed DFD feature selection method against other feature selection \nmethods, including CHI2, OCFS [26], and count difference using the MEM classifier. \nAgarwal et al. [9] investigate minimum redundancy maximum relevancy (mRMR) and \nIG methods for sentiment classification using NBM and SVM classifiers. The results \nshow that mRMR performs better than IG for feature selection, and NBM performs bet-\nter than SVM in accuracy and execution time. Abbasi et al. [22] examine a new feature \nselection method called entropy weighted genetic algorithm (EWGA) and compare the \nperformance of this method using information gain feature selection method. EWGA \nachieves a relatively high accuracy of 91.7% using SVM classifier. Xia et al. [24] design \ntwo types of feature sets: POS based and word relation based. Their word relation based \nmethod improves an accuracy of 87.7 and 85.15% on movie and product datasets. Bai \n[25] proposes a Tabu heuristic search-enhanced Markov blanket model that provides a \nvocabulary to extract sentiment features. Their method achieves an accuracy of 92.7% \nfor the movie review dataset. Mladenovic et al. [16] propose a feature selection method \nthat is based on mapping of a large number of related features to a few features. Their \nproposed method improves the classification performance using unigram features \nwith 95% average accuracy. Zheng et al. [27] perform comparative experiments to test \ntheir proposed improved document frequency feature selection method. Their method \nachieves significant improvement in sentiment analysis of Chinese online reviews with \nan accuracy of 97.3%.\n\nMost of the SA studies listed above focus on the English language. Only few studies \nhave been done on SA for the Turkish language [6, 10, 19, 28–31]. The Turkish language \nbelongs to the Altaic branch of the Ural-Altaic family of languages and is mainly used in \nthe Republic of Turkey. Turkish is an agglutinative language similar to Finnish and Hun-\ngarian, where a single word can be translated into a relatively longer sentence in English \n[32]. For instance, word “karşılaştırmalısın” in Turkish can be expressed as “you must \nmake (something) compare” in English. As Turkish and English have different charac-\nteristics, methods developed for SA in English need to be tested for Turkish. Among \nthe few researchers who investigate the effects of feature selection on the SA of Turkish \nreviews, Boynukalın [29] applies Weighted Log Likelihood Ratio (WLLR) to reduce fea-\nture space with NB, Complementary NB, and SVM classifiers for the emotional analysis \nusing the combinations of n-grams where sequences of n words are considered together. \nIt is shown that WLLR helps to improve the accuracy with reduced feature sizes. Akba \net al. [19] implement and compare the performance of reduced feature sizes using two \nfeature selection methods: CHI2 and IG with NB and SVM classifiers. They show that \nfeature selection methods improve the classification accuracy.\n\n\n\nPage 4 of 19Parlar et al. Hum. Cent. Comput. Inf. Sci.  (2018) 8:10 \n\nOur aim is to propose a new feature selection method for the SA of Turkish and Eng-\nlish reviews. We presented an initial version of this method in [10] where we employ \nonly product review dataset in Turkish and compare our method with CHI2 and DFD \nby using only one classifier. We now extend it to more datasets for Turkish, and also \ninvestigate the performance of our method in English datasets to show that our method \nis language independent. We further include more feature selection methods especially \ndeveloped for SA and compare the performance of our proposed method using NBM, \nSVM, MEM, and DT classifiers along with statistical analysis to prove that our method is \nclassifier independent.\n\nMethods\nMachine learning algorithms\n\nFor sentiment classification, we use the Weka [33] data mining tool, which contains the \nfour classifiers we use in our experiments, i.e., NBM, SMO for SVM, J48 for C4.5, and LR \nfor MEM. We choose NBM, SVM, LR, and J48 classification methods due to the follow-\ning reasons: (i) many researchers use NBM for text classification because it is computa-\ntionally efficient [9, 10, 14] and performs well for large vocabulary sizes [34]; (ii) SVM \ntends to perform well for traditional text classification tasks [3, 4, 7, 14, 35]; (iii) LR is \nknown to be equivalent to MEM which is another method used in SA studies [8]; (iv) J48 \nis a well-known decision tree classifier for many classification problems and is used for \nSA [3, 30].\n\nFeature selection\n\nFeature Selection methods have been shown to be useful for text classification in general \nand sentiment analysis in specific [11, 18]. Such methods rank features according to cer-\ntain measures so that non-informative features can be removed, and at the same time, \nthe most valuable features can be kept in order to improve the classification accuracy \nand efficiency. In this study, we consider several feature selection methods, including \ninformation gain, Chi square, document frequency difference, optimal orthogonal cen-\ntroid, and our new query expansion ranking (QER) so that we can compare their effec-\ntiveness for the sentiment analysis.\n\nFeature sizes are selected in the range from 500 to 3000 with 500 increments, com-\npared with the total feature sizes ranging from 8000 to 18,000 for the Turkish review \ndatasets and from 8000 to 38,000 for English review datasets. In our previous study [10], \nwe observed that feature sizes up to 3000 tend to give good classification performance \nimprovement; therefore we choose these feature sizes in our experiments.\n\nInformation gain\n\nInformation gain is one of the most common feature selection methods for sentiment \nanalysis [3, 9, 19, 35], which measures the content of information obtained after knowing \nthe value of a feature in a document. The higher the information gain, the more power \nwe have to discriminate between different classes.\n\nThe content of information can be calculated by the entropy that captures the uncer-\ntainty of a probability distribution for the given classes. Given m number of classes: \nC = {c1,c2,…,cm} the entropy can be given as follows:\n\n\n\nPage 5 of 19Parlar et al. Hum. Cent. Comput. Inf. Sci.  (2018) 8:10 \n\nwhere P(ci) is the probability of how many documents in class ci. If an attribute A has n \ndistinct values: A = {a1,a2,…,an}, then the entropy after the attribute A is observed can be \ndefined as follows:\n\nwhere P(aj) is the probability of how many documents contain the attribute value aj, and \nP(ci|aj) is the probability of how many documents in class ci that contain the attribute \nvalue aj. Based on the definitions above, the information gain for an attribute is simply \nthe difference between the entropy values before and after the attribute is observed:\n\nFor sentiment analysis, we normally classify the reviews into positive and negative cat-\negories, and for each keyword, it either occurs or does not occur in a given document; so \nthe above formulas can be further simplified. Nevertheless, we can cut down the number \nof features in the same way by choosing the keywords that have high information gain \nscores.\n\nChi square (CHI2)\n\nChi square measures the dependence between a feature and a class. A higher score \nimplies that the related class is more dependent on the given feature. Thus, a feature with \na low score is less informative and should be removed [3, 8, 10, 19]. Using the 2-by-2 \ncontingency table for feature f and class c, where A is the number of documents in class c \nthat contains feature f, B is the number of documents in the other class that contains f, C \nis the number of documents in c that does not contain f, D is the number of documents \nin the other class that does not contain f, and N is the total number of documents, then \nthe Chi square score can be defined in the following:\n\nThe Chi square statistics can also be computed between a feature and a class in the \ndataset, which are then combined across all classes to get the scores for each feature as \nfollows:\n\nOne problem with the CHI2 method is that it may produce high scores for rare features \nas long as they are mostly used for one specific class. This is a bit counter-intuitive, since \nrare features are not frequently used in text and thus do not have a big impact for text \n\n(1)H(C) = −\n\nm\n∑\n\ni=1\n\nP(ci) log2 P(ci)\n\n(2)H(C|A) =\n\nn\n∑\n\nj=1\n\n(\n\n−P(aj)\n\nm\n∑\n\ni=1\n\nP(ci|aj) log2P(ci|aj)\n\n)\n\n(3)IG(A) = H(C)−H(C|A)\n\n(4)χ2\n(\n\nf , c\n)\n\n=\nN (AD − CB)2\n\n(A+ C)(B+ D)(A+ B)(C + D)\n\n(5)χ2(f ) =\n\nm\n∑\n\ni=1\n\nP(ci)χ\n2(f , ci)\n\n\n\nPage 6 of 19Parlar et al. Hum. Cent. Comput. Inf. Sci.  (2018) 8:10 \n\nclassification. For SA, however, this is not a big issue since many sentiment-expressing \nfeatures are not frequently used within an individual review.\n\nDocument frequency difference\n\nInspired by the observation that sentiment-expressing words tends to be less frequent \nwithin a review, but more frequent across different reviews, Nicholls and Song [8] pro-\npose the DFD method that tries to differentiate the features for positive and negative \nclasses, respectively, across a document collection. More specifically, DFD is calculated \nas follows:\n\nwhere DFf\n+ is the number of documents in the positive class that contain feature f, DFf\n\n− \nis the number of documents in the negative class that contain f, and N is the total num-\nber of documents in the dataset. Note that all scores are normalized between 0 and 1; \nso they should be proportional for us to rank the features in a document collection. For \nexample, a non-sentiment word may have similar document frequencies in both posi-\ntive and negative classes, and will get a low score, but a sentiment word for the positive \nclass may have a bigger difference, resulting in a higher score. One limitation of the DFD \nmethod is that it requires an equal or nearly equal number of documents in both classes, \nwhich is more or less true for the datasets used in our experiments.\n\nOptimal orthogonal centroid (OCFS)\n\nOCFS method is an optimized form of the orthogonal centroid algorithm [26]. Docu-\nments are represented as high dimensional vectors where the weights of each dimension \ncorrespond to the importance of the related features, and a centroid is simply the aver-\nage vector for a set of document vectors. OCFS aims at finding a subset of features that \ncan make the sum of distances between all the class means maximized in the selected \nsubspace. The score of a feature f by OCFS is defined in the following [8]:\n\nwhere Nc is the number of documents in class c, N is the number of documents in the \ndataset, mc is the centroid for class c, m is the centroid for the dataset D, and mf, mc\n\nf are \nthe values of feature f in centroid m, mc respectively. The centroids of m and mc are cal-\nculated as follows:\n\nQuery expansion ranking\n\nQuery expansion ranking method is our proposed feature selection method inspired \nby the query expansion methods from the field of information retrieval (IR). Query \n\n(6)Scoref =\n|DF\n\nf\n+ − DF\n\nf\n−|\n\nN\n\n(7)Scoref =\n∑\n\nc\n\nNc\n\nN\n\n(\n\nm\nf\nc −mf\n\n)2\n\n(8)mc =\n\n∑\n\nxi∈c\nxi\n\nNc\n\n(9)m =\n\n∑\n\nxi∈D\nxi\n\nN\n\n\n\nPage 7 of 19Parlar et al. Hum. Cent. Comput. Inf. Sci.  (2018) 8:10 \n\nexpansion helps to find more relevant documents for a given query. It does so by adding \nnew terms to the query. The new terms are selected from documents that are relevant \nto the original query so that the expanded query can retrieve more relevant documents. \nMore specifically, terms from the relevant documents are extracted along with some \nscores, and those with the highest scores are included in the expanded query.\n\nWe propose a new feature selection method inspired by the query expansion technique \ndeveloped for probabilistic weighting model proposed by Harman [12]. Harman [12, 36] \nstudies how to assign scores to terms extracted from relevant documents for a given \nquery Q so that high scored terms are used to expand the original query and improve \nprecision of information retrieval strategy. In this method, first, query Q is sent to the \ninformation retrieval system, and then the system returns documents that are found as \nrelevant to the user. Then, user examines the returned documents and marks the ones \nthat are relevant with the query. After that, all the terms in the relevant documents are \nextracted and they are assigned scores by using a score formula as proposed by Har-\nman [12], and top scored k terms are chosen as the most valuable terms to expand the \nquery. Then, the expanded query Q’, which includes the terms in the original query plus \nthe k new terms that have the top-k scores, is sent to the information retrieval system to \nreturn more relevant documents to the original query Q. Equation 10 presents the score \nformula developed by Harman [12] to calculate ranking score of a term f extracted from \nthe set of relevant documents for a given query Q.\n\nwhere pf is the probability of term f in the set of relevant documents for query Q, and qf \nis the probability of term f in the set of non-relevant documents for query Q. These prob-\nability scores are computed according to Robertson and Sparck Jones [13].\n\nWe revise the above score computation method to develop an efficient feature selector \nfor SA. In our feature selection method, we propose a score formula given in Eq. 11 to \ncompute scores for features:\n\nwhere pf is the ratio of positive documents containing feature f and qf is the ratio of \nnegative documents containing feature f, which are computed according to Eqs. 12, 13, \nrespectively:\n\n(10)Scoref = log2\npf\n(\n\n1− qf\n)\n\n(\n\n1− pf\n)\n\nqf\n\n(11)Scoref =\npf + qf\n∣\n\n∣pf − qf\n∣\n\n∣\n\n(12)pf =\nDF\n\nf\n+ + 0.5\n\nN+ + 1.0\n\n(13)qf =\nDF\n\nf\n− + 0.5\n\nN− + 0.5\n\n\n\nPage 8 of 19Parlar et al. Hum. Cent. Comput. Inf. Sci.  (2018) 8:10 \n\nwhere DFf\n+ and DFf\n\n− are the raw counts of documents that contain f in the positive and \nnegative classes, respectively and N+ and N− are the numbers of documents in the \npositive and negative classes, respectively. In the probability calculations, we add small \nconstants to the numerators and denominators in Eqs. 12, 13 following Robertson and \nSparck Jones [13] who add similar constants to avoid having zero probabilities. Such a \nmethod is known as data smoothing in statistical language processing.\n\nIn QER feature selection method, scores of features are computed before the features \nhaving the lowest scores are selected and used in the classification process. When a fea-\nture has low score, the difference between the probabilities for the positive and negative \nclasses is high; therefore the feature is more class specific and more valuable for clas-\nsification process. Among the feature selection methods we considered, we notice that \nIG and OCFS are good at distinguishing multiple classes, while CHI2, DFD, and QER \nare restricted to two classes, although all of them are suitable for sentiment analysis. IG \nis considered as a greedy approach since it favors those that can maximize the informa-\ntion gain for separating the related classes. Although CHI2 tries to identify the features \nthat are dependent to a class, it can also give high values to rare features that only affect \nfew documents in a given collection. OCFS has been shown to be effective for tradi-\ntional topic-based text classification, but it depends on the distance/similarity measures \nbetween the vectors of the related documents. Since sentiment-expressing features do \nnot happen frequently within a review, as illustrated by the example in the introduction, \nthey may not be favored by the OCFS method. QER is similar to DFD in that they both \nrely on the differences of the document frequencies of a given feature between the two \nclasses. However, QER is different from DFD in that it normalizes the document fre-\nquencies of a feature in both classes into probabilities and uses the ratio of the sum over \nthe difference for these two probabilities.\n\nExperiments and results\nDatasets\n\nWe use Turkish and English review datasets in our experiments. The Turkish movie \nreviews are collected from a publicly available website (http://www.beyazperde.com) \n[30]. The dataset has 1057 positive and 978 negative reviews. The Turkish product review \ndataset is collected from an e-commerce website (http://www.hepsiburada.com) from \ndifferent domains [28]. It consists of four subsets of reviews about books, DVDs, elec-\ntronics, and kitchen appliances, each of which has 700 positive and 700 negative reviews. \nTo compare our results with existing work for sentiment analysis, we use similar datasets \nfor English reviews. The English movie review dataset is introduced by Pang and Lee [7], \nand consists of 1000 positive and 1000 negative reviews. English product review dataset \nis introduced by Blitzer et al. [37] and also has four subsets: books, DVDs, electronics, \nand kitchen appliances, with 1000 positive and 1000 negative reviews for each subset. In \norder to keep the same dataset sizes with Turkish product reviews, we randomly select \n700 positive and 700 negative reviews from each subset of the English product reviews.\n\nPerformance evaluation\n\nThe performance of a classification system is typically evaluated by F measure, which \nis a composite score of precision and recall. Precision (P) is the number of correctly \n\nhttp://www.beyazperde.com\nhttp://www.hepsiburada.com\n\n\nPage 9 of 19Parlar et al. Hum. Cent. Comput. Inf. Sci.  (2018) 8:10 \n\nclassified items over the total number of classified items with respect to a class. Recall \n(R) is the number of correctly classified items over the total number of items that belong \nto a given class. Together, the F measure gives the harmonic mean of precision and \nrecall, and is calculated as follows [33]:\n\nSince we are doing multi-fold cross validations in our experiments, we use the micro-\naverage of F measure for the final classification results. This is done by adding the clas-\nsification results for all documents across all five folds before computing the final P, R, \nand the F.\n\nExperimental settings\n\nWe conduct the experiments on a MacBook Pro with 2.5 GHz Intel Core i7 processor \nand 16 GB 1600 MHz DDR3. We use Python with NLTK [38] library in our experiments. \nAfter tokenizing text into words along with case normalization, we keep some punctua-\ntion marks and stop words, as they may express sentiments (e.g., punctuation marks like \nexclamation and question marks, and stop words like “too” in “too expensive”). In addi-\ntion, we do not apply stemming as Turkish is an agglutinative language and the polarity \nof a word is often included in the suffixes. Therefore, we can have a large feature space \nand it becomes important to apply feature selection methods to reduce this space. For \nsentiment classification, we use the Weka [33] data mining tool, which contains the four \nclassifiers we use in our experiments, i.e., NBM, SMO for SVM, J48 for C4.5, and LR for \nMEM. Since our datasets are relatively small with at most a couple of thousands of docu-\nments, we apply the fivefold cross validation, which divides a dataset into five portions: \nfour of them are used for training and the remaining one for testing, and then these por-\ntions are rotated to get a total of five F measures. Table 1 the average F measures for all \nthe classifiers where the whole feature spaces are used for each dataset, except the LR \nclassifier since it requires too much memory to handle the whole feature spaces for these \ndatasets. As can be seen in Table  1, the total number of features without any reduc-\ntion ranges from 9000 to 18,000 for the Turkish review datasets, and 8,000–38,000 for \nthe English review datasets. These results form the baselines of our study and any new \nresults obtained with feature selection methods by applying five folds cross validation \ncan be compared for possible improvements.\n\n(14)F = 2×\nP × R\n\nP + R\n\nTable 1 Baseline results in F measure for the Turkish and English review datasets\n\nTurkish review datasets English review datasets\n\nFeatures NBM SVM J48 LR Features NBM SVM J48 LR\n\nMovie 18,578 0.8248 0.8161 0.6954 – 38,869 0.8129 0.8480 0.6769 –\n\nDVDs 11,343 0.7957 0.7320 0.6886 – 17,674 0.7836 0.7649 0.6789 –\n\nElectronics 10,911 0.8155 0.7707 0.7371 – 9010 0.7629 0.7856 0.6750 –\n\nBook 10,511 0.8317 0.7955 0.7019 – 18,306 0.7619 0.7485 0.6407 –\n\nKitchen 9447 0.7762 0.7407 0.6647 – 8076 0.8099 0.8136 0.7093 –\n\n\n\nPage 10 of 19Parlar et al. Hum. Cent. Comput. Inf. Sci.  (2018) 8:10 \n\nPerformance of feature selection methods for Turkish reviews\n\nWe tested five feature selection methods: QER, CHI2, IG, DFD, and OCFS on both \nTurkish and English review datasets. For each feature selection method, we tried six fea-\nture sizes at 500, 1000, 1500, 2000, 2500, and 3000, since this is the range typically con-\nsidered for text classification, and in terms of total features, we have 9000–18,000 for the \nTurkish review datasets, and 8000–38,000 for English review datasets from our baseline \nsystems. In our previous study [10], we also observed that feature sizes up to 3000 tend \nto give good classification performance. For all feature selection methods, we pick the \ntop-ranked features of a desirable size n based on the scores of the related formulas for \nthese methods. All of these settings are run against four classifiers: NBM, SVM, LR, and \nJ48, resulting in a total of 120 experiments for each review dataset. Table 2 summarizes \nthe best results for all pairs of feature selection methods and Turkish review datasets. \nFor each pair, we show the best micro-average F measure along with the correspond-\ning classifier and feature size. Also, the best results for each review dataset are given in \nbold-face.\n\nAs observed in Table 2, our new method QER is the best performer for each review \ndataset. CHI2 and IG have almost the same performance for the Turkish reviews and \nhave better results than DFD and OCFS for the movie, book, DVDs, and kitchen review \ndatasets. DFD with NBM classifier has better results than CHI2, IG, and OCFS for the \nelectronics review dataset. Also, CHI2, IG, and QER tend to work well with smaller fea-\nture sizes, while DFD and OCFS tend to favour bigger feature sizes. Note that DFD does \nreasonably well across all review datasets, which confirms our intuition that sentiment-\nexpressing words usually have low frequencies within a document, but relatively high \nfrequencies across different documents. Although OCFS is quite robust for traditional \ntopical text classification as reported in Cai and Song [39], it is not doing well for senti-\nment analysis, perhaps for the same intuition as we just explained for DFD. Once again, \nNBM remains to be the best for most of our experiments except that SVM does the best \nfor the kitchen reviews when analysed with the CHI2 and IG methods. When analysed \nby univariate ANOVA and post hoc tests for the book, DVDs, electronics, and kitchen \nreview datasets, we found that there are significant differences between three groups \n(Baseline and OCFS), (DFD, CHI2, and IG) and (QER) at 95% confidence level. Within \neach group, however, there are no significant differences. For the movie review dataset, \nthere are significant differences between two groups (Baseline and OCFS), and (DFD, \nCHI2, IG, and QER) at the 95% confidence level. Overall, feature selection methods are \nshown to be effective for sentiment analysis, improving significantly over the baseline \nresults.\n\nTo examine the effects of text classifiers, we show the best classification results for \npairs of feature selection methods and text classifiers on the electronic review dataset in \nTable 3. Note that NBM does the best for all review datasets; J48 the worst; and SVM and \nLR in between, although LR is consistently better than SVM except for the QER method. \nOne reason that the decision-tree-based solution J48 does not do well for text classifi-\ncation in general [40] and sentiment analysis in specific is that it is a greedy approach, \nalways trying to find the features that separate the given classes the most. As a result, the \nclassifier may use a much smaller set of features, even though there are many more rel-\nevant features are available. SVM typically does well for the traditional topic-based text \n\n\n\nPage 11 of 19Parlar et al. Hum. Cent. Comput. Inf. Sci.  (2018) 8:10 \n\nTa\nb\n\nle\n 2\n\n T\nh\n\ne \nb\n\nes\nt c\n\nla\nss\n\nifi\nca\n\nti\no\n\nn\n r\n\nes\nu\n\nlt\ns \n\nfo\nr \n\np\nai\n\nrs\n o\n\nf f\nea\n\ntu\nre\n\n s\nel\n\nec\nti\n\no\nn\n\n m\net\n\nh\no\n\nd\ns \n\nan\nd\n\n th\ne \n\nTu\nrk\n\nis\nh\n\n r\nev\n\nie\nw\n\n d\nat\n\nas\net\n\ns\n\nQ\nER\n\nD\nFD\n\nO\nC\n\nFS\nC\n\nH\nI2\n\nIG\n\nSi\nze\n\nF \nm\n\nea\nsu\n\nre\nSi\n\nze\nF \n\nm\nea\n\nsu\nre\n\nSi\nze\n\nF \nm\n\nea\nsu\n\nre\nSi\n\nze\nF \n\nm\nea\n\nsu\nre\n\nSi\nze\n\nF \nm\n\nea\nsu\n\nre\n\nM\nov\n\nie\n30\n\n00\nN\n\nBM\n:0\n\n.9\n11\n\n2\n30\n\n00\nN\n\nBM\n:0\n\n.8\n86\n\n4\n30\n\n00\nN\n\nBM\n:0\n\n.8\n44\n\n7\n15\n\n00\nN\n\nBM\n:0\n\n.8\n88\n\n3\n15\n\n00\nN\n\nBM\n:0\n\n.8\n88\n\n3\n\nD\nVD\n\ns\n15\n\n00\nN\n\nBM\n:0\n\n.9\n13\n\n6\n30\n\n00\nN\n\nBM\n:0\n\n.8\n65\n\n0\n30\n\n00\nN\n\nBM\n:0\n\n.8\n12\n\n9\n50\n\n0\nN\n\nBM\n:0\n\n.8\n67\n\n1\n50\n\n0\nN\n\nBM\n:0\n\n.8\n67\n\n1\n\nEl\nec\n\ntr\non\n\nic\ns\n\n15\n00\n\nN\nBM\n\n:0\n.8\n\n99\n6\n\n15\n00\n\nN\nBM\n\n:0\n.8\n\n56\n7\n\n20\n00\n\nN\nBM\n\n:0\n.8\n\n33\n7\n\n10\n00\n\nN\nBM\n\n:0\n.8\n\n56\n4\n\n15\n00\n\nN\nBM\n\n:0\n.8\n\n55\n1\n\nBo\nok\n\n15\n00\n\nN\nBM\n\n:0\n.9\n\n15\n0\n\n15\n00\n\nN\nBM\n\n:0\n.8\n\n77\n1\n\n30\n00\n\nN\nBM\n\n:0\n.8\n\n50\n6\n\n10\n00\n\nN\nBM\n\n:0\n.8\n\n86\n4\n\n10\n00\n\nN\nBM\n\n:0\n.8\n\n86\n4\n\nKi\ntc\n\nhe\nn\n\n10\n00\n\nN\nBM\n\n:0\n.8\n\n79\n0\n\n30\n00\n\nN\nBM\n\n:0\n.8\n\n31\n4\n\n30\n00\n\nN\nBM\n\n:0\n.8\n\n01\n7\n\n50\n0\n\nSV\nM\n\n:0\n.8\n\n37\n8\n\n50\n0\n\nSV\nM\n\n:0\n.8\n\n37\n8\n\n\n\nPage 12 of 19Parlar et al. Hum. Cent. Comput. Inf. Sci.  (2018) 8:10 \n\nclassification by finding a hyperplane that clearly separates the two classes [40]. In order \nto do this, we need to represent documents as weighted vectors so that we can measure \nthe distances or similarities between the documents. For sentiment analysis, however, \nwe are favouring features that have low frequencies within a document, but relatively \nhigh frequencies across different documents (as illustrated by the example of “great” in \nthe introduction), making the distance/similarity measures less effective. Both NBM and \nLR are based on the probabilities of the features in the given dataset. In particular, LR \nis equivalent to the maximum entropy modelling and is capable of handling dependent \nfeatures, whereas NBM makes the naïve assumption that all features are independent \nof each other. In our experiments, NBM does better than LR, which could be due to the \nsame reason as we just explained for SVM above.\n\nTo see the impacts of feature sizes for different feature selection methods, we plot our \nresults for the Turkish electronic review dataset in Fig.  1. Clearly, OCFS lags behind \nother feature selection methods across all feature sizes. DFD tends to do better with big-\nger feature sizes, while CHI2 and IG tend to favour smaller feature sizes. In addition, \nthe results for CHI2 and IG are sufficiently close, although they are slightly different for \ncertain feature sizes. Our new method QER does reasonably well across all other meth-\nods. For Turkish electronics review dataset, QER is the best performer and the selected \nfeatures include 7.7% of the punctuation patterns and 25% of the stop words; the features \nselected by DFD method include 61.5% of the punctuation patterns and 59% of the stop \nwords; the features selected by CHI2 method include 15% of the punctuation patterns \nand 90% of the stop words; and the features selected by OCFS method include 69.2% of \n\nTable 3 Detailed results for the Turkish electronics review dataset\n\nNBM SVM LR J48\n\nSize F measure Size F measure Size F measure Size F measure\n\nQER 1500 0.8996 2000 0.8715 1000 0.7927 2000 0.6734\n\nCHI2 1000 0.8564 1000 0.8505 500 0.7969 1000 0.7435\n\nIG 1500 0.8551 1000 0.8505 500 0.8156 1500 0.7428\n\nDFD 1500 0.8567 1500 0.8128 2500 0.7829 500 0.7399\n\nOCFS 2000 0.8337 1000 0.7729 3000 0.7643 1500 0.7371\n\nFig. 1 Detailed results of feature sizes for the Turkish electronic review dataset\n\n\n\nPage 13 of 19Parlar et al. Hum. Cent. Comput. Inf. Sci.  (2018) 8:10 \n\nthe punctuation patterns and 49.6% of the stop words. Therefore, CHI2 method tends \nto favor stop words but not punctuation patterns, while DFD and OCFS tend to choose \nmore punctuation patterns and fewer stop words. In addition, when we compare the fea-\ntures selected by QER and CHI2 methods, we observe that 5.7% of selected features are \nthe same, and for QER and DFD methods, there are 6.9% of the features that are com-\nmon, and for QER and OCFS methods, there are 7% of the features that are common. \nHowever, for DFD and CHI2 methods, we observe that 49.8% of the selected features are \nthe same, and for DFD and OCFS methods, there are 76.7% of the features that are com-\nmon, and for CHI2 and OCFS methods, there are 34% of the features that are common. \nNote that although we only show the results on specific datasets in Table 3 and Fig. 1, \nsimilar trends are observed for other datasets as well, and to save space these results are \nnot included.\n\nPerformance of feature selection methods for English reviews\n\nUsing similar settings as described in “Performance of feature selection methods for \nTurkish reviews”, we also carried out experiments on the English review datasets. As \nshown in Table 4, QER achieved the best performance with LR classifier for the movie \nreview dataset and NBM classifier for other datasets. CHI2 and IG achieved better per-\nformance with NBM for all five datasets. Once again, the results are basically the same \nfor CHI2 and IG, indicating that the two methods are also strongly correlated for the \nEnglish review datasets. Compared with the Turkish movie reviews, the feature size for \nthe best performer of the English movie reviews is 3000, which is achieved with QER for \nthe LR classifier. This is likely due to the bigger vocabulary of the English movie reviews \nover that of the Turkish movie reviews as can be observed in Table 1. Also compared \nwith the Turkish review datasets, DFD is not as good as CHI2 and IG for the English \nreview datasets, even though the performance is close for the kitchen reviews and gener-\nally better than OCFS. Furthermore, the best results for DFD are achieved with differ-\nent classifiers for different datasets: SVM for the movie reviews and LR for the kitchen \nreviews. Statistical analysis with univariate ANOVA and post hoc tests show similar \nresults as those for the Turkish reviews: there are significant differences between three \ngroups (Baseline and OCFS), (DFD), and (CHI2, IG, and QER) at 95% confidence level \nfor the movie, DVDs, electronic, and kitchen review datasets, but for the book review \ndataset, there are significant differences between two groups (Baseline and OCFS) and \n(DFD, CHI2, IG, and QER) at the 95% confidence level.\n\nFor text classifiers, Table  4 shows that similar trends are observed for the English \nreviews as those for the Turkish reviews, although LR and SVM can over-perform NBM \nfor some feature selection methods. For different feature sizes, similar trends are also \nobserved, as illustrated in Fig.  2. Once again, in Table  5 and Fig.  2, we only show the \nresults for specific datasets, but the trends are similar to other datasets as well.\n\nIn summary, we see some similarities between Turkish and English reviews in that for \ndata pre-processing, we should keep punctual patterns and stop words, and not per-\nform stemming, leading us to use the same setting as the baselines for further study. \nIn addition, NBM seems to be the most suitable classifier for sentiment analysis since \nsentiment-expressing words tend to have low frequencies within a document, but rela-\ntively high frequencies across different documents. For feature selection methods, our \n\n\n\nPage 14 of 19Parlar et al. Hum. Cent. Comput. Inf. Sci.  (2018) 8:10 \n\nTa\nb\n\nle\n 4\n\n T\nh\n\ne \nb\n\nes\nt c\n\nla\nss\n\nifi\nca\n\nti\no\n\nn\n r\n\nes\nu\n\nlt\ns \n\nfo\nr \n\np\nai\n\nrs\n o\n\nf f\nea\n\ntu\nre\n\n s\nel\n\nec\nti\n\no\nn\n\n m\net\n\nh\no\n\nd\ns \n\nan\nd\n\n th\ne \n\nEn\ng\n\nlis\nh\n\n r\nev\n\nie\nw\n\n d\nat\n\nas\net\n\ns\n\nQ\nER\n\nD\nFD\n\nO\nC\n\nFS\nC\n\nH\nI2\n\nIG\n\nSi\nze\n\nF \nm\n\nea\nsu\n\nre\nSi\n\nze\nF \n\nm\nea\n\nsu\nre\n\nSi\nze\n\nF \nm\n\nea\nsu\n\nre\nSi\n\nze\nF \n\nm\nea\n\nsu\nre\n\nSi\nze\n\nF \nm\n\nea\nsu\n\nre\n\nM\nov\n\nie\n30\n\n00\nLR\n\n:0\n.9\n\n55\n0\n\n25\n00\n\nSV\nM\n\n:0\n.8\n\n64\n0\n\n30\n00\n\nSV\nM\n\n: 0\n.8\n\n28\n5\n\n25\n00\n\nN\nBM\n\n:0\n.9\n\n15\n0\n\n25\n00\n\nN\nBM\n\n:0\n.9\n\n15\n0\n\nD\nVD\n\ns\n25\n\n00\nN\n\nBM\n:0\n\n.9\n16\n\n9\n30\n\n00\nN\n\nBM\n:0\n\n.8\n50\n\n2\n10\n\n00\nN\n\nBM\n:0\n\n.7\n99\n\n6\n10\n\n00\nN\n\nBM\n:0\n\n.8\n96\n\n4\n10\n\n00\nN\n\nBM\n:0\n\n.8\n96\n\n4\n\nEl\nec\n\ntr\non\n\nic\ns\n\n20\n00\n\nN\nBM\n\n:0\n.8\n\n87\n8\n\n15\n00\n\nN\nBM\n\n:0\n.8\n\n22\n1\n\n20\n00\n\nSV\nM\n\n: 0\n.7\n\n82\n1\n\n10\n00\n\nN\nBM\n\n:0\n.8\n\n62\n1\n\n10\n00\n\nN\nBM\n\n:0\n.8\n\n62\n1\n\nBo\nok\n\n30\n00\n\nN\nBM\n\n:0\n.9\n\n16\n2\n\n30\n00\n\nN\nBM\n\n:0\n.8\n\n62\n8\n\n30\n00\n\nN\nBM\n\n:0\n.7\n\n89\n9\n\n10\n00\n\nN\nBM\n\n:0\n.8\n\n87\n9\n\n10\n00\n\nN\nBM\n\n:0\n.8\n\n87\n9\n\nKi\ntc\n\nhe\nn\n\n20\n00\n\nN\nBM\n\n:0\n.9\n\n10\n6\n\n30\n00\n\nLR\n:0\n\n.8\n89\n\n3\n15\n\n00\nSV\n\nM\n: 0\n\n.8\n15\n\n7\n50\n\n0\nN\n\nBM\n:0\n\n.8\n96\n\n4\n50\n\n0\nN\n\nBM\n:0\n\n.8\n96\n\n4\n\n\n\nPage 15 of 19Parlar et al. Hum. Cent. Comput. Inf. Sci.  (2018) 8:10 \n\nproposed QER achieves best performances with feature sizes between 2000 and 3000. \nCHI2 and IG are strongly correlated and tend to work well with smaller feature sizes, \nwhile DFD also works reasonably well, but with bigger feature sizes. For differences, \nthe English review datasets usually have bigger vocabulary, resulting in relatively big-\nger feature sizes for feature selection. Moreover, SVM and LR can also perform well for \nsome English review datasets, while NBM looks like a dominant classifier for the Turk-\nish reviews. Finally, the performance results for the English reviews are generally higher \nthan those for the Turkish reviews, possibly related to the differences between the two \nlanguages in terms of vocabularies, writing styles, and the agglutinative property of the \nTurkish language. The limitation of QER is that it is only suitable for classifying two \nclasses since it is especially developed for sentiment analysis with the observation that \nsentiment-expressing words are usually more frequent across different reviews. The con-\ntribution of QER is that, as it is shown in the experimental results, the method is both \nlanguage and classifier independent and can select better features than other methods \nfor sentiment analysis.\n\nComparison of our proposal with the previous studies\n\nIt is generally difficult to directly compare the results of different studies since there are \noften differences in partitioning and preprocessing the datasets for training and testing, \nas shown in the studies by Pang et al. [4]. That is why we tried different combinations of \nfeature selection methods and text classifiers on multiple datasets in our research so that \n\nFig. 2 Detailed results of feature sizes for the English DVDs review dataset\n\nTable 5 Detailed results for the English DVD review dataset\n\nNBM SVM LR J48\n\nSize F measure Size F measure Size F measure Size F measure\n\nQER 2500 0.9169 3000 0.8724 2000 0.8977 2000 0.5481\n\nCHI2 1000 0.8964 500 0.8650 3000 0.6976 3000 0.6799\n\nIG 1000 0.8964 1000 0.8614 2000 0.6970 500 0.6769\n\nDFD 3000 0.8502 1000 0.8293 3000 0.7600 500 0.6771\n\nOCFS 1000 0.7996 1000 0.7714 500 0.6800 2000 0.6829\n\n\n\nPage 16 of 19Parlar et al. Hum. Cent. Comput. Inf. Sci.  (2018) 8:10 \n\nwe can compare their performance collectively and accurately. However, we do agree \nthat it is helpful to describe the results from the related studies so that we can put our \nresults into a suitable context. Table 6 includes a summary for comparison of our results \nwith that of the previous studies which have used the same datasets with our study. For \nthe English movie review dataset, Nicholls and Song [8] obtained a baseline accuracy \nof 79.9% with the MEM classifier, and better classification accuracies of 86.9, 85.7, and \n80.9% when combined with DFD, CHI2, and OCFS feature selection methods, respec-\ntively. Dang et al. [23] examined their proposed semantic oriented method on the prod-\nuct dataset [37]. They achieved an accuracy of 84.2% for the kitchen dataset. Also, Xia \net al. [24] improved the classification performances from 84.8 to 87.7% using their pro-\nposed word relation based feature selection method. Bai [25] improved the accuracies \nfrom baseline 84.1–92.7% using their proposed Tabu search-enhanced Markov blanket \nmodel for the movie review dataset. Pang et al. [4] obtained accuracy around 78.7% with \nNB using the document frequency of 4 to eliminate the rare features. Agarwal et al. [9] \nimproved the accuracies from baseline 82.7–89.2% using IG feature selection method \nwith Boolean NBM. Our proposed QER method showed an improvement from the \nbaseline of 81.3–91.1% with NBM in terms of F measures.\n\nFor the Turkish movie review dataset, the best classification result of 82.58% is \nobtained with the SVM classifier [30]. As shown in the previous studies, classification \naccuracy is improved by applying feature selection, and NB based classifier performs the \nbest in the majority of the cases. The proposed feature selection method is also com-\nputationally efficient and easy to implement as it only computes scores for features by \ncounting document frequencies.\n\nConclusions\nIn this paper, we proposed a new feature selection method query expansion ranking \n(QER) for the sentiment analysis and compared it with the common feature selection \nmethods for sentiment classification, including DFD and OCFS, CHI2 and IG. All of \nthese methods are tested against five datasets of Turkish reviews, using four common \n\nTable 6 Summary of related work on the sentiment analysis for the same datasets\n\nPaper Dataset Baseline accuracy (%) Best accuracies observed (%) Classifier\n\n[4] Movie 78.7 NB, SVM\n\n[7] Movie 87.1 minimum cut SVM\n\n[8] Movie\nProduct\n\n79.9\n74.3\n\n85.7 CHI2; 86.9 DFD; 80.9 OCFS\n73.7 CHI2; 75 DFD; 73.8 OCFS\n\nMEM\n\n[9] Movie\nProduct\n\n84.2\n80.9 Book; 78.9 DVD; 80.8 El\n\n91.8\n92.5 Book; 91.5 DVD; 91.8 El\nmRMR with composite features\n\nBNBM, SVM\n\n[23] Product 70.1 84.2% Kitc. semantic orientation SVM\n\n[24] Movie\nProduct\n\n84.8\n74.7 Book; 77.2 DVD; 80.8 El.; \n\n83.3 Kitc\n\n87.7\n81.8 Book; 83.8 DVD; 85.9 El.; 88.7 Kitc \n\nword relation based method\n\nNB, SVM, MEM\n\n[25] Movie 84.1 92.7% Tabu search-enhanced Markov \nblanket model\n\nNB, SVM, MEM\n\nOur study Movie\nProduct\n\n84.8\n76.2 Book; 78.4 DVD; 78.6 \n\nElect; 81.4 Kitc\n\n91.5 CHI2-IG; 87.1 DFD; 82.9 OCFS; \n95.5 91.6 Book; 91.7 DVD; 88.8 Elect; \n91.1 Kitc proposed QER\n\nNBM, SVM, MEM, DT\n\n\n\nPage 17 of 19Parlar et al. Hum. Cent. Comput. Inf. Sci.  (2018) 8:10 \n\ntext classifiers, including NBM, SVM, logistic regression (LR), and decision trees (J48). \nSimilar experiments are also conducted for English reviews so that we can compare \ntheir differences with the Turkish reviews. Our results show that for all Turkish review \ndatasets, the best results are all obtained with the NBM classifier, and for some Eng-\nlish review datasets, LR and SVM have the best performance. For feature selection, our \nproposed QER method helps to achieve the best performance compared with all other \nfeature selection methods for both Turkish and English reviews. For feature selection, \nour experiments show that our proposed QER method helps to achieve the best per-\nformance among all other feature selection methods. We found that CHI2 and IG have \nalmost the same performance for the Turkish reviews and they tend to work well with \nsmaller feature sizes compared with other feature selection methods. DFD does reason-\nably well across all review datasets, but it tends to favour bigger feature sizes. This con-\nfirms our intuition that sentiment-expressing words usually have low frequencies within \na document, but relatively high frequencies across different documents. Although OCFS \nis quite robust for traditional topical text classification, it does not do well for sentiment \nanalysis since it relies on word frequencies to measure the distances between docu-\nments. Once again, NBM remains the best performer for most of our experiments when \nanalysed with QER method. Overall, feature selection methods are shown to be effective \nfor sentiment analysis, improving significantly over the baseline results.\n\nFollowing a similar process, we also carried out experiments on English review data-\nsets and NBM seems to be the most suitable classifier for sentiment analysis. For fea-\nture selection methods, CHI2 and IG are strongly correlated and tend to work well with \nsmaller feature sizes, while DFD also works reasonably well, but with bigger feature \nsizes. Our proposed query expansion ranking method achieves the best performances \nfor the English datasets as well. As for differences, the English review datasets usually \nhave a bigger vocabulary, resulting in relatively bigger feature sizes for feature selection. \nMoreover, LR and SVM also perform well for some English review datasets, while NBM \nlooks like a dominant classifier for the Turkish reviews. The performance results for the \nEnglish reviews are generally higher than those for the Turkish reviews, possibly related \nto the differences between the two languages in terms of vocabularies, writing styles, \nand the agglutinative property of the Turkish language. Finally, the experimental results \nshow that our proposal QER method is language, domain and classifier independent \nand improve the classification performance better than other FS methods for sentiment \nanalysis.\nAuthors’ contributions\nTP drafted this manuscript, conducted experiments using the datasets and analyzed the results. SAO and FS suggested \nthe methods used in this study and provided guidelines in drafting the manuscript. FS edited and corrected the manu-\nscript. All authors read and approved the final manuscript.\n\nAuthors’ information\nTP received her Ph.D. degree in Computer Engineering from Çukurova University in 2016. She received a Bachelor of \nEngineering degree in Computer Engineering from Hacettepe University, and she holds a M.Sc. in Management Infor-\nmation Sciences and a M.Sc. in Mathematics. She studied for 4 months of 2015 as a visiting researcher in University of \nGuelph, Canada with a scholarship supporting by The Scientific and Technological Research Council of Turkey (TUBITAK). \nShe is currently working as a senior lecturer and head of the Computer Technologies Department, Antakya Vocational \nSchool, Mustafa Kemal University. Her research interest is in sentiment analysis, data mining, machine learning, and \napplying text processing techniques to medical data extraction and integration.\n\nSAO received her Ph.D. and Bachelor of Science degrees both in Computer Engineering from Bilkent University, \nTurkey, in 2004 and 1996, respectively. Currently she is a professor and head of the Department of Computer Engineer-\ning, Çukurova University, Turkey. Her research interests include text mining, information retrieval systems, and applying \nbiological and nature inspired computing to text mining.\n\n\n\nPage 18 of 19Parlar et al. Hum. Cent. Comput. Inf. Sci.  (2018) 8:10 \n\nFS received his Ph.D. degree in Computer Science from the University of Waterloo in Canada. He is currently an \nassociate professor in the School of Computer Science, University of Guelph in Canada. His interests are mostly in Natural \nLanguage Processing, working on a wide range of topic areas, including information retrieval, text classification, topic \nmodeling, key phrase extraction, text segmentation, sentiment analysis, text summarization, and document clustering. \nMore recently, he is also interested in applying text processing techniques to privacy policy analysis and medical data \nextraction and integration.\n\nAuthor details\n1 Department of Mathematics, Mustafa Kemal University, Antakya, Hatay, Turkey. 2 Department of Computer Engineering, \nÇukurova University, Adana, Turkey. 3 School of Computer Science, University of Guelph, Guelph, Canada. \n\nAcknowledgements\nThis research is supported by TUBITAK-2214-A.\n\nCompeting interests\nThe authors declare that they have no competing interests.\n\nAvailability of data and materials\nNot applicable.\n\nEthics approval and consent to participate\nNot applicable.\n\nFunding\nThis research is supported by Çukurova University Fund of Scientific Research Projects under Grant No. FDK-2015-3833, \nand Mustafa Kemal University Fund of Scientific Research Projects under Grant No. 15426.\n\nPublisher’s Note\nSpringer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.\n\nReceived: 10 February 2018   Accepted: 16 April 2018\n\nReferences\n 1. Pang B, Lee L (2008) Opinion mining and sentiment analysis. Found Trends Inf Retr 2:1–135. https://doi.\n\norg/10.1561/1500000011\n 2. Tripathy A, Anand A, Rath SK (2017) Document-level sentiment classification using hybrid machine learning \n\napproach. Knowl Inf Syst 53:805–831. https://doi.org/10.1007/s10115-017-1055-z\n 3. Yang D-H, Yu G (2013) A method of feature selection and sentiment similarity for Chinese micro-blogs. J Inf Sci \n\n39:429–441. https://doi.org/10.1177/0165551513480308\n 4. Pang B, Lee L, Vaithyanathan S (2002) Thumbs up? In: Proceedings of the ACL-02 conference on empirical methods \n\nin natural language processing—EMNLP’02. Association for computational linguistics, Morristown, pp 79–86\n 5. Mullen T, Collier N (2004) Sentiment analysis using support vector machines with diverse information sources. Conf \n\nEmpir Methods Nat Lang Process. https://doi.org/10.3115/1219044.1219069\n 6. Kaya M, Fidan G, Toroslu IH (2012) Sentiment analysis of Turkish political news. In: 2012 IEEE/WIC/ACM international \n\nconferences on web intelligence and intelligent agent technology. IEEE, Macau, pp 174–180\n 7. Pang B, Lee L (2004) A sentimental education. In: Proceedings of the 42nd annual meeting on association for com-\n\nputational linguistics—ACL’04. Association for Computational Linguistics, Morristown, p 271–es\n 8. Nicholls C, Song F (2010) Comparison of feature selection methods for sentiment analysis. In: Advances in artificial \n\nintelligence. Springer, Berlin, pp 286–289\n 9. Agarwal B, Mittal N (2016) Prominent feature extraction for review analysis: an empirical study. J Exp Theor Artif Intell \n\n28:485–498. https://doi.org/10.1080/0952813X.2014.977830\n 10. Parlar T, Ozel SA (2016) A new feature selection method for sentiment analysis of Turkish reviews. In: International \n\nSymposium on INnovations in Intelligent SysTems and Applications (INISTA). IEEE, Sinaia, pp 1–6\n 11. Fattah MA (2017) A novel statistical feature selection approach for text categorization. J Inf Process Syst 13:1397–\n\n1409. https://doi.org/10.3745/JIPS.02.0076\n 12. Harman D (1992) Relevance feedback revisited. In: Proceedings of the 15th annual international ACM SIGIR confer-\n\nence on Research and development in information retrieval—SIGIR’92. ACM Press, New York, pp 1–10\n 13. Robertson SE, Jones KS (1976) Relevance weighting of search terms. J Am Soc Inf Sci 27:129–146. https://doi.\n\norg/10.1002/asi.4630270302\n 14. Aldoğan D, Yaslan Y (2017) A comparison study on active learning integrated ensemble approaches in sentiment \n\nanalysis. Comput Electr Eng 57:311–323. https://doi.org/10.1016/J.COMPELECENG.2016.11.015\n 15. Singh J, Singh G, Singh R (2017) Optimization of sentiment analysis using machine learning classifiers. Hum centric \n\nComput Inf Sci 7:32. https://doi.org/10.1186/s13673-017-0116-3\n 16. Mladenović M, Mitrović J, Krstev C, Vitas D (2016) Hybrid sentiment analysis framework for a morphologically rich \n\nlanguage. J Intell Inf Syst 46:599–620. https://doi.org/10.1007/s10844-015-0372-5\n 17. Asgarian E, Kahani M, Sharifi S (2018) The impact of sentiment features on the sentiment polarity classification in \n\nPersian reviews. Cognit Comput 10:117–135. https://doi.org/10.1007/s12559-017-9513-1\n\nhttps://doi.org/10.1561/1500000011\nhttps://doi.org/10.1561/1500000011\nhttps://doi.org/10.1007/s10115-017-1055-z\nhttps://doi.org/10.1177/0165551513480308\nhttps://doi.org/10.3115/1219044.1219069\nhttps://doi.org/10.1080/0952813X.2014.977830\nhttps://doi.org/10.3745/JIPS.02.0076\nhttps://doi.org/10.1002/asi.4630270302\nhttps://doi.org/10.1002/asi.4630270302\nhttps://doi.org/10.1016/J.COMPELECENG.2016.11.015\nhttps://doi.org/10.1186/s13673-017-0116-3\nhttps://doi.org/10.1007/s10844-015-0372-5\nhttps://doi.org/10.1007/s12559-017-9513-1\n\n\nPage 19 of 19Parlar et al. Hum. Cent. Comput. Inf. Sci.  (2018) 8:10 \n\n 18. Guyon I, Elisseeff A (2003) An introduction to variable and feature selection. J Mach Learn Res 3:1157–1182. https://\ndoi.org/10.1016/j.aca.2011.07.027\n\n 19. Akba F, Uçan A, Sezer E, Sever H (2014) Assessment of feature selection metrics for sentiment analyses: Turkish \nmovie reviews. In: 8th European conference on data mining. Lisbon, Portugal, pp 180–184\n\n 20. Liu Y, Bi JW, Fan ZP (2017) Multi-class sentiment classification: the experimental comparisons of feature selection \nand machine learning algorithms. Expert Syst Appl 80:323–339. https://doi.org/10.1016/j.eswa.2017.03.042\n\n 21. Sagar K, Saha A (2017) Qualitative usability feature selection with ranking: a novel approach for ranking the identi-\nfied usability problematic attributes for academic websites using data-mining techniques. Hum centric Comput Inf \nSci 7:29. https://doi.org/10.1186/s13673-017-0111-8\n\n 22. Abbasi A, Chen H, Salem A (2008) Sentiment analysis in multiple languages: Feature selection for opinion classifica-\ntion in Web forums. ACM Trans Inf Syst 26:1–34. https://doi.org/10.1145/1361684.1361685\n\n 23. Dang Y, Zhang Y, Chen H (2010) A Lexicon-enhanced method for sentiment classification: an experiment on online \nproduct reviews. IEEE Intell Syst 25:46–53. https://doi.org/10.1109/MIS.2009.105\n\n 24. Xia R, Zong C, Li S (2011) Ensemble of feature sets and classification algorithms for sentiment classification. Inf Sci \n(Ny) 181:1138–1152. https://doi.org/10.1016/j.ins.2010.11.023\n\n 25. Bai X (2011) Predicting consumer sentiments from online text. Decis Support Syst 50:732–742. https://doi.\norg/10.1016/j.dss.2010.08.024\n\n 26. Yan J, Liu N, Zhang B, et al (2005) OCFS: optimal orthogonal centroid feature selection for text categorization. In: \nProceedings of the 28th annual international ACM SIGIR conference on Research and development in information \nretrieval—SIGIR’05. ACM Press, New York, p 122\n\n 27. Zheng L, Wang H, Gao S (2018) Sentimental feature selection for sentiment analysis of Chinese online reviews. Int J \nMach Learn Cybern 9:75–84. https://doi.org/10.1007/s13042-015-0347-4\n\n 28. Demirtas E, Pechenizkiy M (2013) Cross-lingual polarity detection with machine translation. In: Second international \nworkshop on issues of sentiment discovery and opinion mining—WISDOM’13. ACM Press, New York, pp 1–8\n\n 29. Boynukalin Z (2012) Emotion analysis of Turkish texts by using machine learning methods. M.Sc. Thesis, Middle East \nTechnical University\n\n 30. Sevindi BI (2013) Türkçe Metinlerde Denetimli ve Sözlük Tabanlı Duygu Analizi Yaklaşımlarının Karşılaştırılması. M.Sc. \nThesis, Gazi University\n\n 31. Parlar T, Özel SA, Song F (2018) Interactions between term weighting and feature selection methods on the senti-\nment analysis of Turkish reviews. In: Computational linguistics and intelligent text processing. CICLing 2016. Lecture \nNotes in computer Science, vol 9624. Springer, Cham, pp 335–346\n\n 32. Çakici R (2009) Wide-coverage parsing for Turkish. Ph.D. Thesis, University of Edinburgh\n 33. Witten IH, Frank E, Hall MA (2011) Data mining: practical machine learning tools and techniques. Morgan Kaufmann, \n\nBurlington\n 34. McCallum A, Nigam K (1998) A comparison of event models for naive Bayes text classification. In: AAAI/ICML-98 \n\nworkshop on learning for text categorization. pp 41–48\n 35. Zhao X, Li D, Yang B et al (2015) A two-stage feature selection method with its application. Comput Electr Eng \n\n47:114–125. https://doi.org/10.1016/J.COMPELECENG.2015.08.011\n 36. Harman D (1988) Towards interactive query expansion. In: Proceedings of the 11th annual international ACM SIGIR \n\nconference on Research and development in information retrieval—SIGIR’88. ACM Press, New York, pp 321–331\n 37. Blitzer J, Dredze M, Pereira F (2007) Biographies, bollywood, boom-boxes and blenders: domain adaptation for senti-\n\nment classification. In: 45th annual meeting-association for computational linguistics. pp 440–447\n 38. Bird S, Klein E, Loper E (2009) Natural language processing with Python. O’Reilly, Newton\n 39. Cai J, Song F (2008) Maximum entropy modeling with feature selection for text categorization. In: Lecture notes in \n\ncomputer science (including subseries lecture notes in artificial intelligence and lecture notes in bioinformatics). pp \n549–554\n\n 40. Joachims T (1998) Text categorization with support vector machines: learning with many relevant features. Springer, \nBerlin, pp 137–142\n\nhttps://doi.org/10.1016/j.aca.2011.07.027\nhttps://doi.org/10.1016/j.aca.2011.07.027\nhttps://doi.org/10.1016/j.eswa.2017.03.042\nhttps://doi.org/10.1186/s13673-017-0111-8\nhttps://doi.org/10.1145/1361684.1361685\nhttps://doi.org/10.1109/MIS.2009.105\nhttps://doi.org/10.1016/j.ins.2010.11.023\nhttps://doi.org/10.1016/j.dss.2010.08.024\nhttps://doi.org/10.1016/j.dss.2010.08.024\nhttps://doi.org/10.1007/s13042-015-0347-4\nhttps://doi.org/10.1016/J.COMPELECENG.2015.08.011\n\n\tQER: a new feature selection method for sentiment analysis\n\tAbstract \n\tIntroduction\n\tRelated work\n\tMethods\n\tMachine learning algorithms\n\tFeature selection\n\tInformation gain\n\tChi square (CHI2)\n\tDocument frequency difference\n\tOptimal orthogonal centroid (OCFS)\n\tQuery expansion ranking\n\n\n\tExperiments and results\n\tDatasets\n\tPerformance evaluation\n\tExperimental settings\n\tPerformance of feature selection methods for Turkish reviews\n\tPerformance of feature selection methods for English reviews\n\tComparison of our proposal with the previous studies\n\n\tConclusions\n\tAuthors’ contributions\n\tReferences\n\n\n\n\n",
      "metadata_storage_path": "aHR0cHM6Ly9jb3Jwb3JhdGV0cmFpbmluZ3N0b3JhZ2UuYmxvYi5jb3JlLndpbmRvd3MubmV0L3BhcGVycy9zMTM2NzMtMDE4LTAxMzUtOC5wZGY1",
      "metadata_author": "Tuba Parlar ",
      "metadata_title": "QER: a new feature selection method for sentiment analysis",
      "metadata_creation_date": "2018-04-18T08:33:56Z",
      "keyphrases": [
        "new feature selection method",
        "sentiment analysis",
        "QER"
      ]
    },
    {
      "@search.score": 0.17716676,
      "content": "\nDetecting problematic transactions \nin a consumer‑to‑consumer e‑commerce \nnetwork\nShun Kodate1,2, Ryusuke Chiba3, Shunya Kimura3 and Naoki Masuda2,4,5* \n\nIntroduction\nIn tandem with the rapid growth of online and electronic transactions and communi-\ncations, fraud is expanding at a dramatic speed and penetrates our daily lives. Fraud \nincluding cybercrimes costs billions of dollars per year and threatens the security of our \nsociety (UK Parliament 2017; McAfee 2019). In particular, in the recent era where online \nactivity dominates, attacking a system is not too costly, whereas defending the system \nagainst fraud is costly (Anderson et al. 2013). The dimension of fraud is vast and ranges \nfrom credit card fraud, money laundering, computer intrusion, to plagiarism, to name a \nfew.\n\nAbstract \n\nProviders of online marketplaces are constantly combatting against problematic \ntransactions, such as selling illegal items and posting fictive items, exercised by some \nof their users. A typical approach to detect fraud activity has been to analyze registered \nuser profiles, user’s behavior, and texts attached to individual transactions and the user. \nHowever, this traditional approach may be limited because malicious users can easily \nconceal their information. Given this background, network indices have been exploited \nfor detecting frauds in various online transaction platforms. In the present study, we \nanalyzed networks of users of an online consumer-to-consumer marketplace in which \na seller and the corresponding buyer of a transaction are connected by a directed \nedge. We constructed egocentric networks of each of several hundreds of fraudulent \nusers and those of a similar number of normal users. We calculated eight local network \nindices based on up to connectivity between the neighbors of the focal node. Based \non the present descriptive analysis of these network indices, we fed twelve features \nthat we constructed from the eight network indices to random forest classifiers with \nthe aim of distinguishing between normal users and fraudulent users engaged in each \none of the four types of problematic transactions. We found that the classifier accu-\nrately distinguished the fraudulent users from normal users and that the classification \nperformance did not depend on the type of problematic transaction.\n\nKeywords: Network analysis, Machine learning, Fraud detection, Computational social \nscience\n\nOpen Access\n\n© The Author(s) 2020. Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits \nuse, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original \nauthor(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third \nparty material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the mate-\nrial. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or \nexceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://\ncreat iveco mmons .org/licen ses/by/4.0/.\n\nRESEARCH\n\nKodate et al. Appl Netw Sci            (2020) 5:90  \nhttps://doi.org/10.1007/s41109‑020‑00330‑x Applied Network Science\n\n*Correspondence:   \nnaokimas@buffalo.edu \n4 Department \nof Mathematics, University \nat Buffalo, Buffalo, NY \n14260-2900, USA\nFull list of author information \nis available at the end of the \narticle\n\nhttp://orcid.org/0000-0003-1567-801X\nhttp://creativecommons.org/licenses/by/4.0/\nhttp://creativecommons.org/licenses/by/4.0/\nhttp://crossmark.crossref.org/dialog/?doi=10.1007/s41109-020-00330-x&domain=pdf\n\n\nPage 2 of 18Kodate et al. Appl Netw Sci            (2020) 5:90 \n\nComputational and statistical methods for detecting and preventing fraud have been \ndeveloped and implemented for decades (Bolton and Hand 2002; Phua et  al. 2010; \nAbdallah et al. 2016; West and Bhattacharya 2016). Standard practice for fraud detec-\ntion is to employ statistical methods including the case of machine learning algorithms. \nIn particular, when both fraudulent and non-fraudulent samples are available, one can \nconstruct a classifier via supervised learning (Bolton and Hand 2002; Phua et al. 2010; \nAbdallah et al. 2016; West and Bhattacharya 2016). Exemplar features to be fed to such a \nstatistical classifier include the transaction amount, day of the week, item category, and \nuser’s address for detecting frauds in credit card systems, number of calls, call duration, \ncall type, and user’s age, gender, and geographical region in the case of telecommunica-\ntion, and user profiles and transaction history in the case of online auctions (Abdallah \net al. 2016).\n\nHowever, many of these features can be easily faked by advanced fraudsters (Akoglu \net al. 2015; Google LLC 2018). Furthermore, fraudulent users are adept at escaping the \neyes of the administrators or authorities that would detect the usage of particular words \nas a signature of anomalous behavior (Pu and Webb 2006; Hayes 2007; Bhowmick and \nHazarika 2016). For example, if the authority discovers that one jargon means a drug, \nthen fraudulent users may easily switch to another jargon to confuse the authority.\n\nNetwork analysis is an alternative way to construct features and is not new to fraud \ndetection techniques (Savage et al. 2014; Akoglu et al. 2015). The idea is to use connec-\ntivity between nodes, which are usually users or goods, in the given data and calculate \ngraph-theoretic quantities or scores that characterize nodes. These methods stand on \nthe expectation that anomalous users show connectivity patterns that are distinct from \nthose of normal users (Akoglu et al. 2015). Network analysis has been deployed for fraud \ndetection in insurance (Šubelj et  al. 2011), money laundering (Dreżewski et  al. 2015; \nColladon and Remondi 2017; Savage et al. 2017), health-care data (Liu et al. 2016), car-\nbooking (Shchur et al. 2018), a social security system (Van Vlasselaer et al. 2016), mobile \nadvertising (Hu et al. 2017), a mobile phone network (Ferrara et al. 2014), online social \nnetworks (Bhat and Abulaish 2013; Jiang et  al. 2014; Hooi et  al. 2016; Rasheed et  al. \n2018), online review forums (Akoglu et al. 2013; Liu et al. 2017; Wang et al. 2018), online \nauction or marketplaces (Chau et  al. 2006; Pandit et  al. 2007; Wang and Chiu 2008; \nBangcharoensap et  al. 2015; Yanchun et  al. 2011), credit card transactions (Van Vlas-\nselaer et al. 2015; Li et al. 2017), cryptocurrency transaction (Monamo et al. 2016), and \nvarious other fields (Akoglu et al. 2010). For example, fraudulent users and their accom-\nplices were shown to form approximately bipartite cores in a network of users to inflate \ntheir reputations in an online auction system (Chau et al. 2006). Then, the authors pro-\nposed an algorithm based on a belief propagation to detect such suspicious connectivity \npatterns. This method has been proven to be also effective on empirical data obtained \nfrom eBay (Pandit et al. 2007).\n\nIn the present study, we analyze a data set obtained from a large online consumer-to-\nconsumer (C2C) marketplace, Mercari, operating in Japan and the US. They are the larg-\nest C2C marketplace in Japan, in which, as of 2019, there are 13 million monthly active \nusers and 133 billion yen (approximately 1.2 billion USD) transactions per quarter year \n(Mercari 2019). Note that we analyze transaction frauds based on transaction networks \nof users, which contrasts with previous studies of online C2C marketplaces that looked \n\n\n\nPage 3 of 18Kodate et al. Appl Netw Sci            (2020) 5:90  \n\nat reputation frauds (Chau et al. 2006; Pandit et al. 2007; Wang and Chiu 2008; Yanchun \net  al. 2011). Many prior network-based fraud detection algorithms used global infor-\nmation about networks, such as connected components, communities, betweenness, \nk-cores, and that determined by belief propagation (Chau et al. 2006; Pandit et al. 2007; \nWang and Chiu 2008; Šubelj et  al. 2011; Akoglu et  al. 2013; Bhat and Abulaish 2013; \nFerrara et al. 2014; Jiang et al. 2014; Bangcharoensap et al. 2015; Dreżewski et al. 2015; \nVan Vlasselaer et al. 2015; Hooi et al. 2016; Liu et al. 2016; Van Vlasselaer et al. 2016; \nColladon and Remondi 2017; Hu et al. 2017; Li et al. 2017; Liu et al. 2017; Savage et al. \n2017; Shchur et al. 2018; Rasheed et al. 2018; Wang et al. 2018). Others used local infor-\nmation about the users’ network, such as the degree, the number of triangles, and the \nlocal clustering coefficient (Chau et al. 2006; Akoglu et al. 2010; Šubelj et al. 2011; Yan-\nchun et al. 2011; Bhat and Abulaish 2013; Bangcharoensap et al. 2015; Dreżewski et al. \n2015; Monamo et al. 2016; Van Vlasselaer et al. 2016; Colladon and Remondi 2017). We \nwill focus on local features of users, i.e., features of a node that can be calculated from \nthe connectivity of the user and the connectivity between neighbors of the user. This is \nbecause local features are easier and faster to calculate and thus practical for commercial \nimplementations.\n\nMaterials and methods\nData\n\nMercari is an online C2C marketplace service, where users trade various items among \nthemselves. The service is operating in Japan and the United States. In the present study, \nwe used the data obtained from the Japanese market between July 2013 and January \n2019. In addition to normal transactions, we focused on the following types of prob-\nlematic transactions: fictive, underwear, medicine, and weapon. Fictive transactions are \ndefined as selling non-existing items. Underwear refers to transactions of used under-\nwear; they are prohibited by the service from the perspective of morality and hygiene. \nMedicine refers to transactions of medicinal supplies, which are prohibited by the law. \nWeapon refers to transactions of weapons, which are prohibited by the service because \nthey may lead to crime. The number of sampled users of each type is shown in Table 1.\n\nNetwork analysis\n\nWe examine a directed and weighted network of users in which a user corresponds to a \nnode and a transaction between two users represents a directed edge. The weight of the \nedge is equal to the number of transactions between the seller and the buyer. We con-\nstructed egocentric networks of each of several hundreds of normal users and those of \nfraudulent users, i.e., those engaged in at least one problematic sell. Figure 1 shows the \negocentric networks of two normal users (Fig. 1a, b) and those of two fraudulent users \ninvolved in selling a fictive item (Fig. 1c, d). The egocentric network of either a normal or \nfraudulent user contained the nodes neighboring the focal user, edges between the focal \nuser and these neighbors, and edges between the pairs of these neighbors.\n\nWe calculated eight indices for each focal node. They are local indices in the mean-\ning that they require the information up to the connectivity among the neighbors of the \nfocal node.\n\n\n\nPage 4 of 18Kodate et al. Appl Netw Sci            (2020) 5:90 \n\nFive out of the eight indices use only the information about the connectivity of the focal \nnode. The degree ki of node vi is the number of its neighbors. The node strength  (Barrat \net al. 2004) (i.e., weighted degree) of node vi , denoted by si , is the number of transactions in \nwhich vi is involved. Using these two indices, we also considered the mean number of trans-\nactions per neighbor, i.e., si/ki , as a separate index. These three indices do not use informa-\ntion about the direction of edges.\n\nThe sell probability of node vi , denoted by SPi , uses the information about the direction of \nedges and defined as the proportion of the vi ’s neighbors for which vi acts as seller. Precisely, \nthe sell probability is given by\n\n(1)SPi =\nkouti\n\nk ini + kouti\n\n,\n\nFig. 1 Examples of egocentric networks. a, b Egocentric networks of arbitrarily selected two normal users. c, \nd Egocentric networks of arbitrarily selected two fraudulent users involved in selling a fictive item\n\n\n\nPage 5 of 18Kodate et al. Appl Netw Sci            (2020) 5:90  \n\nwhere k ini  is vi ’s in-degree (i.e., the number of neighbors from whom vi bought at least \none item) and kouti  is vi ’s out-degree (i.e., the number of neighbors to whom vi sold at \nleast one item). It should be noted that, if vi acted as both seller and buyer towards vj , the \ncontribution of vj to both in- and out-degree of vi is equal to one. Therefore, k ini + kouti  is \nnot equal to ki in general.\n\nThe weighted version of the sell probability, denoted by WSPi , is defined as\n\nwhere sini  is node vi ’s weighted in-degree (i.e., the number of buys) and souti  is vi ’s weighted \nout-degree (i.e., the number of sells).\n\nThe other three indices are based on triangles that involve the focal node. The local \nclustering coefficient Ci quantifies the abundance of undirected and unweighted triangles \naround vi (Newman 2010). It is defined as the number of undirected and unweighted trian-\ngles including vi divided by ki(ki − 1)/2 . The local clustering coefficient Ci ranges between \n0 and 1.\n\nWe hypothesized that triangles contributing to an increase in the local clustering coef-\nficient are localized around particular neighbors of node vi . Such neighbors together with vi \nmay form an overlapping set of triangles, which may be regarded as a community (Radicchi \net al. 2004; Palla et al. 2005). Therefore, our hypothesis implies that the extent to which the \nfocal node is involved in communities should be different between normal and fraudulent \nusers. To quantify this concept, we introduce the so-called triangle congregation, denoted \nby mi . It is defined as the extent to which two triangles involving vi share another node and \nis given by\n\nwhere Tri = Ciki(ki − 1)/2 is the number of triangles involving vi . Note that mi ranges \nbetween 0 and 1.\n\nFrequencies of different directed three-node subnetworks, conventionally known as net-\nwork motifs (Milo et al. 2002), may distinguish between normal and fraudulent users. In \nparticular, among triangles composed of directed edges, we hypothesized that feedforward \ntriangles (Fig. 2a) should be natural and that cyclic triangles (Fig. 2b) are not. We hypoth-\nesized so because a natural interpretation of a feedforward triangle is that a node with out-\ndegree two tends to serve as seller while that with out-degree zero tends to serve as buyer \nand there are many such nodes that use the marketplace mostly as buyer or seller but not \nboth. In contrast, an abundance of cyclic triangles may imply that relatively many users use \nthe marketplace as both buyer and seller. We used the index called the cycle probability, \ndenoted by CYPi , which is defined by\n\nwhere FFi and CYi are the numbers of feedforward triangles and cyclic triangles to which \nnode vi belongs. The definition of FFi and CYi , and hence CYPi , is valid even when the \n\n(2)WSPi =\nsouti\n\nsini + souti\n\n,\n\n(3)mi =\n(Number of pairs of triangles involving vi that share another node)\n\nTri(Tri − 1)/2\n,\n\n(4)CYPi =\nCYi\n\nFFi + CYi\n,\n\n\n\nPage 6 of 18Kodate et al. Appl Netw Sci            (2020) 5:90 \n\ntriangles involving vi have bidirectional edges. In the case of Fig. 2c, for example, any of \nthe three nodes contains one feedforward triangle and one cyclic triangle. The other four \ncases in which bidirectional edges are involved in triangles are shown in Fig. 2d–g. In the \ncalculation of CYPi , we ignored the weights of edges.\n\nRandom forest classifier\n\nTo classify users into normal and fraudulent users based on their local network proper-\nties, we employed a random forest classifier (Breiman 2001; Breiman et al. 1984; Hastie \net  al. 2009) implemented in scikit-learn (Pedregosa et  al. 2011). It uses an ensemble \nlearning method that combines multiple classifiers, each of which is a decision tree, \nbuilt from training data and classifies test data avoiding overfitting. We combined 300 \ndecision-tree classifiers to construct a random forest classifier. Each decision tree is con-\nstructed on the basis of training samples that are randomly subsampled with replace-\nment from the set of all the training samples. To compute the best split of each node \nin a tree, one randomly samples the candidate features from the set of all the features. \nThe probability that a test sample is positive in a tree is estimated as follows. Consider \nthe terminal node in the tree that a test sample eventually reaches. The fraction of posi-\ntive training samples at the terminal node gives the probability that the test sample is \nclassified as positive. One minus the positive probability gives the negative probability \nestimated for the same test sample. The positive or negative probability for the random \nforest classifier is obtained as the average of single-tree positive or negative probability \nover all the 300 trees. A sample is classified as positive by the random forest classifier if \nthe positive probability is larger than 0.5, otherwise classified as negative.\n\nWe split samples of each type into two sets such that 75% and 25% of the samples of \neach type are assigned to the training and test samples, respectively. There were more \n\ncyclicfeedforward feedforward: 1\ncyclic: 1\n\nfeedforward: 2\ncyclic: 0\n\nfeedforward: 3\ncyclic: 1\n\nfeedforward: 6\ncyclic: 2\n\na b c d\n\nf g\n\nfeedforward: 2\ncyclic: 0\n\ne\n\nFig. 2 Directed triangle patterns and their count. a Feedforward triangle. b Cyclic triangle. c– g Five \nthree-node patterns that contain directed triangles and reciprocal edges. The numbers shown in the figure \nrepresent the number of feedforward or cyclic triangles to which each three-node pattern contributes\n\n\n\nPage 7 of 18Kodate et al. Appl Netw Sci            (2020) 5:90  \n\nnormal users than any type of fraudulent user. Therefore, to balance the number of \nthe negative (i.e., normal) and positive (i.e., fraudulent) samples, we uniformly ran-\ndomly subsampled the negative samples (i.e., under-sampling) such that the number \nof the samples is the same between the normal and fraudulent types in the training \nset. Based on the training sample constructed in this manner, we built each of the 300 \ndecision trees and hence a random forest classifier. Then, we examined the classifica-\ntion performance of the random forest classifier on the set of test samples.\n\nThe true positive rate, also called the recall, is defined as the proportion of the posi-\ntive samples (i.e., fraudulent users) that the random forest classifier correctly classifies \nas positive. The false positive rate is defined as the proportion of the negative samples \n(i.e., normal users) that are incorrectly classified as positive. The precision is defined \nas the proportion of the truly positive samples among those that are classified as posi-\ntive. The true positive rate, false positive rate, and precision range between 0 and 1.\n\nWe used the following two performance measures for the random forest classifier. \nTo draw the receiver operating characteristic (ROC) curve for a random forest clas-\nsifier, one first arranges the test samples in descending order of the estimated prob-\nability that they are positive. Then, one plots each test sample, with its false positive \nrate on the horizontal axis and the true positive rate on the vertical axis. By connect-\ning the test samples in a piecewise linear manner, one obtains the ROC curve. The \nprecision–recall (PR) curve is generated by plotting the samples in the same order in \n[0, 1]2 , with the recall on the horizontal axis and the precision on the vertical axis. For \nan accurate binary classifier, both ROC and PR curves visit near (x, y) = (0, 1) . There-\nfore, we quantify the performance of the classifier by the area under the curve (AUC) \nof each curve. The AUC ranges between 0 and 1, and a large value indicates a good \nperformance of the random forest classifier.\n\nTo calculate the importance of each feature in the random forest classifier, we \nused the permutation importance (Strobl et al. 2007; Altmann et al. 2010). With this \nmethod, the importance of a feature is given by the decrease in the performance of \nthe trained classifier when the feature is randomly permuted among the test samples. \nA large value indicates that the feature considerably contributes to the performance \nof the classifier. To calculate the permutation importance, we used the AUC value of \nthe ROC curve as the performance measure of a random forest classifier. We com-\nputed the permutation importance of each feature with ten different permutations \nand adopted the average over the ten permutations as the importance of the feature.\n\nWe optimized the parameters of the random forest classifier by a grid search with \n10-fold cross-validation on the training set. For the maximum depth of each tree (i.e., \nthe max_depth parameter in scikit-learn), we explored the integers between 3 and 10. \nFor the number of candidate features for each split (i.e., max_features), we explored \nthe integers between 3 and 6. For the minimum number of samples required at termi-\nnal nodes (i.e., min_samples_leaf ), we explored 1, 3, and 5. As mentioned above, the \nnumber of trees (i.e., n_estimators) was set to 300. The seed number for the random \nnumber generator (i.e., random_state) was set to 0. For the other hyperparameters, \nwe used the default values in scikit-learn version 0.22. In the parameter optimization, \nwe evaluated the performance of the random forest classifier with the AUC value of \nthe ROC curve measured on a single set of training and test samples.\n\n\n\nPage 8 of 18Kodate et al. Appl Netw Sci            (2020) 5:90 \n\nTo avoid sampling bias, we built 100 random forest classifiers, trained each classifier, \nand tested its performance on a randomly drawn set of train and test samples, whose \nsampling scheme was described above.\n\nResults\nDescriptive statistics\n\nThe survival probability of the degree (i.e., a fraction of nodes whose degree is larger \nthan a specified value) is shown in Fig. 3a for each user type. Approximately 60% of the \nnormal users have degree ki = 1 , whereas the fraction of the users with ki = 1 is approxi-\nmately equal to 2% or less for any type of fraudulent user (Table 1). Therefore, we expect \nthat whether ki = 1 or ki ≥ 2 gives useful information for distinguishing between normal \nand fraudulent users. The degree distribution at ki ≥ 2 may provide further information \nuseful for the classification. The survival probability of the degree distribution condi-\ntioned on ki ≥ 2 for the different types of users is shown in Fig. 3b. The figure suggests \nthat the degree distribution is systematically different between the normal and fraudu-\nlent users. However, we consider that the difference is not as clear-cut as that in the frac-\ntion of users having ki = 1 (Table 1).\n\nThe survival probability of the node strength (i.e., weighted degree) is shown in Fig. 3c \nfor each user type. As in the case for the unweighted degree, we found that many nor-\nmal users, but not fraudulent users, have si = 1 . In fact, the number of the normal users \nwith si = 1 is equal to those with ki = 1 (Table 1), implying that all normal users with \nki = 1 participated in just one transaction. In contrast, no user had si = 1 for any type \nof fraudulent user. The survival probability of the node strength conditioned on si ≥ 2 \napparently does not show a clear distinction between the normal and fraudulent users \n(Fig. 3d, Table 1).\n\na b\n\nc d\n\nFig. 3 Survival probability of the degree for each user type. a Degree (i.e., ki ) for all nodes. b Degree for the \nnodes with ki ≥ 2 . c Strength (i.e., si ) for all nodes. d Strength for the nodes with si ≥ 2\n\n\n\nPage 9 of 18Kodate et al. Appl Netw Sci            (2020) 5:90  \n\nThe distribution of the average number of transactions per edge, i.e., si/ki , is shown \nin Fig. 4a. We found that a majority of normal users have si/ki = 1 . This result indicates \nthat a large fraction of normal users is engaged in just one transaction per neighbor \n(Table 1). This result is consistent with the fact that approximately 60% of the normal \nusers have ki = si = 1 . In contrast, many of any type of fraudulent users have si/ki > 1 . \nHowever, they tend to have a smaller value of si/ki than the normal users. This differ-\nence is more noticeable when we discraded the users with si/ki = 1 (Fig. 4b, Table 1). \nTherefore, less frequent transactions with a specific neighbor seem to be a characteristic \nbehavior of fraudulent users.\n\nThe distribution of the unweighted sell probability for the different user types is \nshown in Fig.  5a. The distribution for the normal users is peaked around 0 and 1, \n\nTable 1 Properties of different types of users\n\nIn the first column, Mean ( A | B ), for example, represents the mean of A conditioned on B. Unless the first column mentions \nthe conditional mean, median, or the number of transactions, the numbers reported in the table represent the number of \nusers\n\nSeed user type Normal Fictive Underwear Medicine Weapon\n\nNumber of seed users 999 440 468 469 416\n\nNumber of transactions \ninvolving the seed user\n\n151,021 66,215 151,278 92,497 81,970\n\nTotal number of transactions 27,683,860 850,739 2,325,898 925,361 533,963\n\nki = 1 587 (58.8%) 8 (1.8%) 3 (0.6%) 2 (0.4%) 5 (1.2%)\n\nMean ( ki | ki ≥ 2) 195.0 138.3 297.8 184.2 179.7\n\nMedian ( ki | ki ≥ 2) 77.5 61.0 170.0 97.0 86.0\n\nsi = 1 587 (58.8%) 8 (1.8%) 3 (0.6%) 2 (0.4%) 5 (1.2%)\n\nMean ( si | si ≥ 2) 365.1 153.3 325.3 198.1 199.4\n\nMedian ( si | si ≥ 2) 89.0 66.5 175.0 100.0 90.0\n\nsi ≥ 2 412 432 465 467 411\n\nsi/ki = 1 97 (23.5%) 97 (22.5%) 86 (18.5%) 156 (33.4%) 121 (29.4%)\n\nMean ( si/ki | si/ki > 1) 1.413 1.135 1.055 1.066 1.092\n\nMedian ( si/ki | si/ki > 1) 1.124 1.059 1.03 1.031 1.055\n\nki ≥ 2 412 432 465 467 411\n\nSPi = 1 157 (38.1%) 15 (3.5%) 21 (4.5%) 16 (3.4%) 17 (4.1%)\n\nk\nout\ni\n\n= 1 118 (28.6%) 21 (4.9%) 2 (0.4%) 2 (0.4%) 9 (2.2%)\n\nsi ≥ 2 412 432 465 467 411\n\nWSPi = 1 157 (38.1%) 15 (3.5%) 21 (4.5%) 16 (3.4%) 17 (4.1%)\n\ns\nout\ni\n\n= 1 118 (28.6%) 14 (3.2%) 2 (0.4%) 2 (0.4%) 9 (2.2%)\n\nki ≥ 2 412 432 465 467 411\n\nCi = 0 118 (28.6%) 152 (35.2%) 108 (23.2%) 154 (33.0%) 128 (31.1%)\n\nMean ( Ci | Ci > 0) 8.554× 10\n−3\n\n8.348× 10\n−3 9.500× 10\n\n−4\n2.231× 10\n\n−3\n3.810× 10\n\n−3\n\nMedian ( Ci | Ci > 0) 2.411× 10\n−3\n\n2.039× 10\n−3 5.288× 10\n\n−4\n6.494× 10\n\n−4\n1.337× 10\n\n−3\n\nTri ≥ 2 262 241 317 251 244\n\nmi = 0 17 (6.5%) 27 (11.2%) 54 (17.0%) 44 (17.5%) 32 (13.1%)\n\nmi = 1 12 (4.6%) 9 (3.7%) 4 (1.3%) 6 (2.4%) 11 (4.5%)\n\nMean ( mi | mi > 0) 8.554× 10\n−3\n\n8.348× 10\n−3 9.500× 10\n\n−4\n2.231× 10\n\n−3\n3.810× 10\n\n−3\n\nMedian ( mi | mi > 0) 2.411× 10\n−3\n\n2.039× 10\n−3 5.288× 10\n\n−4\n6.494× 10\n\n−4\n1.337× 10\n\n−3\n\nFFi + CYi ≥ 1 294 280 357 313 283\n\nCYPi = 0 234 (79.6%) 188 (67.1%) 222 (62.2%) 227 (72.5%) 202 (71.4%)\n\nMean ( CYPi | CYPi > 0) 1.987× 10\n−2\n\n7.367× 10\n−2\n\n6.739× 10\n−2\n\n8.551× 10\n−2\n\n5.544× 10\n−2\n\nMedian ( CYPi | CYPi > 0) 1.521× 10\n−2\n\n4.481× 10\n−2\n\n3.396× 10\n−2\n\n3.822× 10\n−2\n\n3.618× 10\n−2\n\n\n\nPage 10 of 18Kodate et al. Appl Netw Sci            (2020) 5:90 \n\nindicating that a relatively large fraction of normal users is almost exclusive buyer or \nseller. Note that, by definition, the sell probability is at least 1/(k ini + kouti ) because our \nsamples are sellers. Therefore, a peak around the sell probability of zero implies that \nthe users probably have no or few sell transactions apart from the one sell transaction \nbased on which the users have been sampled as seller. In contrast, the distribution \nfor any fraudulent type is relatively flat. Figure  5b shows the relationships between \nthe unweighted sell probability and the degree. On the dashed line in Fig. 5b, the sell \nprobability is equal to 1/(k ini + kouti ) , indicating that the node has kouti = 1 , which is \nthe smallest possible out-degree. The users on this line were buyers in all but one \n\na b\n\nFig. 4 Survival probability of the average number of transactions per neighbor. a si/ki for all nodes. b si/ki for \nthe nodes with si/ki > 1\n\na b\n\nc d\n\nFig. 5 Sell probability for each user type. a Distribution of the unweighted sell probability. b Relationship \nbetween the degree and the unweighted sell probability. c Distribution of the weighted sell probability. d \nRelationship between the node strength and the weighted sell probability. The dashed lines in b, d indicate \n1/(k in\n\ni\n+ k\n\nout\ni\n\n) and 1/(sin\ni\n+ s\n\nout\ni\n\n) , respectively\n\n\n\nPage 11 of 18Kodate et al. Appl Netw Sci            (2020) 5:90  \n\ntransaction. Figure 5b indicates that a majority of such users are normal as opposed \nto fraudulent users, which is quantitatively confirmed in Table 1. We also found that \nmost of the normal users were either on the horizontal line with the sell probability \nof one (38.1% of the normal users with ki ≥ 2 ; see Table 1 for the corresponding frac-\ntions of normal users with ki = 1 ) or on the dashed line (28.6%). This is not the case \nfor any type of fraudulent user (Table 1).\n\nThe distribution of the weighted sell probability for the different user types and the \nrelationships between the weighted sell probability and the node strength are shown \nin Fig.  5c, d, respectively. The results are similar to the case of the unweighted sell \nprobability in two aspects. First, the normal users and the fraudulent users form dis-\ntinct frequency distributions (Fig. 5c). Second, most of the normal users are either on \nthe horizontal line with the weighted sell probability of one or on the dashed line with \nthe smallest possible weighted sell probability, i.e., 1/si (Fig. 5d, Table 1).\n\nThe survival probability of the local clustering coefficient is shown in Fig.  6a. It \nshould be noted that, in this analysis, we confined ourselves to the users with ki ≥ 2 \nbecause Ci is undefined when ki = 1 . We found that the number of users with Ci = 0 is \nnot considerably different between the normal and fraudulent users (also see Table 1). \nFigure  6b shows the survival probability of Ci conditioned on Ci > 0 . The normal \nusers tend to have a larger value of Ci than fraudulent users, whereas this tendency is \nnot strong (Table 1).\n\nThe survival probability of the triangle congregation is shown in Fig. 7a. Contrary to \nour hypothesis, there is no clear difference between the distribution of the normal and \nfraudulent users. The triangle congregation tends to be large when the node strength \nis small (Fig. 7b) and the local clustering coefficient is large (Fig. 7d). It depends little \non the weighted sell probability (Fig. 7c). However, we did not find clear differences in \nthe triangle congregation between the normal and fraudulent users (also see Table 1).\n\nThe survival probability of the cycle probability is shown in Fig. 8a. A large fraction \nof any type of users has CYPi = 0 (Table 1). When the users with CYPi = 0 are dis-\ncarded, the normal users tend to have a smaller value of CYPi than any type of fraudu-\nlent users (Fig. 8b, Table 1).\n\na b\n\nFig. 6 Local clustering coefficient for each user type. a Survival probability. b Survival probability conditioned \non Ci > 0\n\n\n\nPage 12 of 18Kodate et al. Appl Netw Sci            (2020) 5:90 \n\nClassification of users\n\nBased on the eight indices whose descriptive statistics were analyzed in the previ-\nous section, we defined 12 features and fed them to the random forest classifier. The \naim of the classifier is to distinguish between normal and fraudulent users. The first \nfeature is binary and whether the degree ki = 1 or ki ≥ 2 . The second feature is also \nbinary and whether the node strength si = 1 or si ≥ 2 . The third feature is si/ki , which \nis a real number greater than or equal to 1. The fourth feature is binary and whether the \nunweighted sell probability SPi = 1 or SPi < 1 . The fifth feature is binary and whether \n\na b\n\nc d\n\nFig. 7 Triangle congregation for each user type. a Survival probability. b Relationship between the triangle \ncongregation, mi , and the node strength. c Relationship between mi and the weighted sell probability. d \nRelationship between mi and the local clustering coefficient\n\na b\n\nFig. 8 Cycle probability for each user type. a Survival probability. b Survival probability conditioned on \nCYPi > 0\n\n\n\nPage 13 of 18Kodate et al. Appl Netw Sci            (2020) 5:90  \n\nSPi = 1/(k ini + kouti ) or SPi > 1/(k ini + kouti ) , i.e., whether kouti = 1 or kouti > 1 . The sixth \nfeature is SPi , which ranges between 0 and 1. The seventh feature is binary and whether \nthe weighted sell probability WSPi = 1 or WSPi < 1 . The eighth feature is binary and \nwhether WSPi = 1/(sini + souti ) or WSPi > 1/(sini + souti ) , i.e., whether souti = 1 or \nsouti > 1 . The ninth feature is WSPi , which ranges between 0 and 1. The tenth feature is \nthe local clustering coefficient Ci , which ranges between 0 and 1. When ki = 1 , the local \nclustering coefficient is undefined. In this case, we set Ci = − 1 . The eleventh feature is \nthe triangle congregation mi , which ranges between 0 and 1. When there is no triangle \nor only one triangle involving vi , one cannot calculate mi . In this case, we set mi = − 1 . \nFinally, the twelfth feature is the cycle probability CYPi , which ranges between 0 and 1. \nWhen there is neither feedforward nor cyclic triangle involving vi , CYPi is undefined. In \nthis case, we set CYPi = − 1.\n\nThe ROC and PR curves when all the 12 features of users are used and the fraudu-\nlent type is fictive transactions are shown in Fig. 9a, b, respectively. Each thin line cor-\nresponds to one of the 100 classifiers. The thick lines correspond to the average of the \n100 lines. The dashed lines correspond to the uniformly random classification. Figure 9 \nindicates that the classification performance seems to be high. Quantitatively, for this \nand the other types of fraudulent users, the AUC values always exceeded 0.91 (Table 2).\n\nThe importance of each feature in the classifier is shown in Fig.  10a, separately for \nthe different fraud types. The importance of each feature is similar across the different \ntypes of fraud. Figure 10a indicates that the average number of transactions per neighbor \n(i.e., si/ki ), whether or not kouti = 1 (i.e., SPi = 1/(k ini + kouti ) ), whether or not souti = 1 \n(i.e., WSPi = 1/(sini + souti ) ), and the weighted sell probability (i.e., WSPi ) are the four \nfeatures of the highest importance. Given the results of the descriptive statistics in the \nprevious section, a small value of si/ki , kouti  = 1 , souti  = 1 , and a moderate WSPi value \nstrongly suggest that the user may be fraudulent.\n\nFigure 10a also suggests that the features based on the triangles, i.e., Ci , mi , and CYPi , \nare not strong contributors to the classifier’s performance. Because these features are the \nonly ones that require the information about the connectivity between pairs of neigh-\nbors of the focal node, it is practically beneficial if one can realize a similar classification \n\na b\n\nFig. 9 ROC and PR curves when the normal users and those involved in fictive transactions are classified. a \nROC curves. b PR curves. Each thin line corresponds to one of the 100 classifiers. The thick lines correspond to \nthe average of the 100 lines. The dashed lines correspond to the uniformly random classification\n\n\n\nPage 14 of 18Kodate et al. Appl Netw Sci            (2020) 5:90 \n\nperformance without using these features; then only the information on the connectivity \nof the focal users is required. To explore this possibility, we constructed the random for-\nest classifier using the nine out of the twelve features that do not require the connectivity \nbetween neighbors of the focal node. The mean AUC values for the ROC and PR curves \nare shown in Table 2. We find that, despite some reduction in the performance scores \nrelative to the case of the classifier using all the 12 features, the AUC values with the \nnine features are still large, all exceeding 0.88. The permutation importance of the nine \nfeatures is shown in Fig. 10b. The results are similar to those when all the 12 features are \nused, although the importance of WSPi considerably increased in the case of the nine \nfeatures (Fig. 10a).\n\nMore than half of the normal users have ki = 1 , and there are few fraudulent users \nwith ki = 1 in each fraud category (Table 1). The classification between the normal and \nfraudulent users may be an easy problem for this reason, leading to the large AUC val-\nues. To exclude this possibility, we carried out a classification test for the subdata in \nwhich the normal and fraudulent users with ki = 1 were excluded, leaving 412 normal \nusers and a similar number of fraudulent users in each category (Table 1). We did not \n\na b\n\nFig. 10 Permutation importance of the features in the random forest classifier. a 12 features. b 9 features. The \nbars indicate the average over the 100 classifiers. The error bars indicate standard deviation\n\nTable 2 AUC values for the random forest classifiers\n\nThe average and standard deviation were calculated based on the 100 classifiers\n\nFictive Underwear Medicine Weapon\n\n12 features\n\nROC 0.962 ± 0.003 0.981 ± 0.001 0.979 ± 0.003 0.969 ± 0.004\n\nPR 0.916 ± 0.009 0.948 ± 0.006 0.947 ± 0.005 0.916 ± 0.015\n\n9 features\n\nROC 0.951 ± 0.003 0.973 ± 0.003 0.971 ± 0.003 0.961 ± 0.004\n\nPR 0.889 ± 0.009 0.923 ± 0.010 0.930 ± 0.009 0.888 ± 0.025\n\n\n\nPage 15 of 18Kodate et al. Appl Netw Sci            (2020) 5:90  \n\ncarry out subsampling because the number of the negative and positive samples were \nsimilar. Instead, we generated 100 different sets of train and test samples and built a clas-\nsifier based on each set of train and test samples. The AUC values when either 10 or 7 \nfeatures (i.e., the features excluding whether or not ki = 1 and whether or not si = 1 ) are \nused are shown in Table 3. The table indicates that the AUC values are still competitively \nlarge while they are smaller than those when whether or not ki = 1 and whether or not \nsi = 1 are used as features (Table 2).\n\nDiscussion\nWe showed that a random forest classifier using network features of users distinguished \ndifferent types of fraudulent users from normal users with approximately 0.91–0.98 in \nterms of the AUC. We only used the information about local transaction networks cen-\ntered around focal users to synthesize their features. We did so because it is better in \npractice not to demand the information about global transaction networks due to the \nlarge number of users. It should be noted that AUC values of ≈ 0.88–0.97 was also real-\nized when we only used the information about the connectivity of the focal user, not the \nconnectivity between the neighbors of the focal user. This result has a practical advan-\ntage when the present fraud-detection method is implemented online because it allows \none to classify users with a smaller amount of data per user.\n\nThe random forest classifier is an arbitrary choice. One can alternatively use a different \nlinear or nonlinear classifier to pursue a higher classification performance. This is left as \nfuture work. Other future tasks include the generalizability of the present results to dif-\nferent types of fraudulent transactions, such as resale tickets, pornography, and stolen \nitems, and to different platforms. In particular, if a classifier trained with test samples \nfrom fraudulent users of a particular type and normal users is effective at detecting dif-\nferent types of fraud, the classifier will also be potentially useful for detecting unknown \ntypes of fraudulent transactions. It is also a potentially relevant question to assess the \nclassification performance when one pools different types of fraud as a single positive \ncategory to train a classifier.\n\nPrior network-based fraud detection has employed either global or local network \nproperties to characterize nodes. Global network properties refer to those that require \nthe structure of the entire network for calculating a quantity for individual nodes, such \nas the connected component (Šubelj et al. 2011; Savage et al. 2017; Wang et al. 2018), \nbetweenness centrality (Šubelj et al. 2011; Dreżewski et al. 2015; Colladon and Remondi \n2017), user’s suspiciousness determined by belief propagation (Chau et al. 2006; Pandit \n\nTable 3 AUC values for the random forest classifiers excluding users with ki = 1\n\nThe average and standard deviation were calculated based on the 100 classifiers\n\nFictive Underwear Medicine Weapon\n\n10 features\n\nROC 0.925 ± 0.016 0.950 ± 0.013 0.954 ± 0.012 0.916 ± 0.019\n\nPR 0.923 ± 0.019 0.950 ± 0.018 0.954 ± 0.016 0.911 ± 0.023\n\n7 features\n\nROC 0.886 ± 0.020 0.921 ± 0.015 0.933 ± 0.014 0.899 ± 0.020\n\nPR 0.874 ± 0.027 0.901 ± 0.021 0.928 ± 0.019 0.880 ± 0.028\n\n\n\nPage 16 of 18Kodate et al. Appl Netw Sci            (2020) 5:90 \n\net al. 2007; Akoglu et al. 2013; Bangcharoensap et al. 2015; Van Vlasselaer et al. 2015, \n2016; Li et al. 2017; Hu et al. 2017), dense subgraphs including the case of communities \n(Šubelj et al. 2011; Bhat and Abulaish 2013; Ferrara et al. 2014; Jiang et al. 2014; Hooi \net al. 2016; Liu et al. 2016; Shchur et al. 2018), and k-core (Wang and Chiu 2008; Rasheed \net  al. 2018). Although many of these methods have accrued a high classification per-\nformance, they require the information about the entire network. Obtaining such data \nmay be difficult when the network is large or rapidly evolving over time, thus potentially \ncompromising the computation speed, memory requirement, and the accuracy of the \ninformation on the nodes and edges. Alternatively, other methods employed local net-\nwork properties such as the degree including the case of directed and/or weighted net-\nworks (Chau et al. 2006; Akoglu et al. 2010; Šubelj et al. 2011; Yanchun et al. 2011; Bhat \nand Abulaish 2013; Bangcharoensap et al. 2015; Dreżewski et  al. 2015; Monamo et al. \n2016; Van Vlasselaer et al. 2016; Colladon and Remondi 2017) and the abundance of tri-\nangles and quadrangles (Monamo et al. 2016; Van Vlasselaer et al. 2016). The use of local \nnetwork properties may be advantageous in industrial contexts, particularly to test sam-\npled users, because local quantities can be rapidly calculated given a seed node. Another \nreason for which we focused on local properties was that we could not obtain the global \nnetwork structure for computational reasons. It should be noted that, while the use of \nglobal network properties in addition to local ones may improve the classification accu-\nracy (Bhat and Abulaish 2013), the present local method attained a similar classification \nperformance to those based on global network properties, i.e., 0.880–0.986 in terms of \nthe ROC AUC (Šubelj et al. 2011; Van Vlasselaer et al. 2015; Van Vlasselaer et al. 2016; \nHu et al. 2017; Li et al. 2017; Savage et al. 2017).\n\nA prior study using data from the same marketplace, Mercari, aimed to distinguish \nbetween desirable non-professional frequent sellers and undesirable professional sellers \n(Yamamoto et al. 2019). The authors used information about user profiles, item descrip-\ntions, and other behavioral data such as the number of purchases per day. In contrast, \nwe focused on local network features of the users (while a quantity similar to WSPi was \nused as a feature in Yamamoto et al. (2019)). In addition, we used specific types of fraud-\nulent transactions, whereas Yamamoto et al. (2019) focused on problematic transactions \nas a single broad category. How the present results generalize to different categoriza-\ntions of fraudulent transactions, the platform’s different data such as their US market \ndata, and similar data obtained from other online marketplaces is unknown. Combining \nnetwork and non-network features may realize a better classification performance . Fur-\nthermore, using the information about the time of the transactions may also yield better \nclassification. Using the time information allows us to ask new questions such as predic-\ntion of users’ behavior. These topics warrant future work.\n\nAbbreviations\nC2C: Consumer-to-consumer; ROC: Receiver operating characteristic; PR: Precision–recall; AUC : Area under the curve.\n\nAcknowledgements\nThis work was carried out using the computational facilities of the Advanced Computing Research Centre, University of \nBristol.\n\nAuthors’ contributions\nShun Kodate analyzed data, developed methodology, visualized the results, and drafted the manuscript; RC curated data \nand critically revised the manuscript; Shunya Kimura coordinated the study, acquired funding, and critically revised the \nmanuscript; NM coordinated the study, acquired funding, developed methodology, drafted the manuscript. All authors \n\n\n\nPage 17 of 18Kodate et al. Appl Netw Sci            (2020) 5:90  \n\ngave final approval for publication and agreed to be held accountable for the work performed therein. All authors read \nand approved the final manuscript.\n\nFunding\nThe authors acknowledge financial support by Mercari, Inc. S. Kodate was supported in part by the Top Global University \nProject from the Ministry of Education, Culture, Sports, Science and Technology (MEXT) of Japan.\n\nAvailability of data and materials\nMercari, Inc. approved the use of the data for the present study under the condition that the data were hashed and \nonly released to the collaborators of the project (i.e., the first and last authors, because the second and third authors \nare employees of the company). The figures and tables of the present paper are summary statistics of the data and not \nsufficient on their own for others to replicate the results of the present study. Although the data have been hashed, the \ncompany cannot share the data with the public. This is because, if anybody traces the transaction data on the Mercari’s \nweb platform and checks them against the hashed data, that person would be able to identify individual users including \ntheir private information. Therefore, hashing/anonymizing does not help to guarantee the users’ privacy. Any bona fide \nresearcher could approach the company (Shunya Kimura: kimuras@mercari.com and Ryusuke Chiba: metalunk@mercari.\ncom) to seek access to the complete dataset. However, for the aforementioned reasons, such an attempt is unlikely to be \nsuccessful. The users were made aware that their data may be used for the present research because the Mercari’s terms \nof use (in Japanese only: https ://www.merca ri.com/jp/tos/), Article 20, Term 2, states that their data can be used for \nresearch by the company and by those who the company permits.\n\nEthics approval and consent to participate\nMercari, Inc. approved the use of the data for the present study under the condition that the data were hashed and \nonly released to the collaborators of the project (i.e., the first and last authors, because the second and third authors are \nemployees of the company).\n\nCompeting interests\nThe second and third authors are employees of the company that provided the data analysed in the present manuscript. \nHowever, this fact does not cause any conflict of interest because the analyses, results and their interpretation are free of \nany bias towards the merit of the company.\n\nAuthor details\n1 Graduate School of Information Sciences, Tohoku University, Sendai 980-8579, Japan. 2 Department of Engineering \nMathematics, University of Bristol, Bristol BS8 1UB, UK. 3 Mercari, Inc., Tokyo 106-6118, Japan. 4 Department of Mathemat-\nics, University at Buffalo, Buffalo, NY 14260-2900, USA. 5 Computational and Data-Enabled Science and Engineering \nProgram, University at Buffalo, Buffalo, NY 14260-5030, USA. \n\nReceived: 12 August 2020   Accepted: 23 October 2020\n\nReferences\nAbdallah A, Maarof MA, Zainal A (2016) Fraud detection system: a survey. J Netw Comput Appl 68:90–113\nAkoglu L, McGlohon M, Faloutsos C (2010) Oddball: spotting anomalies in weighted graphs. In: Pacific-Asia conference on \n\nknowledge discovery and data mining, pp 410–421\nAkoglu L, Chandy R, Faloutsos C (2013) Opinion fraud detection in online reviews by network effects. In: 7th international \n\nAAAI conference on weblogs and social media, pp 2–11\nAkoglu L, Tong H, Koutra D (2015) Graph based anomaly detection and description: a survey. Data Min Knowl Discov \n\n29:626–688\nAltmann A, Toloşi L, Sander O, Lengauer T (2010) Permutation importance: a corrected feature importance measure. Bioinfo \n\n26:1340–1347\nAnderson R, Barton C, Böhme R, Clayton R, Van Eeten MJ, Levi M, Moore T, Savage S (2013) Measuring the cost of cybercrime. \n\nIn: The economics of information security and privacy. Springer, Berlin, pp 265–300\nBangcharoensap P, Kobayashi H, Shimizu N, Yamauchi S, Murata T (2015) Two step graph-based semi-supervised learning \n\nfor online auction fraud detection. In: Joint European conference on machine learning and knowledge discovery in \ndatabases, pp 165–179\n\nBarrat A, Barthelemy M, Pastor-Satorras R, Vespignani A (2004) The architecture of complex weighted networks. Proc Natl \nAcad Sci USA 101:3747–3752\n\nBhat SY, Abulaish M (2013) Community-based features for identifying spammers in online social networks. In: 2013 IEEE/ACM \ninternational conference on advances in social networks analysis and mining (ASONAM 2013), pp 100–107\n\nBhowmick A, Hazarika SM (2016) Machine learning for e-mail spam filtering: review, techniques and trends. Preprint arXiv \n:1606.01042 \n\nBolton RJ, Hand DJ (2002) Statistical fraud detection: a review. Stat Sci 17:235–249\nBreiman L (2001) Random forests. Mach Learn 45:5–32\nBreiman L, Friedman JH, Olshen RA, Stone CJ (1984) Classification and regression trees. Chapman & Hall, Boca Raton\nChau DH, Pandit S, Faloutsos C (2006) Detecting fraudulent personalities in networks of online auctioneers. In: European \n\nconference on principles of data mining and knowledge discovery, pp 103–114\nColladon AF, Remondi E (2017) Using social network analysis to prevent money laundering. Expert Syst Appl 67:49–58\nDreżewski R, Sepielak J, Filipkowski W (2015) The application of social network analysis algorithms in a system supporting \n\nmoney laundering detection. Inf Sci 295:18–32\nFerrara E, De Meo P, Catanese S, Fiumara G (2014) Detecting criminal organizations in mobile phone networks. Expert Syst \n\nAppl 41:5733–5750\nGoogle LLC and White Ops, Inc (2018) The Hunt for 3ve. https ://servi ces.googl e.com/fh/files /blogs /3ve_googl e_white \n\nops_white paper _final _nov_2018.pdf. Accessed: 10 May 2019\n\nhttps://www.mercari.com/jp/tos/\nhttp://arxiv.org/abs/1606.01042\nhttp://arxiv.org/abs/1606.01042\nhttps://services.google.com/fh/files/blogs/3ve_google_whiteops_whitepaper_final_nov_2018.pdf\nhttps://services.google.com/fh/files/blogs/3ve_google_whiteops_whitepaper_final_nov_2018.pdf\n\n\nPage 18 of 18Kodate et al. Appl Netw Sci            (2020) 5:90 \n\nHastie T, Tibshirani R, Friedman J (2009) The elements of statistical learning: data mining, inference, and prediction. Springer, \nNew York\n\nHayes B (2007) How many ways can you spell v1@gra? Am Sci 95:298–302\nHooi B, Song HA, Beutel A, Shah N, Shin K, Faloutsos C (2016) Fraudar: bounding graph fraud in the face of camouflage. In: \n\nProceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining, pp 895–904\nHu J, Liang J, Dong S (2017) ibgp: a bipartite graph propagation approach for mobile advertising fraud detection. Mobile Inf \n\nSyst 2017:1–12\nJiang M, Cui P, Beutel A, Faloutsos C, Yang S (2014) Inferring strange behavior from connectivity pattern in social networks. In: \n\nPacific-Asia conference on knowledge discovery and data mining, pp 126–138\nLi Y, Sun Y, Contractor N (2017) Graph mining assisted semi-supervised learning for fraudulent cash-out detection. In: Pro-\n\nceedings of the 2017 IEEE/ACM international conference on advances in social networks analysis and mining 2017, pp \n546–553\n\nLiu J, Bier E, Wilson A, Guerra-Gomez JA, Honda T, Sricharan K, Gilpin L, Davies D (2016) Graph analysis for detecting fraud, \nwaste, and abuse in healthcare data. AI Mag 37:33–46\n\nLiu S, Hooi B, Faloutsos C (2017) Holoscope: topology-and-spike aware fraud detection. In: Proceedings of the 2017 ACM on \nconference on information and knowledge management, pp 1539–1548\n\nMcAfee LLC (2019) Economic impact of cybercrime report. https ://www.mcafe e.com/enter prise /en-us/solut ions/lp/econo \nmics-cyber crime .html. Accessed: 25 Apr 2018\n\nMercari Inc (2019) FY2019.6 Q3 Presentation Material. https ://about .merca ri.com/en/ir/libra ry/resul ts/. Accessed 1 Nov 2020\nMilo R, Shen-Orr S, Itzkovitz S, Kashtan N, Chklovskii D, Alon U (2002) Network motifs: simple building blocks of complex \n\nnetworks. Science 298:824–827\nMonamo P, Marivate V, Twala B (2016) Unsupervised learning for robust Bitcoin fraud detection. In: 2016 information security \n\nfor South Africa (ISSA), pp 129–134\nNewman M (2010) Networks: an introduction. Oxford University Press, Oxford\nPalla G, Derényi I, Farkas I, Vicsek T (2005) Uncovering the overlapping community structure of complex networks in nature \n\nand society. Nature 435:814–818\nPandit S, Chau DH, Wang S, Faloutsos C (2007) Netprobe: a fast and scalable system for fraud detection in online auction \n\nnetworks. In: Proceedings of the 16th international conference on world wide web, pp 201–210\nPedregosa F, Varoquaux G, Gramfort A, Michel V, Thirion B, Grisel O, Blondel M, Prettenhofer P, Weiss R, Dubourg V et al (2011) \n\nScikit-learn: machine learning in Python. J Mach Learn Res 12:2825–2830\nPhua C, Lee V, Smith K, Gayler R (2010) A comprehensive survey of data mining-based fraud detection research. Preprint arXiv \n\n:1009.6119\nPu C, Webb S (2006) Observed trends in spam construction techniques: a case study of spam evolution. In: CEAS, pp 104–112\nRadicchi F, Castellano C, Cecconi F, Loreto V, Parisi D (2004) Defining and identifying communities in networks. Proc Natl Acad \n\nSci USA 101:2658–2663\nRasheed J, Akram U, Malik AK (2018) Terrorist network analysis and identification of main actors using machine learning tech-\n\nniques. In: Proceedings of the 6th international conference on information technology: IoT and smart city, pp 7–12\nSavage D, Zhang X, Yu X, Chou P, Wang Q (2014) Anomaly detection in online social networks. Soc Netw 39:62–70\nSavage D, Wang Q, Zhang X, Chou P, Yu X (2017) Detection of money laundering groups: supervised learning on small net-\n\nworks. In: Workshops at the 31st AAAI conference on artificial intelligence, pp 43–49\nShchur O, Bojchevski A, Farghal M, Günnemann S, Saber Y (2018) Anomaly detection in car-booking graphs. In: 2018 IEEE \n\ninternational conference on data mining workshops (ICDMW), pp 604–607\nStrobl C, Boulesteix A-L, Zeileis A, Hothorn T (2007) Bias in random forest variable importance measures: illustrations, sources \n\nand a solution. BMC Bioinform 8:25\nŠubelj L, Furlan Š, Bajec M (2011) An expert system for detecting automobile insurance fraud using social network analysis. \n\nExpert Syst Appl 38:1039–1052\nUK Parliament: The Growing Threat of Online Fraud (2017). https ://old.parli ament .uk/busin ess/commi ttees /commi ttees -a-z/\n\ncommo ns-selec t/publi c-accou nts-commi ttee/inqui ries/parli ament -2017/growi ng-threa t-onlin e-fraud -17-19/publi catio \nns/. Accessed 1 Nov 2020\n\nVan Vlasselaer V, Bravo C, Caelen O, Eliassi-Rad T, Akoglu L, Snoeck M, Baesens B (2015) Apate: a novel approach for automated \ncredit card transaction fraud detection using network-based extensions. Decis Support Syst 75:38–48\n\nVan Vlasselaer V, Eliassi-Rad T, Akoglu L, Snoeck M, Baesens B (2016) Gotcha! network-based fraud detection for social security \nfraud. Manag Sci 63:3090–3110\n\nWang J-C, Chiu C-C (2008) Recommending trusted online auction sellers using social network analysis. Expert Syst Appl \n34:1666–1679\n\nWang Z, Gu S, Zhao X, Xu X (2018) Graph-based review spammer group detection. Knowl Inf Syst 55:571–597\nWest J, Bhattacharya M (2016) Intelligent financial fraud detection: a comprehensive review. Comput Secur 57:47–66\nYamamoto H, Sugiyama N, Toriumi F, Kashida H, Yamaguchi T (2019) Angels or demons? Classifying desirable heavy users and \n\nundesirable power sellers in online C2C marketplace. J Comput Soc Sci 2:315–329\nYanchun Z, Wei Z, Changhai Y (2011) Detection of feedback reputation fraud in Taobao using social network theory. In: 2011 \n\ninternational joint conference on service sciences, pp 188–192\n\nPublisher’s Note\nSpringer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.\n\nhttps://www.mcafee.com/enterprise/en-us/solutions/lp/economics-cybercrime.html\nhttps://www.mcafee.com/enterprise/en-us/solutions/lp/economics-cybercrime.html\nhttps://about.mercari.com/en/ir/library/results/\nhttp://arxiv.org/abs/1009.6119\nhttp://arxiv.org/abs/1009.6119\nhttps://old.parliament.uk/business/committees/committees-a-z/commons-select/public-accounts-committee/inquiries/parliament-2017/growing-threat-online-fraud-17-19/publications/\nhttps://old.parliament.uk/business/committees/committees-a-z/commons-select/public-accounts-committee/inquiries/parliament-2017/growing-threat-online-fraud-17-19/publications/\nhttps://old.parliament.uk/business/committees/committees-a-z/commons-select/public-accounts-committee/inquiries/parliament-2017/growing-threat-online-fraud-17-19/publications/\n\n\tDetecting problematic transactions in a consumer-to-consumer e-commerce network\n\tAbstract \n\tIntroduction\n\tMaterials and methods\n\tData\n\tNetwork analysis\n\tRandom forest classifier\n\n\tResults\n\tDescriptive statistics\n\tClassification of users\n\n\tDiscussion\n\tAcknowledgements\n\tReferences\n\n\n",
      "metadata_storage_path": "aHR0cHM6Ly9jb3Jwb3JhdGV0cmFpbmluZ3N0b3JhZ2UuYmxvYi5jb3JlLndpbmRvd3MubmV0L3BhcGVycy9zNDExMDktMDIwLTAwMzMwLXgucGRm0",
      "metadata_author": " Shun Kodate ",
      "metadata_title": "Detecting problematic transactions in a consumer-to-consumer e-commerce network",
      "metadata_creation_date": "2020-11-12T15:20:34Z",
      "keyphrases": [
        "problematic transactions",
        "commerce network",
        "consumer"
      ]
    },
    {
      "@search.score": 0.1541468,
      "content": "\nBig data stream analysis: a systematic \nliterature review\nTaiwo Kolajo1,2* , Olawande Daramola3  and Ayodele Adebiyi1,4 \n\nIntroduction\nAdvances in information technology have facilitated large volume, high-velocity of data, \nand the ability to store data continuously leading to several computational challenges. \nDue to the nature of big data in terms of volume, velocity, variety, variability, veracity, \nvolatility, and value [1] that are being generated recently, big data computing is a new \ntrend for future computing.\n\nBig data computing can be generally categorized into two types based on the process-\ning requirements, which are big data batch computing and big data stream computing \n\nAbstract \n\nRecently, big data streams have become ubiquitous due to the fact that a number of \napplications generate a huge amount of data at a great velocity. This made it difficult \nfor existing data mining tools, technologies, methods, and techniques to be applied \ndirectly on big data streams due to the inherent dynamic characteristics of big data. In \nthis paper, a systematic review of big data streams analysis which employed a rigorous \nand methodical approach to look at the trends of big data stream tools and technolo-\ngies as well as methods and techniques employed in analysing big data streams. It \nprovides a global view of big data stream tools and technologies and its comparisons. \nThree major databases, Scopus, ScienceDirect and EBSCO, which indexes journals and \nconferences that are promoted by entities such as IEEE, ACM, SpringerLink, and Elsevier \nwere explored as data sources. Out of the initial 2295 papers that resulted from the \nfirst search string, 47 papers were found to be relevant to our research questions after \nimplementing the inclusion and exclusion criteria. The study found that scalability, \nprivacy and load balancing issues as well as empirical analysis of big data streams and \ntechnologies are still open for further research efforts. We also found that although, sig-\nnificant research efforts have been directed to real-time analysis of big data stream not \nmuch attention has been given to the preprocessing stage of big data streams. Only a \nfew big data streaming tools and technologies can do all of the batch, streaming, and \niterative jobs; there seems to be no big data tool and technology that offers all the key \nfeatures required for now and standard benchmark dataset for big data streaming ana-\nlytics has not been widely adopted. In conclusion, it was recommended that research \nefforts should be geared towards developing scalable frameworks and algorithms that \nwill accommodate data stream computing mode, effective resource allocation strategy \nand parallelization issues to cope with the ever-growing size and complexity of data.\n\nKeywords: Big data stream analysis, Stream computing, Big data streaming tools and \ntechnologies\n\nOpen Access\n\n© The Author(s) 2019. This article is distributed under the terms of the Creative Commons Attribution 4.0 International License \n(http://creat iveco mmons .org/licen ses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, \nprovided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and \nindicate if changes were made.\n\nSURVEY PAPER\n\nKolajo et al. J Big Data            (2019) 6:47  \nhttps://doi.org/10.1186/s40537-019-0210-7\n\n*Correspondence:   \ntaiwo.kolajo@stu.cu.edu.ng; \ntaiwo.kolajo@fulokoja.edu.ng \n1 Department of Computer \nand Information Sciences, \nCovenant University, Ota, \nNigeria\nFull list of author information \nis available at the end of the \narticle\n\nhttp://orcid.org/0000-0001-6780-2495\nhttp://orcid.org/0000-0001-6340-078X\nhttp://orcid.org/0000-0002-3114-6315\nhttp://creativecommons.org/licenses/by/4.0/\nhttp://crossmark.crossref.org/dialog/?doi=10.1186/s40537-019-0210-7&domain=pdf\n\n\nPage 2 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\n[2]. Big data batch processing is not sufficient when it comes to analysing real-time \napplication scenarios. Most of the data generated in a real-time data stream need real-\ntime data analysis. In addition, the output must be generated with low-latency and any \nincoming data must be reflected in the newly generated output within seconds. This \nnecessitates big data stream analysis [3].\n\nThe demand for stream processing is increasing. The reason being not only that huge \nvolume of data need to be processed but that data must be speedily processed so that \norganisations or businesses can react to changing conditions in real-time.\n\nThis paper presents a systematic review of big data stream analysis. The purpose is to \npresent an overview of research works, findings, as well as implications for research and \npractice. This is necessary to (1) provide an update about the state of research, (2) iden-\ntify areas that are well researched, (3) showcase areas that are lacking and need further \nresearch, and (4) build a common understanding of the challenges that exist for the ben-\nefit of the scientific community.\n\nThe rest of the paper is organized as follows: “Background and related work” section \nprovides information on stream computing and big data stream analysis and the key \nissues involved in it and presents a review on big data streaming analytics. In “Research \nmethod” section, the adopted research methodology is discussed, while “Result” section \npresents the findings of the study. “Discussion” section presents a detailed evaluation \nperformed on big data stream analysis, “Limitation of the review” section highlights the \nlimitations of the study, while “Conclusion and further work” concludes the paper.\n\nBackground and related work\nStream computing\n\nStream computing refers to the processing of massive amount of data generated at high-\nvelocity from multiple sources with low latency in real-time. It is a new paradigm neces-\nsitated because of new sources of data generating scenarios which include ubiquity of \nlocation services, mobile devices, and sensor pervasiveness [4]. It can be applied to the \nhigh-velocity flow of data from real-time sources such as the Internet of Things, Sensors, \nmarket data, mobile, and clickstream.\n\nThe fundamental assumption of this paradigm is that the potential value of data lies in \nits freshness. As a result, data are analysed as soon as they arrive in a stream to produce \nresult as opposed to what obtains in batch computing where data are first stored before \nthey are analysed. There is a crucial need for parallel architectures and scalable com-\nputing platforms [5]. With stream computing, organisations can analyse and respond in \nreal-time to rapidly changing data. Streaming processing frameworks include Storm, S4, \nKafka, and Spark [6–8]. The real contrasts between the batch processing and the stream \nprocessing paradigms are outlined in Table 1.\n\nIncorporating streaming data into decision-making process necessitates a program-\nming paradigm called stream computing. With stream computing, fairly static questions \ncan be evaluated on data in motion (i.e. real-time data) continuously [9].\n\nBig data stream analysis\n\nThe essence of big data streaming analytics is the need to analyse and respond to real-\ntime streaming data using continuous queries so that it is possible to continuously \n\n\n\nPage 3 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\nperform analysis on the fly within the stream. Stream processing solutions must be \nable to handle a real-time, high volume of data from diverse sources putting into con-\nsideration availability, scalability and fault tolerance. Big data stream analysis involves \nassimilation of data as an infinite tuple, analysis and production of actionable results \nusually in a form of stream [10].\n\nIn a stream processor, applications are represented as data flow graph made up of \noperations and interconnected streams as depicted in Fig. 1. In a streaming analytics \nsystem, application comes in a form of continuous queries, data are ingested continu-\nously, analysed and correlated, and stream of results are generated. Streaming analytic \napplications is usually a set of operators connected by streams. Streaming analytics \nsystems must be able to identify new information, incrementally build models and \naccess whether the new incoming data deviate from model predictions [9].\n\nThe idea of streaming analytics is that each of the received data tuples is processed \nin the data processing node. Such processing includes removing duplicates, filling \nmissing data, data normalization, parsing, feature extraction, which are typically done \nin a single pass due to the high data rates of external feeds. When a new tuple arrives, \nthis node is triggered, and it expels tuples older than the time specified in the sliding \nwindow (sliding window is a typical example of windows used in stream computing \nwhich keeps only the latest tuples up to the time specified in the windows). A window \n\nTable 1 Comparison between batch processing and streaming processing [82]\n\nDimension Batch processing Streaming processing\n\nInput Data chunks Stream of new data or updates\n\nData size Known and finite Infinite or unknown in advance\n\nHardware Multiple CPUs Typical single limited amount of memory\n\nStorage Store Not store or store non-trivial portion in memory\n\nProcessing Processed in multiple rounds A single or few passes over data\n\nTime Much longer A few seconds or even milliseconds\n\nApplications Widely adopted in almost every domain Web mining, traffic monitoring, sensor networks\n\nFig. 1 Data flow graph of a stream processor. The figure shows how applications (made up of operations and \ninterconnected streams) are represented as data flow graph in a stream processor [10]\n\n\n\nPage 4 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\nis referred to as a logical container for data tuples received. It defines how frequently \ndata is refreshed in the container as well as when data processing is triggered [4].\n\nKey issues in big data stream analysis\n\nBig data stream analysis is relevant when there is a need to obtain useful knowledge \nfrom current happenings in an efficient and speedy manner in order to enable organisa-\ntions to quickly react to problems, or detect new trends which can help improve their \nperformance. However, there are some challenges such as scalability, integration, fault-\ntolerance, timeliness, consistency, heterogeneity and incompleteness, load balancing, \nprivacy issues, and accuracy [3, 11–18] which arises from the nature of big data streams \nthat must be dealt with.\n\nScalability\n\nOne of the main challenges in big data streaming analysis is the issue of scalability. The \nbig data stream is experiencing exponential growth in a way much faster than computer \nresources. The processors follow Moore’s law, but the size of data is exploding. There-\nfore, research efforts should be geared towards developing scalable frameworks and \nalgorithms that will accommodate data stream computing mode, effective resource allo-\ncation strategy and parallelization issues to cope with the ever-growing size and com-\nplexity of data.\n\nIntegration\n\nBuilding a distributed system where each node has a view of the data flow, that is, every \nnode performing analysis with a small number of sources, then aggregating these views \nto build a global view is non-trivial. An integration technique should be designed to ena-\nble efficient operations across different datasets.\n\nFault‑tolerance\n\nHigh fault-tolerance is required in life-critical systems. As data is real-time and infinite \nin big data stream computing environments, a good scalable high fault-tolerance strat-\negy is required that allows an application to continue working despite component failure \nwithout interruption.\n\nTimeliness\n\nTime is of the essence for time-sensitive processes such as mitigating security threats, \nthwarting fraud, or responding to a natural disaster. There is a need for scalable architec-\ntures or platforms that will enable continuous processing of data streams which can be \nused to maximize the timeliness of data. The main challenge is implementing a distrib-\nuted architecture that will aggregate local views of data into global view with minimal \nlatency between communicating nodes.\n\nConsistency\n\nAchieving high consistency (i.e. stability) in big data stream computing environments is \nnon-trivial as it is difficult to determine which data are needed and which nodes should \nbe consistent. Hence a good system structure is required.\n\n\n\nPage 5 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\nHeterogeneity and incompleteness\n\nBig data streams are heterogeneous in structure, organisations, semantics, accessi-\nbility and granularity. The challenge here is how to handle an always ever-increas-\ning data, extract meaningful content out of it, aggregate and correlate streaming \ndata from multiple sources in real-time. A competent data presentation should be \ndesigned to reflect the structure, diversity and hierarchy of the streaming data.\n\nLoad balancing\n\nA big data stream computing system is expected to be self-adaptive to data streams \nchanges and avoid load shedding. This is challenging as dedicating resources to cover \npeak loads 24/7 is impossible and load shedding is not feasible when the variance \nbetween the average load and the peak load is high. As a result, a distributing envi-\nronment that automatically streams partial data streams to a global centre when local \nresources become insufficient is required.\n\nHigh throughput\n\nDecision with respect to identifying the sub-graph that needs replication, how many \nreplicas are needed and the portion of the data stream to assign to each replica is an \nissue in big data stream computing environment. There is a need for good multiple \ninstances replication if high throughput is to be achieved.\n\nPrivacy\n\nBig data stream analytics created opportunities for analyzing a huge amount of data \nin real-time but also created a big threat to individual privacy. According to the Inter-\nnational Data Cooperation (IDC), not more than half of the entire information that \nneeds protection is effectively protected. The main challenge is proposing techniques \nfor protecting a big data stream dataset before its analysis.\n\nAccuracy\n\nOne of the main objectives of big data stream analysis is to develop effective tech-\nniques that can accurately predict future observations. However, as a result of inher-\nent characteristics of big data such as volume, velocity, variety, variability, veracity, \nvolatility, and value, big data analysis strongly constrain processing algorithms spatio-\ntemporally and hence stream-specific requirements must be taken into consideration \nto ensure high accuracy.\n\nRelated work\n\nThis section discusses some of the previous research efforts that relate to big data \nstreaming analytics.\n\nThe work of [13] presented a review of various tools, technologies and methods \nfor big data analytics by categorizing big data analytics literature according to their \nresearch focus. This paper is different in that it presents a systematic literature review \nthat focused on big data “streaming” analytics.\n\n\n\nPage 6 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\nAuthors in [19] presented a systematic review of big data analytics in e-commerce. The \nstudy explored characteristics, definitions, business values, types and challenges of big \ndata analytics in the e-commerce landscape. Likewise, [20] conducted a study that is cen-\ntred on big data analytics in technology and organisational resource management specifi-\ncally focusing on reviews that present big data challenges and big data analytics methods. \nAlthough they are systematic reviews, the focus is not, particularly on big data streaming.\n\nAuthors in [21] presented the status of empirical research and application areas in big \ndata by employing a systematic mapping method. In the same vein, authors in [22] also \nconducted a survey on big data technologies and machine learning algorithms with a \nparticular focus on anomaly detection. A systematic review of literature which aims to \ndetermine the scope, application, and challenges of big data analytics in healthcare was \npresented by [23]. The work of [2] presented a review of four big data streaming tools \nand technologies. While the study conducted in this paper provided a comprehensive \nreview of not only big data streaming tools and technologies but also methods and tech-\nniques employed in analyzing big data streams. In addition, authors [2] did not provide a \nclear explanation of the methodical approach for selecting the reviewed papers.\n\nResearch method\nThe study was grounded in a systematic literature review of tools and technologies \nwith methods and techniques used in analysing big data streams by adopting [24, 25] as \nmodels.\n\nResearch question\n\nThe study tries to answer the following research questions:\n\nResearch Question 1: What are the tools and technologies employed for big data \nstream analysis?\nResearch Question 2: What methods and techniques are used in analysing big data \nstreams?\nResearch Question 3: What do these tools and technologies have in common and \ntheir differences in terms of concept, purpose and capabilities?\nResearch Question 4: What are the limitations and strengths of these tools and tech-\nnologies?\nResearch Question 5: What are the evaluation techniques or benchmarks used for \nevaluating big data streaming tools and technology?\n\nSearch string\n\nCreating a good search string requires structuring in terms of population, compari-\nson, intervention and outcome [24]. Relevant publications were identified by forming \na search string that combined keywords driven by the research questions earlier stated. \nThe searches were conducted by employing three standard database indexes, which are \nScopus, Science Direct and EBSCOhost. The search string is “big data stream analysis” \nOR “big data stream technologies” OR “big data stream framework” OR “big data stream \nalgorithms” OR “big data stream analysis tools” OR “big data stream processing” OR “big \n\n\n\nPage 7 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\ndata stream analysis reviews” OR “big data stream literature review” OR “big data stream \nanalytics”.\n\nData sources\n\nAs research becomes increasingly interdisciplinary, global and collaborative, it is expedi-\nent to select from rich and standard databases. The databases consulted are as follows:\n\n i. Scopus1: Scopus is a bibliographic database containing abstracts and citations for \nacademic journal articles launched in 2004. It covers nearly 36,377 titles from over \n11,678 publishers of which 34,346 are peer-reviewed journals, delivering a compre-\nhensive overview of the world’s research output in the scientific, technical, medi-\ncal, and social sciences (including arts and humanities). It is the largest abstract \nand citation database of peer-reviewed literature.\n\n ii. ScienceDirect2: ScienceDirect is Elsevier’s leading information solution for \nresearchers, students, teachers, information professionals and healthcare profes-\nsionals. It provides both subscription-based and open access-based to a large data-\nbase combining authoritative, full-text scientific, technical and health publications \nwith smart intuitive functionality. It covers over 14 million publications from over \n3800 journals and more than 35,000 books. The journals are grouped into four \ncategories: Life Sciences, Physical Sciences and Engineering, Health Sciences, and \nSocial Sciences and Humanities.\n\n iii. EBSCOhost3: EBSCOhost covers a wide range of bibliographic and full-text data-\nbases for researchers, providing electronic journal service available to both cor-\nporate and academic researchers. It has a total of 16,711 journals and magazine \nindexed and abstracted of which 14,914 are peer-reviewed; more than 900,000 \nhigh-quality e-books and titles and over 60,000 audiobooks from more than 1500 \nmajor academic publishers.\n\n iv. ResearchGate4: A free online professional network for scientists and researchers to \nask and answer questions, share papers and find collaborators. It covers over 100 \nmillion publications from over 11 million researchers. ResearchGate was used as \na secondary source where the authors could not access some papers due to lack of \nsubscription.\n\nData retrieval\n\nThe search was conducted in Scopus, ScienceDirect and EBSCOhost since most of \nthe high impact journals and conferences are indexed in these set of rich databases. \nBoolean ‘OR’ was used in combining the nine (9) search strings. A total of 2295 arti-\ncles from the three databases were retrieved as shown in Table 2.\n\n1 http://www.scopu s.com.\n2 http://www.scien cedir ect.com.\n3 https ://www.ebsco host.com.\n4 https ://www.resea archg ate.net.\n\nhttp://www.scopus.com\nhttp://www.sciencedirect.com\nhttps://www.ebscohost.com\nhttps://www.reseaarchgate.net\n\n\nPage 8 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\nFurther refinement was performed by (i) limiting the search to journals and confer-\nence papers; (ii) selecting computer science and IT related as the subject domain; (iii) \nselecting ACM, IEEE, SpringerLink, Elsevier as sources; and year of publication to \nbetween 2004 and 2018. The year range was selected due to the fact that interest in \nbig data stream analysis actually started in 2004. At this stage, a total of 1989 papers \nwere excluded leaving a total of 315 papers (see Table  3). The result of the search \nstring was exported to PDF.\n\nBy going through the title of the papers, 111 seemingly relevant papers were extracted \nexcluding a total number of 213 that were not relevant at this stage (see Table 4).\n\nThe abstracts of 111 papers and introduction (for papers that the abstracts were not \nclear enough) were then read to have a quick overview of the paper and to ascertain \nwhether they are suitable or at variance with the research questions. The citations of \nthe papers were exported to Microsoft Excel for easy analysis. The papers were grouped \ninto three categories; “relevant”, “may be relevant” and “irrelevant”. The “relevant” papers \nwere marked with black colour, “may be relevant” and “irrelevant” with green and red \ncolours respectively. At the end of this stage, 45 papers were classified as “relevant”, 9 \npapers as “may be relevant” and 11 as “irrelevant”. Looking critically at the abstract again, \n18 papers were excluded by using the exclusion criteria leaving a total of 47 papers (see \nTable 5) which were manually reviewed in line with the research questions.\n\nInclusion criteria\n\nPapers published in journals, peer-reviewed conferences, workshops, technical and \nsymposium from 2004 and 2018 were included. In addition, the most recent papers \nwere selected in case of papers with similar investigations and results.\n\nTable 2 First search string result\n\nScopus ScienceDirect EBSCOhost Total\n\nNumber of papers 2097 65 133 2295\n\nTable 3 Second search string result\n\nScopus ScienceDirect EBSCOhost Total\n\nNumber of papers 196 27 92 315\n\nTable 4 Third Search string refinement result\n\nScopus ScienceDirect EBSCOhost Total\n\nNumber of papers 64 23 24 111\n\nTable 5 Final Selection\n\nScopus ScienceDirect EBSCOhost Total\n\nNumber of papers 25 10 12 47\n\n\n\nPage 9 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\nExclusion criteria\n\nPapers that belong to the following categories were excluded from selection as part of \nthe primary study: (i) papers written in source language other than English; (ii) papers \nwith an abstract and or introduction that does not clearly define the contributions of the \nwork; (iii) papers whose abstract do not relate to big data stream analysis.\n\nResult\nThe findings of the study are now presented with respect to the research questions that \nguided the execution of the systematic literature review.\n\nResearch Question 1: What are the tools and technologies employed for big data stream \n\nanalysis?\n\nBig data stream platforms provide functionalities and features that enable big data \nstream applications to develop, operate, deploy, and manage big data streams. Such \nplatforms must be able to pull in streams of data, process the data and stream it back \nas a single flow. Several tools and technologies have been employed to analyse big data \nstreams. In response to the growing demand for big data streaming analytics, a large \nnumber of alternative big data streaming solutions have been developed both by the \nopen source community and enterprise technology vendors. According to [26], there are \nsome factors to consider when selecting big data streaming tools and technologies in \norder to make effective data management decisions. These are briefly described below.\n\nShape of the data\n\nStreaming data sources require serialization technologies for capturing, storing and rep-\nresenting such high-velocity data. For instance, some tools and technologies allow pro-\njection of different structures across data stores, giving room for flexibility for storage \nand access of data in different ways. However, the performance of such platforms may \nnot be suitable for high-velocity data.\n\nData access\n\nThere is a need to put into consideration how the data will be accessed by users and \napplications. For instance, many NoSQL databases require specific application interfaces \nfor data access. Hence there is a need to consider the integration of some other neces-\nsary tools for data access.\n\nAvailability and consistency requirement\n\nIf a distributed system is needed, then CAP theorem states that consistency and avail-\nability cannot be both guaranteed in the presence of network partition (i.e. when there is \na break in the network). In such a scenario, consistency is often traded off for availability \nto ensure that requests can always be processed.\n\nWorkload profile required\n\nPlatform as a service deployment may be appropriate for a spike load profile platform. \nIf platform distribution can be deployed on Infrastructure as a service cloud, then this \noption may be preferred as users will need to pay only when processing. On-premise \n\n\n\nPage 10 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\ndeployment may be considered for predictable or consistent loads. But if workloads are \nmixed (i.e. consistent flows or spikes), a combination of cloud and on-premise approach \nmay be considered so as to give room for easy integration of web-based services or soft-\nware and access to critical functions on the go.\n\nLatency requirement\n\nIf a minimal delay or low latency is required, key-value stores may be considered or bet-\nter still, an in-memory solution which allows the process of large datasets in real-time is \nrequired in order to optimize the data loading procedure.\n\nThe tools and technologies for big data stream analysis can be broadly categorized into \ntwo, which are open source and proprietary solutions. These are listed in Tables 6 and 7.\n\nThe selection of big data streaming tools and technologies should be based on the impor-\ntance of each factor earlier mentioned in this section. Proprietary solutions may not be eas-\nily available because of pricing and licensing issues. While open source supports innovation \nand development at a large scale, careful selection must be made especially when choosing \na recent technology still in production due to limited maturity and lack of support from \nacademic researchers or developer communities. In addition, open source solutions may \nlead to outdating and modification challenges [27]. Moreover, the selection of whether pro-\nprietary or open source or combination of both should depend on the problem to address, \nthe understanding of the true costs, and benefits of both open and proprietary solutions.\n\nTable 6 Open source tools and technologies for big data stream analysis\n\nTools and technology Article\n\nBlockMon [83]\n\nNoSQL [4, 84–86]\n\nSpark streaming [67, 87–91]\n\nApache storm [68, 85, 86, 92–97]\n\nKafka [85, 91, 95, 96, 98]\n\nYahoo! S4 [6, 45, 87, 99]\n\nApache Samza [46, 67, 100]\n\nPhoton [67, 101]\n\nApache Aurora [67, 102]\n\nMavEStream [103]\n\nEsperTech [104, 105]\n\nRedis [106]\n\nC-SPARQL [107, 108]\n\nSAMOA [56, 78, 109]\n\nCQELS [108, 110, 111]\n\nETALIS [112]\n\nXSEQ [73]\n\nApache Kylin [113]\n\nSplunk stream [114]\n\n\n\nPage 11 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\nResearch Question 2: What methods and techniques are used in analysing big data \n\nstreams?\n\nGiven the real-time nature, velocity and volume of social media streams, the clus-\ntering algorithms that are applied on streaming data must be highly scalable and \nefficient. Also, the dynamic nature of data makes it difficult to know the required or \ndesirable number of clusters in advance. This renders partitioning clustering tech-\nniques (such as k-median, k-means and k-medoid) or expectation-maximization \n(EM) algorithms-based approaches unsuitable for analysing real-time social media \ndata because they require prior knowledge of clusters in advance. In addition, due \nto concept drift inherent in social media streams, scalable graph partitioning algo-\nrithms are not also suitable because of their tendency towards balanced partitioning. \nSocial media streams must be analysed dynamically in order to provide decisions at \nany given time within a limited space and time window [28–30].\n\nDensity-based clustering algorithm (such as DenStream, OpticStream, Flock-\nStream, Exclusive and Complete Clustering) unlike partitioning algorithms does not \nrequire apriori number of clusters in advance and can detect outliers [31]. However, \nthe issue with density-based clustering algorithms is that most of them except for few \nlike HDDStream, PreDeCon-Stream and PKS-Stream (which are memory intensive) \nperform less efficiently in the face of high dimensional data and as a result are not \nsuitable for analyzing social media streams [32].\n\nThreshold-based techniques, hierarchical clustering, and incremental clustering \nor online clustering are more relevant to social media analysis. Several online thresh-\nold-based stream clustering approaches or incremental clustering approaches such as \nMarkov Random Field [33, 34], Online Spherical K-means [35], and Condensed Clusters \n[36] have been adopted. Incremental approaches are suitable for continuously generated \ndata grouping by setting a maximum similarity threshold between the incoming stream \n\nTable 7 Proprietary tools and technologies for big data stream analysis\n\nTools and technology Article\n\nCodeBlue [115]\n\nAnodot [116]\n\nCloudet [117]\n\nSentiment brand monitoring [118]\n\nNumenta [119]\n\nElastic streaming processing engine [120]\n\nMicrosoft azure stream analytics [121]\n\nIBM InfoSphere streams [8, 122]\n\nGoogle MillWheel [123]\n\nArtemis [124]\n\nWSO2 analytics [125]\n\nMicrosoft StreamInsight [126]\n\nTIBCO StreamBase [127]\n\nStriim [128]\n\nKyvos insights [129]\n\nAtScale [130, 131]\n\nLambda architecture [57]\n\n\n\nPage 12 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\nand the existing clusters. Much work has been done in improving the efficiency of online \nclustering algorithms, however, little research efforts have been directed to threshold \nand fragmentation issues. Incremental algorithm threshold setting should employ adap-\ntive approach instead of relying on static values [37, 38]. Some of the methods and tech-\nniques that have been employed in analysing big data streams are outlined in Table 8.\n\nTable 8 Methods and techniques for big data stream analysis\n\nMethods and techniques Article\n\nSPADE [132]\n\nLocally supervised metric learning (LSML) [133]\n\nKTS [106]\n\nMultinomial latent dirichlet allocation [106]\n\nVoltage clustering algorithm [106]\n\nLocality sensitive hashing (LSH) [134]\n\nUser profile vector update algorithm [134]\n\nTag assignment stream clustering (TASC) [134]\n\nStreamMap [117]\n\nDensity cognition [117]\n\nQRS detection algorithm [87]\n\nForward chaining rule [110]\n\nStream [135]\n\nCluStream [136, 137]\n\nHPClustering [138]\n\nDenStream [139]\n\nD-Stream [140]\n\nACluStream [141]\n\nDCStream [142]\n\nP-Stream [143]\n\nADStream [144]\n\nContinuous query processing (CQR) [145]\n\nFPSPAN-growth [146]\n\nOutlier method for cloud computing algorithm (OMCA) [147]\n\nMulti-query optimization strategy (MQOS) [148]\n\nParallel K-means clustering [72]\n\nVisibly push down automata (VPA) [73]\n\nIncremental MI outlier detection algorithm (Inc I-MLOF) [149]\n\nAdaptive windowing based online ensemble (AWOE) [74]\n\nDynamic prime-number based security verification [84]\n\nK-anonymity, I-diversity, t-closeness [90]\n\nSingular spectrum matrix completion (SS-MC) [76]\n\nTemporal fuzzy concept analysis [96]\n\nECM-sketch [77]\n\nNearest neighbour [91]\n\nMarkov chains [91]\n\nBlock-QuickSort-AdjacentJobMatch [86]\n\nBlock-QuickSort-OverlapReplicate [86]\n\nFuzzy-CSar-AFP [150]\n\nWeighted online sequential extreme learning machine with kernels (WOS-ELMK) [22]\n\nConcept-adapting very fast decision tree (CVFDT) [151]\n\n\n\nPage 13 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\nMany researchers have looked at the aspect of the real-time analysis of big data \nstreams but not much attention has been directed towards social media stream pre-\nprocessing. For instance, the social media stream is characterized by incomplete, noisy, \nslang, abbreviated words. Also, contextual meaning of social media post is essential for \nimproved event detection, sentiment analysis or any other social media analytics algo-\nrithms in terms of quality and accuracy [36, 39]. There is the need to give more atten-\ntion to the preprocessing stage of social media stream analysis in the face of incomplete, \nnoisy, slang, and abbreviated words that are pertinent to social media streams. These \nchallenges create opportunities application of new semantic technology approaches, \nwhich are more suited to social media streams [40, 41].\n\nResearch Question 3: What do big data streaming tools and technologies have in common \n\nand their differences in terms of concept, purpose, and capabilities?\n\nThe features of various tools and technologies for big data stream were compared in \norder to answer this question. An overview analysis based on 10 dimensions, which are \ndatabase support, execution model, workload, fault-tolerance, latency, throughput, reli-\nability, operating system, implementation languages and application domain or areas is \npresented in Table 9.\n\nFor organisations with existing applications that have support for SQL, MySQL, SQL \nServer, Oracle Database, for instance, may consider choosing big data streaming tools \nand technologies that have support for their existing databases. There are few big data \nstreaming tools and technology that support virtually any data format. An example of \nsuch is Infochimps Cloud.\n\nThe major big data streaming tools and technologies considered are all suitable for \nstreaming execution model, however out of 19 big data tools and technology compared \nand contrasted in this section, only 10.5% is suitable for streaming, batch, and iterative \nprocessing while 47.4% can handle jobs requiring both batch and streaming processing. \nIt is safer for a job to be executed on a single platform which can accommodate all the \ndependencies required in order to avoid interoperability constraints than combining \ntwo or more platforms or frameworks. The best fit with respect to the choice of big data \nstreaming tools and technologies will depend on the state of data to process, infrastruc-\nture preference, business use case, and kind of results interested in.\n\nVirtually all the big data streaming tools and technologies are memory intensive. This \nimplies that the main performance bottleneck at higher load conditions will be due to \nlack of memory [42]. However, research has shown that the benefit of high intensive \nmemory applications outweighs the performance loss due to long memory latency [43].\n\nFrom all the big data streaming tools and technologies reviewed, only IBMInfoS-\nphere and TIBCO StreamBase support all of the three “at-most-once” “at-least-once” \nand “exactly-once” message delivery mechanisms while others support one or two of the \nthree delivery mechanisms. “At-most-once” is the cheapest with least implementation \noverhead and highest performance because it can be done in a fire-and-forget fashion \nwithout keeping the state in the transport mechanism or at the sending end. “At-least-\nonce” delivery requires multiple attempts in order to counter transport losses which \nmeans keeping the state at the sending end and having an acknowledgement mechanism \nat the receiving end. “Exactly-once” is the most expensive and has consequently worst \n\n\n\nPage 14 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\nTa\nbl\n\ne \n9 \n\nCo\nm\n\npa\nri\n\nso\nn \n\nof\n b\n\nig\n d\n\nat\na \n\nst\nre\n\nam\nin\n\ng \nto\n\nol\ns \n\nan\nd \n\nte\nch\n\nno\nlo\n\ngi\nes\n\nTo\nol\n\ns \nan\n\nd \nte\n\nch\nno\n\nlo\ngy\n\nD\nat\n\nab\nas\n\ne \nsu\n\npp\nor\n\nt\nEx\n\nec\nut\n\nio\nn \n\nm\nod\n\nel\nW\n\nor\nkl\n\noa\nd\n\nFa\nul\n\nt t\nol\n\ner\nan\n\nce\nLa\n\nte\nnc\n\ny\nTh\n\nro\nug\n\nhp\nut\n\nRe\nlia\n\nbi\nlit\n\ny\nO\n\npe\nra\n\ntin\ng \n\nsy\nst\n\nem\nIm\n\npl\nem\n\nen\nta\n\ntio\nn/\n\nsu\npp\n\nor\nte\n\nd \nla\n\nng\nua\n\nge\ns\n\nA\npp\n\nlic\nat\n\nio\nn\n\nBl\noc\n\nkM\non\n\nCa\nss\n\nan\ndr\n\na,\n M\n\non\n-\n\ngo\nD\n\nB,\n X\n\nM\nL\n\nSt\nre\n\nam\nin\n\ng\nM\n\nul\nti-\n\nsl\nic\n\ne \nm\n\nem\n-\n\nor\ny \n\nal\nlo\n\nca\ntio\n\nn \nan\n\nd \nba\n\ntc\nh \n\nal\nlo\n\nca\ntio\n\nns\n\nC\nhe\n\nck\npo\n\nin\nt, \n\nro\nllb\n\nac\nk\n\nVe\nry\n\n lo\nw\n\nH\nig\n\nh\nA\n\nt l\nea\n\nst\n o\n\nnc\ne\n\nLi\nnu\n\nx\nC\n\n +\n+\n\n11\n, P\n\nyt\nho\n\nn\nA\n\nno\nm\n\nal\ny \n\nde\nte\n\nct\nio\n\nn,\n \n\nne\ntw\n\nor\nk \n\nop\ntim\n\niz\na-\n\ntio\nn,\n\n m\nul\n\ntim\ned\n\nia\n \n\nco\nnt\n\nen\nt d\n\nel\niv\n\ner\ny,\n\n \nfin\n\nan\nci\n\nal\n m\n\nar\nke\n\nt \nan\n\nal\nys\n\nis\n, w\n\neb\n \n\nan\nal\n\nyt\nic\n\ns\n\nSp\nar\n\nk \nSt\n\nre\nam\n\nin\ng\n\nKa\nfk\n\na,\n H\n\nBa\nse\n\n, \nH\n\niv\ne \n\nFl\num\n\ne,\n \n\nH\nD\n\nF/\nS3\n\n, \nKi\n\nne\nsi\n\ns, \nTC\n\nP \nso\n\nck\net\n\ns, \nTw\n\nit-\nte\n\nr, \nSQ\n\nL\n\nBa\ntc\n\nh,\n It\n\ner\nat\n\niv\ne,\n\n \nSt\n\nre\nam\n\nin\ng\n\nC\nPU\n\n/m\nem\n\nor\ny \n\nin\nte\n\nns\niv\n\ne\nRD\n\nD\n b\n\nas\ned\n\n \nC\n\nhe\nck\n\n-p\noi\n\nnt\n-\n\nin\ng,\n\n p\nar\n\nal\nle\n\nl \nre\n\nco\nve\n\nry\n, \n\nre\npl\n\nic\nat\n\nio\nn\n\nLo\nw\n\nH\nig\n\nh\nEx\n\nac\ntly\n\n o\nnc\n\ne\nW\n\nin\ndo\n\nw\ns, \n\nm\nac\n\nO\nS,\n\n L\nin\n\nux\nSc\n\nal\na,\n\n P\nyt\n\nho\nn,\n\n \nJa\n\nva\n, R\n\nEv\nen\n\nt d\net\n\nec\ntio\n\nn,\n \n\nst\nre\n\nam\nin\n\ng \nm\n\nac\nhi\n\nne\n \n\nle\nar\n\nni\nng\n\n, f\nog\n\n c\nom\n\n-\npu\n\ntin\ng,\n\n in\nte\n\nra\nct\n\niv\ne \n\nan\nal\n\nys\nis\n\n, m\nul\n\ntim\ne-\n\ndi\na \n\nan\nal\n\nys\nis\n\n, c\nlu\n\nst\ner\n\n \nan\n\nal\nys\n\nis\n, fi\n\nlte\nrin\n\ng,\n \n\nre\n-p\n\nro\nce\n\nss\nin\n\ng,\n \n\nca\nch\n\ne \nin\n\nva\nlid\n\nat\nio\n\nn\n\nA\npa\n\nch\ne \n\nSt\nor\n\nm\nSp\n\nou\nt, \n\nH\nBa\n\nse\n, \n\nH\niv\n\ne,\n S\n\nQ\nL,\n\n \nCa\n\nss\nan\n\ndr\na,\n\n \nM\n\nem\nca\n\nch\ned\n\nSt\nre\n\nam\nin\n\ng\nC\n\nPU\n/m\n\nem\nor\n\ny \nin\n\nte\nns\n\niv\ne\n\nRe\npl\n\nic\nat\n\nio\nn,\n\n \nch\n\nec\nkp\n\noi\nnt\n\n, \nda\n\nta\n re\n\nco\nve\n\nry\n, \n\nU\nps\n\ntr\nea\n\nm\n \n\nba\nck\n\nup\n, \n\nre\nco\n\nrd\n-le\n\nve\nl \n\nac\nkn\n\now\nle\n\ndg\ne-\n\nm\nen\n\nt, \nst\n\nat\nel\n\nes\ns \n\nm\nan\n\nag\nem\n\nen\nt\n\nVe\nry\n\n lo\nw\n\nLo\nw\n\nA\nt l\n\nea\nst\n\n o\nnc\n\ne\nW\n\nin\ndo\n\nw\ns, \n\nm\nac\n\nO\nS,\n\n L\nin\n\nux\nC\n\nlo\nju\n\nre\n, J\n\nav\na,\n\n S\nca\n\nla\n, \n\nC\nlo\n\nju\nre\n\n, n\non\n\n-J\nVM\n\n \nla\n\nng\nua\n\nge\ns\n\nIn\nte\n\nrn\net\n\n o\nf t\n\nhi\nng\n\ns, \nst\n\nre\nam\n\nin\ng \n\nm\nac\n\nhi\nne\n\n \nle\n\nar\nni\n\nng\n, m\n\nul\ntim\n\ne-\ndi\n\na \nan\n\nal\nys\n\nis\n\nYa\nho\n\no!\n S\n\n4\nM\n\nyS\nQ\n\nL,\n N\n\noS\nQ\n\nL,\n \n\nRi\nch\n\n D\nat\n\na \nFo\n\nrm\nat\n\nSt\nre\n\nam\nin\n\ng\nC\n\nPU\n/m\n\nem\nor\n\ny \nin\n\nte\nns\n\niv\ne\n\nRe\npl\n\nic\nat\n\nio\nn,\n\n \nch\n\nec\nkp\n\noi\nnt\n\n, \nda\n\nta\n re\n\nco\nve\n\nry\n\nLo\nw\n\nLo\nw\n\nEx\nac\n\ntly\n o\n\nnc\ne\n\nLi\nnu\n\nx\nJa\n\nva\n, P\n\nyt\nho\n\nn,\n C\n+\n+\n\n, \nPe\n\nrl\nO\n\nnl\nin\n\ne \nan\n\nal\nyt\n\nic\ns, \n\nm\non\n\nito\nrin\n\ng,\n fr\n\nau\nd \n\nde\nte\n\nct\nio\n\nn,\n fi\n\nna\nnc\n\nia\nl \n\nda\nta\n\n p\nro\n\nce\nss\n\nin\ng,\n\n \nw\n\neb\n p\n\ner\nso\n\nna\nliz\n\na-\ntio\n\nn \nan\n\nd \nse\n\nss\nio\n\nn \nm\n\nod\nel\n\nlin\ng\n\n\n\nPage 15 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\nTa\nbl\n\ne \n9 \n\n(c\non\n\nti\nnu\n\ned\n)\n\nTo\nol\n\ns \nan\n\nd \nte\n\nch\nno\n\nlo\ngy\n\nD\nat\n\nab\nas\n\ne \nsu\n\npp\nor\n\nt\nEx\n\nec\nut\n\nio\nn \n\nm\nod\n\nel\nW\n\nor\nkl\n\noa\nd\n\nFa\nul\n\nt t\nol\n\ner\nan\n\nce\nLa\n\nte\nnc\n\ny\nTh\n\nro\nug\n\nhp\nut\n\nRe\nlia\n\nbi\nlit\n\ny\nO\n\npe\nra\n\ntin\ng \n\nsy\nst\n\nem\nIm\n\npl\nem\n\nen\nta\n\ntio\nn/\n\nsu\npp\n\nor\nte\n\nd \nla\n\nng\nua\n\nge\ns\n\nA\npp\n\nlic\nat\n\nio\nn\n\nA\npa\n\nch\ne \n\nSa\nm\n\nza\nKa\n\nfk\na,\n\n H\nD\n\nFS\n, \n\nKi\nne\n\nsi\ns, \n\nSt\nre\n\nam\n \n\nco\nns\n\num\ner\n\n, K\ney\n\n-\nva\n\nlu\ne \n\nst\nor\n\nes\n\nSt\nre\n\nam\nin\n\ng,\n b\n\nat\nch\n\n \npr\n\noc\nes\n\nsi\nng\n\nM\nem\n\nor\ny \n\nin\nte\n\nn-\nsi\n\nve\nC\n\nhe\nck\n\npo\nin\n\nt\nVe\n\nry\n lo\n\nw\nH\n\nig\nh\n\nA\nt l\n\nea\nst\n\n o\nnc\n\ne\nLi\n\nnu\nx,\n\n W\nin\n\ndo\nw\n\ns\nJa\n\nva\n, S\n\nca\nla\n\n, J\nVM\n\n \nla\n\nng\nua\n\nge\ns\n\nFi\nlte\n\nrin\ng,\n\n re\n-p\n\nro\n-\n\nce\nss\n\nin\ng,\n\n c\nac\n\nhe\n \n\nin\nva\n\nlid\nat\n\nio\nn\n\nA\npa\n\nch\ne \n\nFl\nin\n\nk\nKa\n\nfk\na,\n\n F\nlu\n\nm\ne,\n\n \nH\n\nD\nF/\n\nS3\n, \n\nKi\nne\n\nsi\ns, \n\nTC\nP \n\nso\nck\n\net\ns, \n\nTw\nit-\n\nte\nr, \n\nCa\nss\n\nan\ndr\n\na,\n \n\nRe\ndi\n\ns, \nM\n\non\n-\n\ngo\nD\n\nB,\n H\n\nBa\nse\n\n, \nSQ\n\nL\n\nSt\nre\n\nam\nin\n\ng,\n \n\nba\ntc\n\nh,\n it\n\ner\nat\n\niv\ne,\n\n \nin\n\nte\nra\n\nct\niv\n\ne\n\nM\nem\n\nor\ny \n\nin\nte\n\nn-\nsi\n\nve\nSt\n\nre\nam\n\n re\npl\n\nay\n \n\nan\nd \n\nm\nar\n\nke\nr-\n\nch\nec\n\nkp\noi\n\nnt\n\nVe\nry\n\n lo\nw\n\nH\nig\n\nh\nEx\n\nac\ntly\n\n o\nnc\n\ne\nLi\n\nnu\nx,\n\n M\nac\n\nO\nS,\n\n \nW\n\nin\ndo\n\nw\ns\n\nJa\nva\n\n, S\nca\n\nla\n, P\n\nyt\nho\n\nn\nO\n\npt\nim\n\niz\nat\n\nio\nn \n\nof\n \n\ne-\nco\n\nm\nm\n\ner\nce\n\n \nse\n\nar\nch\n\n re\nsu\n\nlt,\n \n\nne\ntw\n\nor\nk/\n\nse\nns\n\nor\n \n\nm\non\n\nito\nrin\n\ng \nan\n\nd \ner\n\nro\nr d\n\net\nec\n\ntio\nn,\n\n \nET\n\nL \nfo\n\nr b\nus\n\nin\nes\n\ns \nin\n\nte\nlli\n\nge\nnc\n\ne \nin\n\nfra\n-\n\nst\nru\n\nct\nur\n\ne,\n m\n\nac\nhi\n\nne\n \n\nle\nar\n\nni\nng\n\nA\npa\n\nch\ne \n\nA\nur\n\nor\na\n\nH\n2,\n\n Ja\nva\n\n m\nap\n\ns, \nM\n\nyB\nat\n\nis\n, \n\nM\nyS\n\nQ\nL,\n\n P\nos\n\nt-\ngr\n\neS\nQ\n\nL\n\nSt\nre\n\nam\nin\n\ng\nM\n\nem\nor\n\ny \nan\n\nd \ndi\n\nsk\n s\n\npa\nce\n\nPe\nrio\n\ndi\nc \n\nre\nco\n\nv-\ner\n\ny \nch\n\nec\nkp\n\noi\nnt\n\n \nan\n\nd \nro\n\nllb\nac\n\nk\n\nLo\nw\n\nH\nig\n\nh\nA\n\nt l\nea\n\nst\n o\n\nnc\ne\n\nLi\nnu\n\nx\nPy\n\nth\non\n\nM\non\n\nito\nrin\n\ng \nap\n\npl\nic\n\na-\ntio\n\nns\n s\n\nuc\nh \n\nas\n \n\nfin\nan\n\nci\nal\n\n a\nna\n\nly\nsi\n\ns \nan\n\nd \nm\n\nili\nta\n\nry\n a\n\npp\nli-\n\nca\ntio\n\nns\n\nRe\ndi\n\ns\nKe\n\ny-\nva\n\nlu\ne \n\nst\nor\n\nes\n, \n\nra\nbi\n\ntm\nq,\n\n M\non\n\n-\ngo\n\nD\nB\n\nSt\nre\n\nam\nin\n\ng\nIn\n\n-m\nem\n\nor\ny \n\nbu\nt \n\npe\nrs\n\nis\nte\n\nnt\n o\n\nn-\ndi\n\nsk\n d\n\nat\nab\n\nas\ne\n\nRe\npl\n\nic\na \n\nm\nig\n\nra\n-\n\ntio\nn,\n\n S\nen\n\ntin\nel\n\nLo\nw\n\nH\nig\n\nh\nA\n\nt l\nea\n\nst\n o\n\nnc\ne\n\nU\nbu\n\nnt\nu,\n\n L\nin\n\nux\n, \n\nO\nSX\n\nC\n, C\n\n#,\n Ja\n\nva\n, P\n\nH\nP, \n\nPy\nth\n\non\nW\n\neb\n a\n\nna\nly\n\nsi\ns, \n\nca\nch\n\ne,\n \n\nm\nes\n\nsa\nge\n\n q\nue\n\nue\ns\n\nC\n-S\n\nPA\nRQ\n\nL\nRD\n\nF, \nSQ\n\nLJ\n, \n\nN\noS\n\nQ\nL,\n\n H\nD\n\nF\nBa\n\ntc\nh,\n\n s\ntr\n\nea\nm\n\nin\ng\n\nLo\nw\n\n m\nem\n\nor\ny \n\nus\nag\n\ne\nA\n\nda\npt\n\nat\nio\n\nn\nVe\n\nry\n lo\n\nw\nH\n\nig\nh\n\nCu\nm\n\nul\nat\n\niv\ne\n\nW\nin\n\ndo\nw\n\ns, \nLi\n\nnu\nx,\n\n M\nac\n\nO\nS,\n\n \nA\n\nnd\nro\n\nid\n\nJa\nva\n\n, A\npa\n\nch\ne \n\nJe\nna\n\n \nlib\n\nra\nrie\n\ns\nRe\n\nal\n-t\n\nim\ne \n\nre\nas\n\non\nin\n\ng \nov\n\ner\n s\n\nen\nso\n\nr d\nat\n\na,\n \n\nso\nci\n\nal\n s\n\nem\nan\n\ntic\n \n\nda\nta\n\n, u\nrb\n\nan\n c\n\nom\n-\n\npu\ntin\n\ng\n\nSA\nM\n\nO\nA\n\nH\nBa\n\nse\n, H\n\niv\ne,\n\n C\nas\n\n-\nsa\n\nnd\nra\n\nSt\nre\n\nam\nin\n\ng\nLo\n\nw\n m\n\nem\nor\n\ny \nus\n\nag\ne\n\nU\nps\n\ntr\nea\n\nm\n \n\nba\nck\n\nup\nLo\n\nw\nH\n\nig\nh\n\nEx\nac\n\ntly\n o\n\nnc\ne\n\nLi\nnu\n\nx\nJa\n\nva\nC\n\nla\nss\n\nifi\nca\n\ntio\nn,\n\n c\nlu\n\nst\ner\n\n-\nin\n\ng,\n s\n\npa\nm\n\n d\net\n\nec\n-\n\ntio\nn,\n\n re\ngr\n\nes\nsi\n\non\n, \n\nfre\nqu\n\nen\nt p\n\nat\nte\n\nrn\n \n\nm\nin\n\nin\ng\n\n\n\nPage 16 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\nTa\nbl\n\ne \n9 \n\n(c\non\n\nti\nnu\n\ned\n)\n\nTo\nol\n\ns \nan\n\nd \nte\n\nch\nno\n\nlo\ngy\n\nD\nat\n\nab\nas\n\ne \nsu\n\npp\nor\n\nt\nEx\n\nec\nut\n\nio\nn \n\nm\nod\n\nel\nW\n\nor\nkl\n\noa\nd\n\nFa\nul\n\nt t\nol\n\ner\nan\n\nce\nLa\n\nte\nnc\n\ny\nTh\n\nro\nug\n\nhp\nut\n\nRe\nlia\n\nbi\nlit\n\ny\nO\n\npe\nra\n\ntin\ng \n\nsy\nst\n\nem\nIm\n\npl\nem\n\nen\nta\n\ntio\nn/\n\nsu\npp\n\nor\nte\n\nd \nla\n\nng\nua\n\nge\ns\n\nA\npp\n\nlic\nat\n\nio\nn\n\nCQ\nEL\n\nS\nRD\n\nF, \nSQ\n\nLJ\n, \n\nN\noS\n\nQ\nL,\n\n H\nD\n\nF\nBa\n\ntc\nh,\n\n s\ntr\n\nea\nm\n\nin\ng\n\nIn\n-m\n\nem\nor\n\ny\nA\n\nda\npt\n\nat\nio\n\nn\nLo\n\nw\nH\n\nig\nh\n\nCu\nm\n\nul\nat\n\niv\ne\n\nW\nin\n\ndo\nw\n\ns, \nLi\n\nnu\nx,\n\n M\nac\n\nO\nS,\n\n \nA\n\nnd\nro\n\nid\n\nJa\nva\n\nRe\nal\n\n-t\nim\n\ne \nre\n\nas\non\n\nin\ng \n\nov\ner\n\n s\nen\n\nso\nr d\n\nat\na,\n\n \nso\n\nci\nal\n\n s\nem\n\nan\ntic\n\n \nda\n\nta\n, u\n\nrb\nan\n\n c\nom\n\n-\npu\n\ntin\ng\n\nET\nA\n\nLI\nS\n\nRD\nF\n\nSt\nre\n\nam\nin\n\ng\nBi\n\nna\nriz\n\nat\nio\n\nn\nA\n\nda\npt\n\nat\nio\n\nn\nLo\n\nw\nLo\n\nw\nCu\n\nm\nul\n\nat\niv\n\ne\nW\n\nin\ndo\n\nw\ns, \n\nLi\nnu\n\nx,\n M\n\nac\nO\n\nS,\n \n\nA\nnd\n\nro\nid\n\nPr\nol\n\nog\n, J\n\nav\na,\n\n C\n, \n\nSP\nA\n\nRQ\nL,\n\n C\n#,\n\n \nET\n\nA\nLI\n\nS \nLa\n\nng\nua\n\nge\n \n\nfo\nr E\n\nve\nnt\n\ns \n(E\n\nLE\n)\n\nEv\nen\n\nt d\net\n\nec\ntio\n\nn,\n \n\nre\nas\n\non\nin\n\ng \nov\n\ner\n \n\nst\nre\n\nam\nin\n\ng \nev\n\nen\nts\n\nXS\nEQ\n\nXM\nL\n\nBa\ntc\n\nh,\n s\n\ntr\nea\n\nm\nin\n\ng\nIn\n\n-m\nem\n\nor\ny \n\nw\nith\n\n \nbu\n\nffe\nrin\n\ng\nch\n\nec\nkp\n\noi\nnt\n\nLo\nw\n\nH\nig\n\nh\nA\n\nt l\nea\n\nst\n o\n\nnc\ne\n\nW\nin\n\ndo\nw\n\ns, \nLi\n\nnu\nx\n\nJa\nva\n\n, A\npa\n\nch\ne \n\nXe\nrc\n\nes\nBi\n\nol\nog\n\nic\nal\n\n d\nat\n\na,\n s\n\noc\nia\n\nl \nne\n\ntw\nor\n\nks\n, u\n\nse\nr \n\nbe\nha\n\nvi\nou\n\nr, \nfin\n\nan\nci\n\nal\n \n\nda\nta\n\n a\nna\n\nly\nsi\n\ns, \nfil\n\nte\nrin\n\ng\n\nIB\nM\n\n In\nfo\n\nSp\nhe\n\nre\n \n\nst\nre\n\nam\ns\n\nPi\ng,\n\n H\niv\n\ne,\n Ja\n\nql\n, \n\nH\nBa\n\nse\n F\n\nlu\nm\n\ne,\n \n\nLu\nce\n\nne\n, A\n\nvr\no,\n\n \nZo\n\noK\nee\n\npe\nr, \n\nO\noz\n\nie\n, O\n\nra\ncl\n\ne \nD\n\nat\nab\n\nas\ne,\n\n \nD\n\nB2\n, N\n\net\nez\n\nza\n, \n\nM\nyS\n\nQ\nL,\n\n A\nst\n\ner\n, \n\nIn\nfo\n\nrm\nix\n\n.\n\nSt\nre\n\nam\nin\n\ng\nCa\n\npt\nur\n\ne \nda\n\nta\nba\n\nse\n \n\nw\nor\n\nkl\noa\n\nds\n a\n\nnd\n \n\nre\npl\n\nay\n th\n\nem\n in\n\n \na \n\nte\nst\n\n d\nat\n\nab\nas\n\ne \nen\n\nvi\nro\n\nnm\nen\n\nt\n\nA\nut\n\nom\nat\n\nic\n \n\nre\nco\n\nve\nry\n\nLo\nw\n\nH\nig\n\nh\nEx\n\nac\ntly\n\n o\nnc\n\ne,\n \n\nA\nt l\n\nea\nst\n\n \non\n\nce\n, A\n\nt \nm\n\nos\nt o\n\nnc\ne\n\nLi\nnu\n\nx,\n C\n\nen\ntO\n\nS\nC\n\n +\n+\n\nJa\nva\n\nSP\nL\n\nSp\nac\n\ne \nw\n\nea\nth\n\ner\n p\n\nre\n-\n\ndi\nct\n\nio\nn,\n\n p\nhy\n\nsi\nol\n\nog\ni-\n\nca\nl d\n\nat\na \n\nst\nre\n\nam\ns \n\nan\nal\n\nys\nis\n\n, t\nra\n\nffi\nc \n\nm\nan\n\nag\nem\n\nen\nt, \n\nre\nal\n\n-\ntim\n\ne \npr\n\ned\nic\n\ntio\nns\n\n, \nev\n\nen\nt d\n\net\nec\n\ntio\nn,\n\n \nvi\n\nsu\nal\n\nis\nat\n\nio\nn\n\nG\noo\n\ngl\ne \n\nM\nill\n\n-\nW\n\nhe\nel\n\nBi\ngT\n\nab\nle\n\n, S\npa\n\nn-\nne\n\nr\nSt\n\nre\nam\n\nin\ng\n\nIn\n-m\n\nem\nor\n\ny \nan\n\nd \nbl\n\noo\nm\n\n fi\nlte\n\nrin\ng\n\nU\nnc\n\noo\nrd\n\nin\nat\n\ned\n \n\npe\nrio\n\ndi\nc,\n\n \nch\n\nec\nkp\n\noi\nnt\n\n, \nup\n\nst\nre\n\nam\n \n\nba\nck\n\nup\n\nLo\nw\n\nH\nig\n\nh\nEx\n\nac\ntly\n\n o\nnc\n\ne\nLi\n\nnu\nx\n\nVi\nrt\n\nua\nlly\n\n a\nny\n\n \npr\n\nog\nra\n\nm\nm\n\nin\ng \n\nla\nng\n\nua\nge\n\nA\nno\n\nm\nal\n\ny \nde\n\nte\nct\n\nio\nn,\n\n \nhe\n\nal\nth\n\n m\non\n\nito\nrin\n\ng,\n \n\nim\nag\n\ne \npr\n\noc\nes\n\nsi\nng\n\n, \nne\n\ntw\nor\n\nk \nsw\n\nitc\nh \n\nm\nan\n\nag\nem\n\nen\nt\n\n\n\nPage 17 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\nTa\nbl\n\ne \n9 \n\n(c\non\n\nti\nnu\n\ned\n)\n\nTo\nol\n\ns \nan\n\nd \nte\n\nch\nno\n\nlo\ngy\n\nD\nat\n\nab\nas\n\ne \nsu\n\npp\nor\n\nt\nEx\n\nec\nut\n\nio\nn \n\nm\nod\n\nel\nW\n\nor\nkl\n\noa\nd\n\nFa\nul\n\nt t\nol\n\ner\nan\n\nce\nLa\n\nte\nnc\n\ny\nTh\n\nro\nug\n\nhp\nut\n\nRe\nlia\n\nbi\nlit\n\ny\nO\n\npe\nra\n\ntin\ng \n\nsy\nst\n\nem\nIm\n\npl\nem\n\nen\nta\n\ntio\nn/\n\nsu\npp\n\nor\nte\n\nd \nla\n\nng\nua\n\nge\ns\n\nA\npp\n\nlic\nat\n\nio\nn\n\nIn\nfo\n\nch\nim\n\nps\n \n\ncl\nou\n\nd\nSQ\n\nL,\n N\n\noS\nQ\n\nL,\n \n\nH\niv\n\ne,\n P\n\nig\n \n\nW\nuk\n\non\ng,\n\n \nH\n\nad\noo\n\np,\n \n\nRD\nBM\n\nS,\n V\n\nirt\nu-\n\nal\nly\n\n a\nny\n\n d\nat\n\na \nfo\n\nrm\nat\n\nBa\ntc\n\nh,\n s\n\ntr\nea\n\nm\nin\n\ng\nIn\n\n-m\nem\n\nor\ny\n\nU\nps\n\ntr\nea\n\nm\n \n\nba\nck\n\nup\nLo\n\nw\nH\n\nig\nh\n\nEx\nac\n\ntly\n o\n\nnc\ne\n\nLi\nnu\n\nx\nJa\n\nva\nD\n\nis\nas\n\nte\nr d\n\nis\nco\n\nve\nry\n\n, \nte\n\nxt\n a\n\nna\nly\n\nsi\ns, \n\nco\nm\n\n-\npl\n\nex\n e\n\nve\nnt\n\n p\nro\n\nce\nss\n\n-\nin\n\ng,\n v\n\nis\nua\n\nlis\nat\n\nio\nn\n\nM\nic\n\nro\nso\n\nft\n \n\nSt\nre\n\nam\nIn\n\nsi\ngh\n\nt\nSQ\n\nL \nSe\n\nrv\ner\n\nSt\nre\n\nam\nin\n\ng\nIn\n\n-m\nem\n\nor\ny\n\nRe\npl\n\nic\nat\n\nio\nn,\n\n \nch\n\nec\nkp\n\noi\nnt\n\n, \nda\n\nta\n re\n\nco\nve\n\nry\n\nVe\nry\n\n lo\nw\n\nH\nig\n\nh\nEx\n\nac\ntly\n\n o\nnc\n\ne\nW\n\nin\ndo\n\nw\ns\n\n.N\nET\n\n, C\n#,\n\n L\nIN\n\nQ\n, R\n\nx\nM\n\nan\nuf\n\nac\ntu\n\nrin\ng \n\npr\noc\n\nes\ns \n\nm\non\n\nito\nr-\n\nin\ng \n\nan\nd \n\nco\nnt\n\nro\nl, \n\nfin\nan\n\nci\nal\n\n d\nat\n\na \nan\n\nal\nys\n\nis\n, o\n\npe\nra\n\n-\ntio\n\nn \nan\n\nal\nyt\n\nic\ns, \n\nw\neb\n\n \nan\n\nal\nyt\n\nic\ns, \n\nev\nen\n\nt \npa\n\ntt\ner\n\nn \nde\n\nte\nct\n\nio\nn\n\nTI\nBC\n\nO\n S\n\ntr\nea\n\nm\n-\n\nBa\nse\n\nO\nra\n\ncl\ne \n\nda\nta\n\nba\nse\n\n, \nSQ\n\nL \nSe\n\nrv\ner\n\n, \nIm\n\npa\nla\n\nBa\ntc\n\nh,\n S\n\ntr\nea\n\nm\nin\n\ng\nIn\n\n-m\nem\n\nor\ny\n\nSy\nnc\n\nhr\non\n\niz\nat\n\nio\nn,\n\n \nre\n\npl\nic\n\nat\nio\n\nn,\n \n\nro\nllb\n\nac\nk\n\nVe\nry\n\n lo\nw\n\nH\nig\n\nh\nA\n\nt l\nea\n\nst\n o\n\nnc\ne/\n\nat\n m\n\nos\nt \n\non\nce\n\n/\nex\n\nac\ntly\n\n o\nnc\n\ne\n\nW\nin\n\ndo\nw\n\ns, \nM\n\nac\nO\n\nS,\n L\n\nin\nux\n\nR,\n Ja\n\nva\nM\n\nis\nsi\n\non\n c\n\nrit\nic\n\nal\n \n\nan\nal\n\nys\nis\n\n, I\noT\n\n a\nna\n\nly\n-\n\nsi\ns, \n\ncl\nic\n\nk-\nst\n\nre\nam\n\n \nan\n\nal\nys\n\nis\n, p\n\nre\ndi\n\nct\niv\n\ne \nan\n\nal\nyt\n\nic\ns, \n\nw\nor\n\nkfl\now\n\n \nop\n\ntim\niz\n\nat\nio\n\nn,\n ri\n\nsk\n \n\nav\noi\n\nda\nnc\n\ne\n\nLa\nm\n\nbd\na \n\nA\nrc\n\nhi\n-\n\nte\nct\n\nur\ne\n\nRD\nBM\n\nS,\n C\n\nas\nsa\n\nn-\ndr\n\na,\n K\n\naf\nka\n\n, D\nat\n\na \nW\n\nar\neh\n\nou\nse\n\ns, \nKi\n\nne\nsi\n\ns \nD\n\nat\na \n\nSt\nre\n\nam\n, H\n\nD\nFS\n\n, \nH\n\nBa\nse\n\nBa\ntc\n\nh,\n S\n\ntr\nea\n\nm\nin\n\ng\nIn\n\n-m\nem\n\nor\ny/\n\ndi\nsk\n\n \nda\n\nta\nba\n\nse\nRe\n\npl\nic\n\nat\nio\n\nn,\n \n\nch\nec\n\nkp\noi\n\nnt\nLo\n\nw\nLo\n\nw\nEx\n\nac\ntly\n\n o\nnc\n\ne\nU\n\nbu\nnt\n\nu,\n W\n\nin\n-\n\ndo\nw\n\ns, \nLi\n\nnu\nx\n\nJa\nva\n\n, C\n#,\n\n P\nyt\n\nho\nn,\n\n \nPi\n\ng \nLa\n\ntin\nIo\n\nT \nan\n\nal\nys\n\nis\n, t\n\nra\nck\n\nin\ng \n\nre\nal\n\n-t\nim\n\ne \nup\n\nda\nte\n\ns, \nfin\n\nan\nci\n\nal\n ri\n\nsk\n m\n\nan\n-\n\nag\nem\n\nen\nt, \n\ncl\nic\n\nk-\nst\n\nre\nam\n\n a\nna\n\nly\nsi\n\ns\n\n\n\nPage 18 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\nperformance because, in addition to “at-least-once” delivery mechanism, it requires the \nstate to be kept at the receiving end in order to filter duplicate deliveries. In other words, \n“at-most-once” delivery mechanism implies that the message may be lost while “at-\nleast-once” delivery ensures that messages are not lost and “exactly-once” implies that \nmessage can neither be lost nor duplicated. “Exactly-once” is suitable for many critical \nsystems where duplicate messages are unacceptable.\n\nResearch Question 4: What are the limitations and strengths of big data streaming tools \n\nand technologies?\n\nObservations from the literature reveal that specific big data streaming technology may \nnot provide the full set of features that are required. It is rare to find specific big data \ntechnology that combines key features such as scalability, integration, fault-tolerance, \ntimeliness, consistency, heterogeneity and incompleteness management, and load bal-\nancing. For instance, Spark streaming [16] and Sonora [44] are excellent and efficient \nfor checkpointing but the operator space available to user codes are limited. S4 does not \nguarantee 100% fault-tolerant persistent state [45]. Storm does not guarantee the order-\ning of messages due to its “at-least-once” mechanism for record delivery [46, 47]. Strict \ntransaction ordering is required by Trident to operate [48]. While streaming SQL pro-\nvide simple and succinct solutions to many streaming problems, the complex application \nlogic (such as matrix multiplication) and intuitive state abstractions are expressed with \nthe operational flow of an imperative language rather than a declarative language such as \nSQL [49–51].\n\nMoreover, BlockMon uses batches and cache locality optimization techniques for \nmemory allocation efficiency and data speed up access. However, deadlock may occur \nif data streams are enqueued with a higher rate than that of the block consumption [52]. \nApache Samza solves batch latency processing problems but requires an added layer for \nflow control [53]. Flink is suitable for heavy stream processing and batch-oriented tasks \nalthough it has scaling limitations [46]. Redis’ in-memory data store makes it extremely \nfast although this implies that available memory size determines the size of the Redis \ndata store [54]. While C-SPARQL and CQELS are excellent for combining static and \nstreaming data, they are not suitable when scalability is required [55]. SAMOA is suit-\nable for machine learning paradigm as it focuses on speed/real-time analytics, scales \nhorizontally and is loosely coupled with its underlying distributed computation platform \n[56]. With Lambda architecture, a real-time layer can complement the batch processing \none thereby reducing maintenance overhead and risk for errors as a result of duplicate \ncode bases. In addition, Lambda architecture handles reprocessing, which is one of the \nkey challenges in stream processing. Two main problems with Lambda architecture are \ncode maintenance in two complex distributed systems that need to produce the same \nresult and high operational complexity [57, 58].\n\nSummarily, there exists various tools and technologies for implementing big data \nstreams and there seems to be no big data streaming tool and technology that offers all \nthe key features required for now. While each tool and technology may have its strengths \nand weaknesses, the choice depends on the objective of the research and data availa-\nbility. A decision in favour of the wrong technology may result in increased overhead \ncost and time. The decision should take into consideration empirical analysis along with \n\n\n\nPage 19 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\nsystem requirements. In addition, research efforts should also be directed to how to \nimprove on existing big data streaming tools and technologies to provide key features \nsuch as scalability, integration, fault-tolerance, timeliness, consistency, heterogeneity \nand incompleteness management, and load balancing.\n\nResearch Question 5: What are the evaluation techniques or benchmarks that are used \n\nfor evaluating big data streaming tools and technologies?\n\nThe diversity of big data poses a challenge when it comes to developing big data bench-\nmarks that will be suitable for all workload cases. One cannot stick to one big data \nbenchmark because it has been observed that using only one benchmark on differ-\nent data sets do not give the same result. This implies that benchmark testing should \nbe application specific. Subsequently, in evaluating big data system, the identification \nof workload for an application domain is a prerequisite [59]. Most of the existing big \ndata benchmarks are designed to evaluate a specific type of systems or architectures. For \ninstance, HiBench [60] is suitable for benchmarking Hadoop, Spark and streaming work-\nloads, GridMix [61] and PigMix [62] are for MapReduce Hadoop systems. BigBench [63, \n64] is suitable for benchmarking Teradata Aster DBMS, MapReduce systems, Redshift \ndatabase, Hive, Spark and Impala. Presently, BigDataBench [65, 66] seems to be the only \nbig data benchmark that can evaluate a hybrid of different big data systems.\n\nSo far, many researchers have evaluated their work by making use of synthetic and \nreal-life data. Standard benchmark dataset for big data streaming analytics has not been \nwidely adopted. However, few of the researchers that used standardized benchmarking \nare briefly discussed below. The work of [67] was tested with two benchmarks; Word \nCount and Grep. The result showed that the proposed algorithm can effectively handle \nunstable input and the delay of the total event can be limited to an expected range.\n\nThe tool developed by [68] was tested on both car dataset and Wikinews5 dataset in \ncomparison with sequential processing. It was discovered that their tool (pipeline imple-\nmentation) performed better and faster.\n\nKrawczyk and Wozniak used several benchmark datasets which include Breast-Wis-\nconsin, Pima, Yeast3, Voting records, CYP2C19 isoform, RBF for estimating weights for \nthe new incoming data stream with their proposed method against other standard meth-\nods. They also analysed time and memory requirements. Experimental investigation \nresult proved that the proposed method can achieve better [69].\n\nA benchmark evaluation using an English movie review dataset collected from Rotten \nTomatoes website (a de facto benchmark for analysing sentiment applications) was con-\nducted by [70], the result showed that sentiment analysis engine (SAE) proposed by the \nauthors outperformed the bag of words approach.\n\nAuthors’ suite of ideas in [71] outperformed state-of-the-art searching technique \ncalled EBSM. The work of [72] used various datasets such as KDD-Cup 99, Forest Cover \ntype, Household power consumption, etc. They compared their algorithm—parallel \nK-means clustering with k-means and k-means++, the result showed that their algo-\nrithm performed better in terms of speed.\n\n5 http://en.wikin ews.org.\n\nhttp://en.wikinews.org\n\n\nPage 20 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\nMozafari et al. in [73] benchmarked their system, XSeq against other general-purpose \nXML engines. The system outperformed other complex event processing engines by two \norders of magnitude improvement.\n\nAuthors in [74] evaluated their work in terms of time, accuracy and memory using \nForest cover type, Poker hand, and electricity datasets. They compared their method, \nadaptive windowing based online ensemble (AWOE) with other standard methods such \nas accuracy updated ensemble (AUE), online accuracy updated ensemble (OAUE), accu-\nracy weighted ensemble (AWE), dynamic weighted majority (DWM) and Lev Bagging \n(Lev). Their proposed approach outperformed other methods in three perspectives \nwhich include suitability in terms of different type of drifts, better resolved appropriate \nsize of block, and efficiency.\n\nThe evaluation performed by [75] using FACup and Super Tuesday datasets showed \nthat their method, which is a hybrid of topic extraction methods (i.e. a combination of \nfeature pivot and document pivot) has high efficiency and accuracy with respect to recall \nand precision.\n\nEvaluating the performance of low-rank reconstruction and prediction scheme, spe-\ncifically, singular spectrum matrix completion (SS-MC) proposed by [76], SensorScope \nGrand St-Bernard dataset6 and Intel Berkeley Research Lab dataset7 were used. The \nauthors compared their proposed method with three state-of-the-art methods; KNN-\nimputation, RegEM and ADMM version of MC and discovered that their method \noutperformed the other methods in terms of pure reconstruction as well as in the \ndemanding case of simultaneous recovery and prediction.\n\nThe authors in [77] evaluated their work using World Cup 1998 and CAIDA \nAnonymized Internet Traces 2011 datasets. When their method, ECM-Sketch (a sketch \nsynopsis that allows effective summarization of streaming data over both time-based \nand count-based sliding windows) was compared with three state-of-the-art algorithms \n(Sketch variants); ECM-RW, ECM-DW, and ECM-EH, variants using randomized waves, \ndeterministic waves and exponential histograms respectively, their method reduce \nmemory and computational requirements by at least one order of magnitude with a very \nsmall loss in accuracy.\n\nThe work of [78] centred on benchmarking real-time vehicle data streaming models \nfor a smart city using a simulator that emulates the data produced by a given amount of \nsimultaneous drivers. Experiment with the simulator shows that streaming processing \nengine such as Apache Kafka could serve as a replacement to custom-made streaming \nservers to achieve low latency and higher scalability together with cost reduction.\n\nA benchmark among Kyvos Insight, Impala and Spark conducted by [79] shows that \nKyvos Insight performed analytical queries with much lower latencies when there is a \nlarge number of concurrent users due to pre-aggregation and incremental code building \n[80].\n\nAuthors in [81] proposed that in addition to execution time and resource utilization, \nmicroarchitecture-level and energy consumption are key to fully understanding the \nbehaviour of big data frameworks.\n\n6 http://lcav.epfl.ch.page-86035 -en.html.\n7 http://db.csail .mit.edu/labda ta/labda ta.html.\n\nhttp://lcav.epfl.ch.page-86035-en.html\nhttp://db.csail.mit.edu/labdata/labdata.html\n\n\nPage 21 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\nIn addition, to strengthen the confidence of big data research evaluation or result, \napplication of empirical methods (i.e. tested or evaluated concept or technology for \nevidence-based result) should be highly encouraged. The current status of empirical \nresearch in big data stream analysis is still at an infant stage. The maturity of a research \nfield is directly proportional to the number of publications with empirical result [20, 21]. \nAccording to [21] that conducted a systematic literature mapping to verify the current \nstatus of empirical research in big data, it was found out that only 151 out of 1778 stud-\nies contained empirical result. As a result, more research efforts should be directed to \nempirical research in order to raise the level of confidence of big data research outputs \nthan it is at present.\n\nMoreover, only a few big data benchmarks are suitable for different workloads at pre-\nsent. Research efforts should be geared towards advancing benchmarks that are suitable \nfor evaluating different big data systems. This would go a long way to reduce cost and \ninteroperability issue.\n\nDiscussion\nFrom the analysis, it was observed that there has been a wave of interest in big data \nstream analysis since 2013. The number of papers produced in 2012 was doubled in \n2013. In the same vein, more than double of the papers in 2013 were produced in 2014. \nThere was a relative surge in 2017 having a total of 98 paper while the year 2018 received \n156 papers (see Tables 9, 10 and Fig. 2). The percentage of papers analyzed from journals \nwas 50%; that of conferences was 41% while that of workshop/technical/symposium was \n9% as depicted in Fig. 3. Figure 4 presented the frequency of research efforts from differ-\nent geographical locations with researchers from China taking the lead.   \n\nThe selection of big data streaming tools and technologies should be based on the \nimportance of each of the factors such as the shape of the data, data access, availabil-\nity and consistent requirements, workload profile required, and latency requirement. \nCareful selection with respect to open source technology must be made especially when \nchoosing a recent technology still in production. Moreover, the problem to address, the \nunderstanding of the true costs, and benefits of both open and proprietary solutions are \nalso vital when making a selection.\n\nA lot of research efforts have been directed to big data stream analysis but social media \nstream preprocessing is still an open issue. Due to inherent characteristics of social \nmedia stream which include incomplete, noisy, slang, abbreviated words, social media \nstreams present a challenge to big data streams analytics algorithms. There is the need \nto give more attention to the preprocessing stage of social media stream analysis in the \nface of incomplete, noisy, slang, and abbreviated words that are pertinent to social media \nstreams in order to improve big data streams analytics result.\n\nOut of 19 big data streaming tools and technologies compared, 100% support stream-\ning, 47.4% can do both batch and streaming processing while only 10.5% support stream-\ning, batch and iterative processing. Depending on the state of the data to be processed, \ninfrastructure preference, business use case, and kind of results that is of interest, choos-\ning a single big data streaming technology platform that supports all the system require-\nments minimizes the effect of interoperability constraints.\n\n\n\nPage 22 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\nFrom all the big data streaming tools and technologies reviewed, only IBMInfoS-\nphere and TIBCO StreamBase support all of the three “at-most-once”, “at-least-once”, \nand “exactly-once” message delivery mechanisms while others support one or two of \nthe three delivery mechanisms. Having all the three delivery mechanisms give room for \nflexibility.\n\nIt is rare to find a specific big data technology that combines key features such as scal-\nability, integration, fault-tolerance, timeliness, consistency, heterogeneity and incom-\npleteness management, and load balancing. There seems to be no big data streaming \ntool and technology that offers all the key features required for now. This calls for more \nresearch efforts that are directed to building more robust big data streaming tools and \ntechnologies.\n\nFew big data benchmarks are suitable for a hybrid of big data systems at present and \nstandard benchmark datasets for big data streaming analytics have not been widely \nadopted. Hence, research efforts should be geared towards advancing benchmarks that \nare suitable for evaluating different big data systems.\n\nLimitation of the review\nWhile authors explored Scopus, ScienceDirect and EBSCO databases which index high \nimpact journals and conference papers from IEEE, ACM, SpringerLink, and Elsevier to \nidentify all possible relevant articles, it is possible that some other relevant articles from \nother databases such as Web of Science could have been missed.\n\nThe analysis and synthesis are based on interpretation of selected articles by the \nresearch team. The authors attempted to avoid this by cross-checking papers to deal \nwith bias though that cannot completely rule out the possibility of errors. In addition, \nthe authors implemented the inclusion and exclusion criteria in the selection of articles \nand only relevant articles written in the English Language were selected. Building on the \nunderpinning of the findings of the research, while a lot of research has been done with \nrespect to tools and technologies as well as methods and techniques employed in big \ndata streaming analytics, method of evaluation or benchmarks of the technologies of \nvarious workloads for big data streaming analytics have not received much attention. As \nit could be gathered from the literature reviewed that most of the researchers evaluated \ntheir work using either synthetic or real-life datasets.\n\nConclusion and further work\nAs a result of challenges and opportunities presented by the Information Technology \nrevolution, big data streaming analytics has emerged as the new frontier of competition \nand innovation. Organisations who seize the opportunity of big data streaming analytics \nare provided with insights for robust decision making in real-time thereby making them \nto have an edge over their competitors.\n\nIn this paper, the authors have tried to present a holistic view of big data streaming \nanalytics by conducting a comprehensive literature review to understand and identify \nthe tools and technologies, methods and techniques, benchmarks or methods of evalu-\nation employed, and key issues in big data stream analysis to showcase the signpost of \nfuture research directions.\n\n\n\nPage 23 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\nTa\nbl\n\ne \n10\n\n D\nis\n\ntr\nib\n\nut\nio\n\nn \nof\n\n p\nap\n\ner\ns \n\nov\ner\n\n th\ne \n\nst\nud\n\nie\nd \n\nye\nar\n\ns\n\nYe\nar\n\n20\n04\n\n20\n05\n\n20\n06\n\n20\n07\n\n20\n08\n\n20\n09\n\n20\n10\n\n20\n11\n\n20\n12\n\n20\n13\n\n20\n14\n\n20\n15\n\n20\n16\n\n20\n17\n\n20\n18\n\nTo\nta\n\nl\n\nPa\npe\n\nr\n2\n\n1\n2\n\n3\n5\n\n2\n5\n\n4\n5\n\n10\n22\n\n28\n38\n\n98\n15\n\n6\n38\n\n1\n\n\n\nPage 24 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\nAlthough a lot of research efforts have been directed towards big data at rest (i.e. \nbig data batch processing), there has been increased interest in analysing big data \nin motion (i.e. big data stream processing). With respect to issues identified in this \npaper, big data streaming analytics can be considered as an emerging phenomenon \nalthough some countries and industries have seized the opportunities by making it a \n\nFig. 2 Magnitude of change in paper distribution. The figure shows the magnitude of change in paper \ndistribution over the studied years (i.e. 2004 to 2018)\n\nFig. 3 Percentage of publication type. The figure shows percentage of 381 papers from journals (50%), \nconferences (41%), and workshop/technical/symposium (9%)\n\nFig. 4 Frequency of researchers across different. The figure presented the frequency of research \ngeographical locations research efforts from different geographical locations\n\n\n\nPage 25 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\npertinent research area. Some of the key issues such as scalability, integration, fault-\ntolerance, timeliness, consistency, heterogeneity and incompleteness, load balancing, \nhigh throughput, and privacy that require further research attention were identified. \nWhile researchers have invested a lot of efforts to mitigate these issues, scalability, \nprivacy and load balancing remain a concern. In addition, researchers also need to \ngive more focus to the empirical analysis of big data streaming tools and technologies \nin order to be able to provide concrete reasons and support for choosing a tool/tech-\nnology based on empirical evidence.\n\nPresently, BigDataBench seems to be the only big data benchmark that can evaluate \na hybrid of different big data systems. Standard benchmark for a hybrid of big data sys-\ntems has not been widely adopted. It is rare to find a specific big data technology that \ncombines key features such as scalability, integration, fault-tolerance, timeliness, consist-\nency, heterogeneity and incompleteness management, and load balancing.\n\nThere is the need to give more attention to the preprocessing stage of social media \nstream analysis in the face of incomplete, noisy, slang, and abbreviated words that are \npertinent to social media streams. Many researchers have looked at the aspect of the \nreal-time analysis of big data streams but not much attention has been directed towards \nsocial media stream preprocessing.\n\nIn addition, research efforts should be geared towards developing scalable frameworks \nand algorithms that will accommodate data stream computing mode, effective resource \nallocation strategy and parallelization issues to cope with the ever-growing size and \ncomplexity of data. As regards load balancing, a distributing environment that automati-\ncally streams partial data streams to a global centre when local resources become insuf-\nficient is required. The demand for big data stream analysis is that data must be analysed \nas soon as they arrive makes privacy issue a big concern. The main challenge here is \nproposing techniques for protecting a big data stream dataset before its analysis in such \na way that the real-time analysis is still maintained. As a result, research efforts should \nbe directed to the identified areas in order to have robust solutions for big data stream-\ning analytics.\n\nAbbreviations\nAUE: accuracy updated ensemble; AWE: accuracy weighted ensemble; AWOE: adaptive windowing based online \nensemble; CEP: complex event processing; CQR: continuous query processing; DWM: dynamic weighted majority; EM: \nexpectation–maximization; GOAL: GOd’s ALgorithm; IDC: International Data Cooperation; Inc I-MLOF: Incremental MI \noutlier detection algorithm; LSH: locality sensitive hashing; LSML: locally supervised metric learning; MQOS: multi-query \noptimization strategy; OAUE: online accuracy updated ensemble; OMCA: outlier method for cloud computing algorithm; \nSAE: sentiment analysis engine; SAMOA: scalable advanced massive online analysis; SS-MC: singular spectrum matrix \ncompletion; VPA: visibly push down automata; WOS-ELMK: weighted online sequential extreme learning machine with \nkernels.\n\nAcknowledgements\nThe research was supported by Covenant University Centre for Research, Innovation, and Discovery (CUCRID); Landmark \nUniversity, Omu-Aran, Osun State, Nigeria; The World Academy of Sciences for Research and Advanced Training Fellow-\nship, FR Number: 3240301383; and the Cape Peninsula University of Technology, South Africa.\n\nAuthors’ contributions\nTK gathered all the papers from various databases that were used for the manuscript and was a major contributor in \nwriting the manuscript. OD ensured that the guideline for systematic review literature was followed, and provided direc-\ntion for the literature-based research. AA contributed to the validation of selected primary studies. All authors contrib-\nuted to the selection of papers for the systematic review. All authors read and approved the final manuscript.\n\nFunding\nNot applicable.\n\n\n\nPage 26 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\nAvailability of data and materials\nAll data (papers) analysed are included in Scopus, ScienceDirect, and EBSCOhost.\n\nCompeting interests\nThe authors declare that they have no competing interests.\n\nAuthor details\n1 Department of Computer and Information Sciences, Covenant University, Ota, Nigeria. 2 Department of Computer Sci-\nence, Federal University Lokoja, Lokoja, Kogi, Nigeria. 3 Department of Information Technology, Cape Peninsula University \nof Technology, Cape Town, South Africa. 4 Department of Computer Science, Landmark University, Omu-Aran, Kwara, \nNigeria. \n\nReceived: 28 March 2019   Accepted: 28 May 2019\n\nReferences\n 1. Mavragani A, Ochoa G, Tsagarakis KP. Assessing the methods, tools, and statistical procedures in Google trends \n\nresearch: systematic review. J Med Internet Res. 2018;20(11):e270.\n 2. Sun D, Zhang G, Zheng W, Li K. Key technologies for big data stream computing. In: Li K, Jiang H, Yang LT, Guz-\n\nzocrea A, editors. Big data algorithms, analytics and applications. New York: Chapman and Hall/CRC; 2015. p. \n193–214. ISBN 978-1-4822-4055-9.\n\n 3. Qian ZP, He Y, Su CZ et al. TimeStream: Reliable stream computation in the cloud. In: Proc. 8th ACM European \nconference in computer system, EuroSys 2013. Prague: ACM Press; 2013. p. 1–4.\n\n 4. Liu R, Li Q, Li F, Mei L, Lee, J. Big data architecture for IT incident management. In: Proceedings of IEEE international \nconference on service operations and logistics, and informatics (SOLI), Qingdao, China. 2014. p. 424–9.\n\n 5. Sakr S. An introduction to Infosphere streams: A platform for analysing big data in motion. IBM. 2013. https ://\nwww.ibm.com/devel operw orks/libra ry/bd-strea msint ro/index .html. Accessed 7 Oct 2018.\n\n 6. Xhafa F, Naranjo V, Caballé S. Processing and analytics of big data stream with Yahoo!S4. In: 2015 IEEE 29th inter-\nnational conference on advanced information networking and applications, Gwangiu, South Korea, 24–27 March \n2015. 2015. https ://doi.org/10.1109/aina.2015.194.\n\n 7. Marz N. Storm: distributed and fault-tolerant real-time computation. In: Paper presented at Strata conference on \nmaking data work, Santa Clara, California, 28 Feb–1 March 2012. 2012. https ://cdn.oreil lysta tic.com/en/asset s/1/\nevent /75/Storm _%20dis tribu ted%20and %20fau lt-toler ant%20rea ltime %20com putat ion%20Pre senta tion.pdf. \nAccessed 25 Jan 2018.\n\n 8. Ballard C, Farrell DM, Lee M, Stone PD, Thibault S, Tucker S. IBM InfoSphere Streams: harnessing data in motion. IBM \nRedbooks. 2010.\n\n 9. Joseph S, Jasmin EA, Chandran S. Stream computing: opportunities and challenges in smart grid. Procedia Tech-\nnol. 2015;21:49–53.\n\n 10. IBM Research (no date) Stream computing platforms, applications and analytics. IBM. http://resea rcher .watso \nn.ibm.com/resea rcher /view_grp.php?id=2531 Accessed 5 Mar 2019.\n\n 11. Gantz J, Reinsel D. The digital universe in 2020: big data, bigger digital shadows, and biggest growth in the Far \nEast. New York: IDC iView: IDC Analyse future; 2012.\n\n 12. Cortes R, Bonnaire X, Marin O, Sens P. Stream processing of healthcare sensor data: studying user traces to identify \nchallenges from a big data perspective. The 4th international workshop on body area sensor networks (BAS-\nNet-2015). Procedia Comput Sci. 2015;52:1004–9.\n\n 13. Chung D, Shi H. Big data analytics: a literature review. J Manag Anal. 2015;2(3):175–201.\n 14. Lu J, Li D. Bias correction in a small sample from big data. IEEE Trans Knowl Data Eng. 2013;25(11):2658–63.\n 15. Garzo A, Benczur AA, Sidlo CI, Tahara D, Ywatt EF. Real-time streaming mobility analytics. In: Proc. 2013 IEEE interna-\n\ntional conference on big data, big data, Santa Clara, CA, United States, IEEE Press. 2013. p 697–702.\n 16. Zaharia M, Das T, Li H, Hunter T, Shenker S, Stoica I. Discretized streams: fault-tolerant streaming computation \n\nat scale. In: Proc. the 24th ACM symposium on operating system principles, SOSP 2013, Farmington, PA, United \nStates. New York: ACM Press; 2013. p. 423–38.\n\n 17. Fan J, Liu H. Statistical analysis of big data on pharmacogenomics. Adv Drug Deliv Rev. 2013;65(7):987–1000.\n 18. Bifet A, Holmes G, Kirkby R, Pfahringer B. Moa: massive online analysis. J Mach Learn Res. 2010;11:1601–4.\n 19. Akter S, Fosso WS. Big data analytics in e-commerce: a systematic review and agenda for future research. Electr \n\nMarkets. 2016;26:173–94.\n 20. Sivarajah U, Kamal MM, Irani Z, Weerakkody V. Critical analysis of big data challenges and analytical methods. J Bus \n\nRes. 2016;70:263–86.\n 21. Wienhofen LW, Mathisen BM, Roman D. Empirical big data research: a systematic literature mapping. CoRR, \n\nabs/1509.03045. 2015.\n 22. Habeeb RAA, Nasaruddin F, Gani A, Hashem IAT, Ahmed E, Imran M. Real-time big data processing for anomaly \n\ndetection: a survey. Int J Inform Manage. 2018;45:289–307. https ://doi.org/10.1016/j.ijinf omgt.2018.08.006.\n 23. Mehta N, Pandit A. Concurrence of big data analytics in healthcare: a systematic review. Int J Med Inform. \n\n2018;114:57–65.\n 24. Kitchenham BA, Charters S. Guidelines for performing systematic literature review in software engineering. Techni-\n\ncal report 2(3), EBSE-2007-01, Keele University and University of Durham. 2007.\n 25. Host M, Orucevic-Alagic A. A systematic review of research on open source software in commercial software prod-\n\nuct development. 2013. http://www.bcs.org/uploa d/pdf/ewic_ea10_sessi on5pa per2.pdf. Accessed 2 Mar 2018.\n\nhttps://www.ibm.com/developerworks/library/bd-streamsintro/index.html\nhttps://www.ibm.com/developerworks/library/bd-streamsintro/index.html\nhttps://doi.org/10.1109/aina.2015.194\nhttps://cdn.oreillystatic.com/en/assets/1/event/75/Storm_%20distributed%20and%20fault-tolerant%20realtime%20computation%20Presentation.pdf\nhttps://cdn.oreillystatic.com/en/assets/1/event/75/Storm_%20distributed%20and%20fault-tolerant%20realtime%20computation%20Presentation.pdf\nhttp://researcher.watson.ibm.com/researcher/view_grp.php%3fid%3d2531\nhttp://researcher.watson.ibm.com/researcher/view_grp.php%3fid%3d2531\nhttps://doi.org/10.1016/j.ijinfomgt.2018.08.006\nhttp://www.bcs.org/upload/pdf/ewic_ea10_session5paper2.pdf\n\n\nPage 27 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\n 26. Millman N. Analytics for business. Computerworld. 2014. https ://www.compu terwo rld.com/artic le/24758 40/big-\ndata/8-consi derat ions-when-selec ting-big-data-techn ology .html. Accessed 7 Oct 2018.\n\n 27. Oussous A, Benjelloun F, Lachen AA, Belfkih S. Big data technologies: a survey. J King Saud Univ Comput Inform \nSci. 2018;30:431–48.\n\n 28. Becker H, Naaman M, Gravano L. Learning similarity metrics for event identification in social media. In: Proceed-\nings of the third ACM international conference on web search and data mining (WSDM’10), ACM New York, NY, \nUSA, 4–6 Feb 2010. 2010. p. 291–300.\n\n 29. Aggarwal CC, Zhai C. A survey of text clustering algorithms. In: Aggarwal CC, Zhai C, editors. Mining text data. New \nYork: Springer; 2012. p. 77–128.\n\n 30. Panagiotou N, Katakis I, Gunopulos D. Detecting events in online social networks: Definitions, trends and chal-\nlenges. In: Michaelis S, et al., editors. Solving large scale learning tasks: challenges and algorithms. Lecture Notes in \nComputer Science, vol. 9850. Cham: Springer; 2016. p. 42–84. https ://doi.org/10.1007/978-3-319-41706 -6_2.\n\n 31. Deepa MS, Sujatha N. Comparative study of various clustering techniques and its characteristics. Int J Adv Netw \nAppl. 2014;5(6):2104–16.\n\n 32. Reddy KSS, Bindu CS. A review of density-based clustering algorithms for big data analysis. In: International confer-\nence on I-SMAC (IoT in Social, Mobile, Analytic, and Cloud), Palladam, India 10–11 February 2017, IEEE. 2017. https \n://doi.org/10.1109/i-smac.2017.80583 22.\n\n 33. Pelkowitz L. A continuous relaxation labelling algorithm for Markov random fields. IEEE Trans Syst Man Cybern. \n1990;20:709–15.\n\n 34. Li SZ. Markov random field modelling in image analysis. New York: Springer; 2001.\n 35. Zhong S. Efficient streaming text clustering. Neural Netw. 2005;18:5–6.\n 36. Aggarwal CC, Yu PS. A framework for clustering massive text and categorical data streams. In: Proceedings of \n\nthe sixth SIAM international conference on data mining, Bethesda, MD, USA, 20–22 Apr 2016. 2006. https ://doi.\norg/10.1137/1.97816 11972 764.44.\n\n 37. Li H, Jiang X, Xiong L, Liu J. Differentially private histogram publication for dynamic datasets: an adaptive sampling \napproach. Proc ACM Int Conf Knowl Manag. 2015. p. 1001–10. https ://doi.org/10.1145/28064 16.28064 41.\n\n 38. Deng JD. Outline detection energy data streams using incremental and kernel PCA algorithms. 2016 IEEE 16th \ninternational conference on data mining workshops. 2016. p. 390–7. https ://doi.org/10.1109/icdmw .2016.158.\n\n 39. Limsopatham N, Collier N. Adapting phrase-based machine translation to normalise medical terms in social media \nmessages. In: Proceedings of the 2015 conference on empirical methods in natural language processing, EMNLP \n2015, Lisbon. 2015. p.ρ 1675–80.\n\n 40. Kaushik R, Apoorva CS, Mallya D, Chaitanya JNVK, Kamath SS. Sociopedia: an interactive system for event detec-\ntion and trend analysis for Twitter data. In: Nagar A, Mohapatra D, Chaki N (eds) Smart innovation, systems and \ntechnologies, proceedings of 3rd international conference on advanced computing, networking and informatics. \nNew Delhi: Springer; 2016.\n\n 41. Carter S, Weerkamp W, Tsagkias E. Microblog language identification: overcoming the limitations of short, \nunedited and idiomatic text. Lang Resour Eval J. 2013;47(1):195–215.\n\n 42. Pooja P, Pandey A. Impact of memory intensive applications on performance of cloud virtual machine. In: Pro-\nceedings of 2014 recent advances in engineering and computational sciences (RAECS), UIET Panjab University \nChandigarh, 6–8 March 2014. 2014. p. 1–6. https ://doi.org/10.1109/raecs .2014.67996 29.\n\n 43. Chang M, Choi IS, Niu D, Zheng H. Performance impact of emerging memory technologies on big data applica-\ntions: a latency-programmable system emulation approach. In: Proceedings of 2018 on great lake symposium \non VLSI (GLSVLSI’18), Chicago, IL, USA, ACM New York, NY, USA, 23–25 May 2018. 2018. p. 439–42. https ://doi.\norg/10.1145/31945 54.31946 33.\n\n 44. Yang W, Da Silva A, Picard ML. Computing data quality indicators on big data streams using a CEP. In: International \nworkshop on computational intelligence for multimedia understanding IWCIM, Prague, Czech Republic, 29–30 \nOctober 2015. 2015.\n\n 45. Neumeyer L, Robbins B, Nair A, Kesari A. S4: Distribute stream computing platform. In: Proceedings of the 2010 \nIEEE international conference on data mining workshops. 2010. p. 170–7. https ://doi.org/10.1109/icdmw .2010.172.\n\n 46. Inoubli W, Aridhi S, Mezni H, Maddouri M, Nguifo E. A comparative study on streaming frameworks for big data. \nIn: 44th international conference on very large databases: workshop LADaS—Latin American Data Science, Aug \n2018, Rio de Janeiro, Brazil. 2018. p. 1–8.\n\n 47. Peng D, Dabek F Large-scale incremental processing using distributed transactions and notifications. In: Proc 9th \nUSENIX conf oper sys. des implement, Vancouver, BC, Canada, 4–6 Oct 2010. 2010. p. 1–15.\n\n 48. Marz N. Trident. 2012. https ://githu b.com/natha nmarz /storm /wiki/Tride nt-tutor ial. Accessed 8 Mar 2018.\n 49. Babcock B, Babu S, Datar M, Motwani R, Widom J. Models and issues in data stream systems. In: Proc of the 21st \n\nACM SIGACT-SIGMOD-SIGART symposium on principles of database systems (PODS), Madison, Wisconsin, 3–5 \nJune 2002. 2002. p. 1–16.\n\n 50. Chandrasekaran S, Cooper O, Deshpande A, Franklin MJ, Hellerstein JM, Hong W, Krishnamurthy S, Madden SR, \nReiss F, Shah MA. TelegraphCQ: Continuous dataflow processing. In: Proceedings of the 2003 ACM SIGMOD inter-\nnational conference on management of data, San Diego, California, 9–12 Jun 2003. 2003. p. 668.\n\n 51. Abadi DJ, Ahmad Y, Balazinska M, Cherniack M, Hwang JH, Lindner W, Maskey AS, Rasin E, Ryvkina E, Tatbul N, Xing \nY, Zdonik S. The design of the borealis stream processing engine. Second biennial conference on innovative data \nsystems research (CIDR 2005). CA: Asilomar; 2005. p. 277–89.\n\n 52. Groleat T. High-performance traffic monitoring for network security and management. Human–computer interac-\ntion [cs.HC]. Télécom Bretagne; Université de Bretagne Occidentale; 2014.\n\n 53. Kamburugamuve S, Fox G, Leake D, Qiu J. Survey of distributed stream processing for large stream sources. Grids \nUCS Indiana Educ. 2013. https ://doi.org/10.13140 /rg.2.1.3856.2968.\n\n 54. Murthy S. What are the disadvantages of Redis? 2016. https ://www.quora .com/What-are-the-disad vanta ges-of-\nRedis . Accessed 8 Mar 2018.\n\nhttps://www.computerworld.com/article/2475840/big-data/8-considerations-when-selecting-big-data-technology.html\nhttps://www.computerworld.com/article/2475840/big-data/8-considerations-when-selecting-big-data-technology.html\nhttps://doi.org/10.1007/978-3-319-41706-6_2\nhttps://doi.org/10.1109/i-smac.2017.8058322\nhttps://doi.org/10.1109/i-smac.2017.8058322\nhttps://doi.org/10.1137/1.9781611972764.44\nhttps://doi.org/10.1137/1.9781611972764.44\nhttps://doi.org/10.1145/2806416.2806441\nhttps://doi.org/10.1109/icdmw.2016.158\nhttps://doi.org/10.1109/raecs.2014.6799629\nhttps://doi.org/10.1145/3194554.3194633\nhttps://doi.org/10.1145/3194554.3194633\nhttps://doi.org/10.1109/icdmw.2010.172\nhttps://github.com/nathanmarz/storm/wiki/Trident-tutorial\nhttps://doi.org/10.13140/rg.2.1.3856.2968\nhttps://www.quora.com/What-are-the-disadvantages-of-Redis\nhttps://www.quora.com/What-are-the-disadvantages-of-Redis\n\n\nPage 28 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\n 55. Su X, Gilman E, Wetz P, Riekki J, Zuo Y, Leppanen T. Stream reasoning for the internet of things: challenges and gap \nanalysis. WIMS ‘16 proceedings of the 6th international conference on web intelligence, mining and semantics, \nNîmes, France—June 13–15, New York: ACM. Article no 1. 2016. https ://doi.org/10.1145/29128 45.29128 53.\n\n 56. Morales GDF, Bifet A. SAMOA: scalable advanced massive online analysis. J Mach Learn Res. 2015;16(1):149–53.\n 57. Amazon Web Services. Lambda architecture for batch and stream processing. 2018. https ://d1.awsst atic.com/\n\nwhite paper s/lambd a-archi tecur e-on-for-batch -aws.pdf Accessed 2 May 2019.\n 58. Kreps J. Questioning the Lambda architecture. 2014. https ://www.oreil ly.com/ideas /quest ionin g-the-lambd a-archi \n\ntectu re. Accessed 2 May 2019.\n 59. Tay Y. Data generation for application-specific benchmarking. Proc VLDB Endowment. 2011;4(12):1470–3.\n 60. HiBench big data benchmark suite. https ://githu b.com/intel -hadoo p/HiBen ch. Accessed 21 Dec 2018.\n 61. Hadoop 1.2.1 Documentation. GridMix. https ://hadoo p.apach e.org/docs/r1.2.1/gridm ix.html. Accessed 8 Mar \n\n2018.\n 62. Ouaknine K, Carey M, KirkPatrick S. The PigMix benchmark on Pig, MapReduce, and HPCC systems. 2015 IEEE \n\ninternational conference on big data, New York, NY, USA, 27 June–2 July 2015. p. 643–8. https ://doi.org/10.1109/\nbigda tacon gress .2015.99.\n\n 63. Ghazal A, Rabl T, Hu M, Raab F, Poess M, Crolotte A, Jacobson H. BigBench: towards an industry standard bench-\nmark for big data analytics. In: Proceedings of the 2013 ACM SIGMOID international conference on management \nof data, New York, NY, USA, 22–27 Jun 2013. p. 1197–203.\n\n 64. Bergamaschi S, Gagliardelli L, Simonini G, Zhu S. BigBench workload executed by using apache flink. Procedia \nManuf. 2017;11:695–702. https ://doi.org/10.1016/j.promf g.2017.07.169.\n\n 65. Wang L, Zhan J, Luo C, Zhu Y, Yang Q, He Y, et al. BigDataBench: a big data benchmark suite from internet services. \nIn: 2014 IEEE 20th international symposium on high performance architecture (HPCA), Orlando, FL, USA: IEEE, \n15–19 February 2014. 2014. https ://doi.org/10.1109/hpca.2014.68359 58.\n\n 66. Gao W, Zhan J, Wang L, Luo C, Zheng D, Wen X, et al. BigDataBench: A scalable and unified big data and AI bench-\nmark suite. 2018. arXiv.org > cs > arXiv :1802.08254 v2. https ://arxiv .org/abs/1802.08254 v2.\n\n 67. Liao X, Gao Z, Ji W, Wang Y. An enforcement of real-time scheduling in Spark Streaming. 6th international green \nand sustainable computing conference, IEEE. 2016. https ://doi.org/10.1109/igcc.2015.73937 30. p. 1–6.\n\n 68. Agerri R, Artola X, Beloki Z, Rigau G, Soroa A. Big data for natural language processing: a streaming approach. \nKnowledge‐based systems. 2015;79:36–42 ISSN 0950-7051.\n\n 69. Krawczyk B, Woźniak M. Incremental weighted one-class classifier for mining stationary data streams. J Comput \nSci. 2015;9:19–25.\n\n 70. Chan SWK, Chong MWC. Sentiment analysis in financial texts. Decis Support Syst. 2017;94:53–64.\n 71. Rakthanmanon T, Campana B, Mueen A, Batista G, Westover B, Zhu Q, Zakaria J, Keogh E. Addressing big data time \n\nseries: mining trillions of time series subsequences under dynamic time warping. ACM Trans Knowl Discov Data. \n2013;7(3):31. https ://doi.org/10.1145/25004 89.\n\n 72. Hadian A, Shahrivari S. High-performance parallel k-means clustering for disk-resident datasets on multi-core \nCPUs. J Supercomput. 2014;69(2):845–63.\n\n 73. Mozafari B, Zeng K, D’Antoni L, Zaniolo C. High-performance complex event processing over hierarchical data. \nACM Trans Datab Syst. 2013;38(4):39. https ://doi.org/10.1145/25367 79.\n\n 74. Sun Y, Wang Z, Liu H, Du C, Yuan J. Online ensemble using adaptive windowing for data streams with concept \ndrift. Int J Distrib Sens Netw. Article ID 4218973, 9 pages. 2016. http://dx.doi.org/10.1155/2016/42189 73.\n\n 75. Nguyen DT, Jung JJ. Real-time event detection on social data stream. Mobile Netw Appl. 2014;20(4):475–86.\n 76. Tsagkatakis G, Beferull-Lozano B, Tsakalides P. Singular spectrum-based matrix completion for time series recovery \n\nand prediction. EURASIP J Adv Signal Proces. 2016;2016:66. https ://doi.org/10.1186/s1363 4-016-0360-0.\n 77. Papapetrou O, Garofalakis M, Deligiannakis A. Sketching distributed sliding-window data streams. VLDB J. \n\n2015;24:345–68. https ://doi.org/10.1007/s0077 8-015-0380-7.\n 78. Elkhoukhi H, NaitMalek Y, Berouine A, Bakhouya M, Elouadghiri D, Essaaidi M. Towards a real-time occupancy \n\ndetection approach for smart buildings. Procedia Comput Sci. 2018;134:114–20.\n 79. Chakrabarti C. Delivering interactive access to data at massive scale at Barclays. Austin. 2016.\n 80. Kovacevc I, Mekterovic I. Novel BI data architectures. MIPRO 2018, Opatija, Croatia. 2018. p. 1191–6.\n 81. Veiga J, Enes J, Exposito RR, Tourino J. BDEv 3.0: energy efficiency and microarchitectural characterization of big \n\ndata processing frameworks. Fut Generat Comput Syst. 2018;86:565–81.\n 82. Tozzi, C. Dummy’s guide to batch vs. streaming. Trillium Software. 2017. http://blog.syncs ort.com/2017/07/big-\n\ndata/big-data-101-batch -strea m-proce ssing /. Accessed 2 Mar 2018.\n 83. Dusi M, D’Heureuse N, Huici F, Trammell B, Niccolini S. Blockmon: flexible and high performance big data stream \n\nanalytics platform and its use cases. NEC Tech J. 2012;7:102–6.\n 84. Puthal D, Nepal S, Ranjan R, Chen J. A dynamic prime number based efficient security mechanism for big sensing \n\ndata streams. J Comput Syst Sci. 2017;83:22–42.\n 85. Vanathi R, and Khadir ASA. A robust architectural framework for big data stream computing in personal healthcare \n\nreal-time analytics. World Congress on Computing and Communication Technologies. 2017. p. 97–104. https ://doi.\norg/10.1109/wccct .2016.32.\n\n 86. Ma K, Yang B. Stream-based live entity resolution approach with adaptive duplicate count strategy. Int J Web Grid \nServ. 2017;13(3):351–73.\n\n 87. Murphy BM, O’Driscoll C, Boylan GB, Lightbody G, Marnane WP. Stream computing for biomedical signal process-\ning: A QRS complex detection case study. In: Conf proc IEEE eng med biol soc. 2015. https ://doi.org/10.1109/\nembc.2015.73197 41. p. 5928–31.\n\n 88. Apache Spark Streaming—Spark 2.1.0 Documentation. http://spark .apach e.org/strea ming.\n 89. Sun H, Birke R, Bjorkqvist M, Chen LY. AccStream: accuracy-aware overload management for stream processing \n\nsystems. In: IEEE conference on autonomic computing. New York: Elsevier; 2017. p. 39–48.\n 90. Canbay Y, Sağıroğlu S. Big data anonymization with spark (UBMK’17). In: 2nd IEEE international conference \n\non computer science and engineering. 2017. p. 833–8.\n\nhttps://doi.org/10.1145/2912845.2912853\nhttps://d1.awsstatic.com/whitepapers/lambda-architecure-on-for-batch-aws.pdf\nhttps://d1.awsstatic.com/whitepapers/lambda-architecure-on-for-batch-aws.pdf\nhttps://www.oreilly.com/ideas/questioning-the-lambda-architecture\nhttps://www.oreilly.com/ideas/questioning-the-lambda-architecture\nhttps://github.com/intel-hadoop/HiBench\nhttps://hadoop.apache.org/docs/r1.2.1/gridmix.html\nhttps://doi.org/10.1109/bigdatacongress.2015.99\nhttps://doi.org/10.1109/bigdatacongress.2015.99\nhttps://doi.org/10.1016/j.promfg.2017.07.169\nhttps://doi.org/10.1109/hpca.2014.6835958\nhttp://arxiv.org/abs/1802.08254v2\nhttps://arxiv.org/abs/1802.08254v2\nhttps://doi.org/10.1109/igcc.2015.7393730\nhttps://doi.org/10.1145/2500489\nhttps://doi.org/10.1145/2536779\nhttp://dx.doi.org/10.1155/2016/4218973\nhttps://doi.org/10.1186/s13634-016-0360-0\nhttps://doi.org/10.1007/s00778-015-0380-7\nhttp://blog.syncsort.com/2017/07/big-data/big-data-101-batch-stream-processing/\nhttp://blog.syncsort.com/2017/07/big-data/big-data-101-batch-stream-processing/\nhttps://doi.org/10.1109/wccct.2016.32\nhttps://doi.org/10.1109/wccct.2016.32\nhttps://doi.org/10.1109/embc.2015.7319741\nhttps://doi.org/10.1109/embc.2015.7319741\nhttp://spark.apache.org/streaming\n\n\nPage 29 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\n 91. Sahana RG, Babu BS. Converting an E-commerce prospect into a customer using streaming analytics. In: 2nd \ninternational conference on applied and theoretical computing and communication technology (iCATccT) IEEE. \n2016. p. 312–7. https ://doi.org/10.1109/icatc ct.2016.79120 14.\n\n 92. Troiano L, Vaccaro A, Vitelli MC. On-line smart grids optimization by case-based reasoning on big data. In: 2016 \nIEEE workshop on environmental, energy, and structural monitoring systems (EESMS), Bari, Italy, 13–14 Jun 2016.\n\n 93. Joseph S, Jasmin EA. Stream computing framework for outage detection in smart grid. In: Proceedings of 2015 \nIEEE international conference on power, instrumentation, control and computing (PICC), Thrissur, India, 9–11 Dec \n2015. 2015. https ://doi.org/10.1109/picc.2015.74557 44.\n\n 94. Apache. Apache Storm. 2016. http://storm .apach e.org. Accessed 10 Oct 2018.\n 95. Gokalp MO, Kocyigit A, Eren PE. A visual programming framework for distributed Internet of Things centric com-\n\nplex event processing. Comput Elect Eng. 2018;74:581–604.\n 96. Maio CD, Fenza G, Loia E, Orciuoli F. Distributed online temporal fuzzy concept analysis for stream processing in \n\nsmart cities. J Parallel Distrib Comput. 2017;110:31–41.\n 97. Val PB, Garcia NF, Sanchez-Fernandez L, Arias-Fisteus J. Patterns for distributed real-time stream processing. IEEE \n\nTrans Parallel Distrib Syst. 2017;2(11):3243–57. https ://doi.org/10.1109/TPDS.2017.27169 29.\n 98. Fernandez-Rodrigues JY, Alvarez-Garcia JA, Fisteus JA, Luaces MR, Magana VC. Benchmarking real-time vehicle \n\ndata streaming models for a smart city. Inform Syst. 2017;72:62–76.\n 99. Bifet A. Mining big data in real time. Informatica (Slovenia). 2013;37:15–20.\n 100. Apache. Apache Samza-What is Samza? 2016. http://samza .apach e.org. Accessed 8 Oct 2018.\n 101. Ananthanarayanan R, Basker V, Das S, Gupta A, Jiang H, Qiu T, Reznichenko A, Ryabkov D, Singh M, Venkataraman \n\nS. Photon: fault-tolerant and scalable joining of continuous data streams. In: Proceedings of 2013 ACM SIGMOD \ninternational conference on management of data, New York, New York, USA, 22–27 June 2013. 2013. p. 577–88.\n\n 102. Apache Apache Aurora. 2016. http://auror a.apach e.org. Accessed 7 Oct 2018.\n 103. Jiang Q, Adaikkalavan R, Chakravarthy S. MavEStream: synergistic integration of stream and event processing. In: \n\n2007 second international conference on digital telecommunications (ICDT’07) San Jose, CA, USA. 2007. p 29–361. \nhttps ://doi.org/10.1109/icdt.2007.21 IEEE Xplore.\n\n 104. Yang W, Da Silva A, Picard ML. Computing data quality indicators on big data streams using a CEP. In: 2015 Inter-\nnational workshop on computational intelligence for multimedia understanding (IWCIM), Prague, Czech Republic, \n29–30 Oct 2015. 2015.\n\n 105. EsperTech. http://www.esper tech.com. Accessed 8 Oct 2018.\n 106. Song M, Kim MC.  RT2M: real-time twitter trend mining system. In: Proceedings of international conference on \n\nsocial intelligence and technology (SOCIETY), State College, PA, USA, 8–10 May 2013. 2013. p. 64–71.\n 107. Barbieri DF, Braga D, Ceri S. Querying RDF streams with C-SPARQL. ACM Sigmoid. 2010;39(1):20–36. https ://doi.\n\norg/10.1145/18607 02.18607 05.\n 108. Ren X, Khrouf H, Kazi-Aoul Z, ChabChoub Y, Cure O. On measuring performances of C-SPARQL and CQELS. CoRR, \n\nabs/1611.08269. 2016.\n 109. Morales GF. SAMOA: A platform for mining big data streams. WWW 2013 Companions, Rio de Janeiro, Brazil, 13–17 \n\nMay 2013. 2013.\n 110. Keeney J, Fallon L, Tai W, O’Sullivan D. Towards composite semantic reasoning for real-time network management \n\ndata enrichment. In: Proceedings of the 11th international conference on network and service management \n(CNSM), Barcelona, Spain, 9–13 Nov 2013. 2015. p. 182–6.\n\n 111. Le-Phuoc D, Dao-Tran M, Parreira JX, Hauswirth M. A native and adaptive approach for unified processing of linked \nstreams and linked data. In: International semantic web conference, Koblenz, Germany, 23–27 October 2011. \n2011. p. 370–88.\n\n 112. Anicic D, Rudolph S, Fodor P, Stojanovic N. Stream reasoning and complex event processing in ETALIS. Sem Web \nLinked Spatiotemp Data Geo-Ontolo. 2012;3(4):397–407.\n\n 113. Apache Kylin. Kylin cube from streaming (Kafka). 2015. http://kylin .apach e.org/docs1 5/tutor ial/cube_strea ming.\nhtml. Accessed 2 Oct 2018.\n\n 114. Splunk. Splunk Stream. 2017. https ://splun kbase .splun k.com/app/1809/. Accessed 2 Oct 2018.\n 115. Shnayder V, Chen B, Lorincz K, Fulford-Jones TRF, Welsh M. Sensor networks for medical care. Technical report \n\nTR-08-05, Division of Engineering and Applied Sciences, Harvard University. 2005. https ://www.eecs.harva \nrd.edu/~shnay der/paper s/codeb lue-techr ept05 .pdf. Accessed 8 Oct 2018.\n\n 116. Dror Y. Practical elastic search anomaly detection made powerful with anodot. 2017. https ://www.anodo t.com/\nblog/pract ical-elast icsea rch-anoma lydet ectio n-made-owerf ul-with-anodo t/. Accessed 8 Mar 2019.\n\n 117. Baciu G, Li C, Wang Y, Zhang X. Cloudets: Cloud-based cognition for large streaming data. In: Ge N, Lu J, Wang Y, \nHoward N, Chen P, Tao X, Zhang B, Zadeh LA (eds) Proceedings of IEEE 14th international conference on cognitive \ninformatics and cognitive computing (ICCI*CC’15), Tsinghua, Univ., Beijing, China, 6–8 Jul 2015. 2015. p. 333–8.\n\n 118. Tedeschi A, Benedetto F. A cloud-based big data sentiment analysis application for enterprises’ brand monitor-\ning in social media streams. In: 2015 IEEE 1st international forum on research and technologies for society and \nindustry leveraging a better tomorrow (RTSI), Turing, Italy, 16–18 Sept 2015. 2015. p 186–91.\n\n 119. Lavin A, Ahmad S. Evaluating real-time anomaly detection algorithms–the Numenta anomaly benchmark. In: 2015 \nIEEE 14th international conference on machine learning and applications (ICMLA), Miami, FL, USA, 9–11 Dec 2015. \n2015. https ://doi.org/10.1109/icmla .2015.141.\n\n 120. Chen X, Chen H, Zhang N, Huang J, Zhang W. Large-scale real-time semantic processing framework for Internet of \nThings. Int J Distrib Sens Netw. 2015;365372:11. https ://doi.org/10.1155/2015/36537 2.\n\n 121. Branscombe M. How Microsoft’s fast track Azure will help businesses conquer IoT. 2015. http://www.techr adar.\ncom/news/inter net/cloud -servi ces/howmi croso ft-s-fast-track -azure -will-help-busin esses -conqu er-iot-12910 25. \nAccessed 8 Mar 2018.\n\n 122. Biem A, Bouillet E, Feng H, Ranganathan A, Riabov A, Verscheure O, Koutsopoulos H, Moran C. IBM InfoSphere \nstreams for scalable, real-time, intelligent transportation services. SIGMOID’10 Indianapolis, Indiana, USA, 6–11 Jun \n2010. 2010. p. 1093–100.\n\nhttps://doi.org/10.1109/icatcct.2016.7912014\nhttps://doi.org/10.1109/picc.2015.7455744\nhttp://storm.apache.org\nhttps://doi.org/10.1109/TPDS.2017.2716929\nhttp://samza.apache.org\nhttp://aurora.apache.org\nhttps://doi.org/10.1109/icdt.2007.21\nhttp://www.espertech.com\nhttps://doi.org/10.1145/1860702.1860705\nhttps://doi.org/10.1145/1860702.1860705\nhttp://kylin.apache.org/docs15/tutorial/cube_streaming.html\nhttp://kylin.apache.org/docs15/tutorial/cube_streaming.html\nhttps://splunkbase.splunk.com/app/1809/\nhttps://www.eecs.harvard.edu/%7eshnayder/papers/codeblue-techrept05.pdf\nhttps://www.eecs.harvard.edu/%7eshnayder/papers/codeblue-techrept05.pdf\nhttps://www.anodot.com/blog/practical-elasticsearch-anomalydetection-made-owerful-with-anodot/\nhttps://www.anodot.com/blog/practical-elasticsearch-anomalydetection-made-owerful-with-anodot/\nhttps://doi.org/10.1109/icmla.2015.141\nhttps://doi.org/10.1155/2015/365372\nhttp://www.techradar.com/news/internet/cloud-services/howmicrosoft-s-fast-track-azure-will-help-businesses-conquer-iot-1291025\nhttp://www.techradar.com/news/internet/cloud-services/howmicrosoft-s-fast-track-azure-will-help-businesses-conquer-iot-1291025\n\n\nPage 30 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\n 123. Akidau T, Balikov A, Bekiroglu K, Chernyak S, Haberman J, Lax R, McVeety S, Mills D, Nordstrom P, Whittle S. Mill-\nWheel: fault-tolerant stream processing at internet scale. Proc VLDB Endowment. 2013;6(11):1033–44.\n\n 124. Blount M, Ebling MR, Eklund JM, James AG, McGregor C, Percival N, Smith KP, Sow D. Real-time analysis for inten-\nsive care: development and deployment of the artemis analytic system. IEEE Eng Med Biol Mag. 2010;29(2):110–8. \nhttps ://doi.org/10.1109/MEMB.2010.93645 4.\n\n 125. Introducing WSO2 Data Analytics Server. 2015. https ://docs.wso2.com/displ ay/DAS30 0/Intro ducin g+DAS. \nAccessed 8 Mar 2019.\n\n 126. Ali M, Chandramouli B, Goldstein J, Schindlauer R. The extensibility framework in Microsoft StreamInsight. In: Pro-\nceedings of the 2011 IEEE 27th international conference on data engineering (ICDE), Washington, DC, USA, 11–16 \nApr 2011. 2011. p. 1242–53.\n\n 127. TIBCO StreamBase Documentation. https ://docs.tibco .com. Accessed 8 Mar 2018.\n 128. Wilkes S. Making in-memory computing enterprise-grade—overview–Striim. 2016. http://www.strii m.com/\n\nblog/2016/06/makin g-in-memor ycomp uting -enter prise -grade -overv iew/ Accessed 8 Mar 2019.\n 129. Kyvos Insights. Kyvos insights 2018. 2018. https ://www.kyvos insig hts.com/. Accessed 1 Feb 2018.\n 130. AtScale. AtScale overview (version 4.1). 2017. http://info.atsca le.com/atsca le-overv iew. Accessed 2 Feb 2018.\n 131. AtScale. AtScale. 2018. http://atsca le.com/produ ct/. Accessed 2 Feb 2018.\n 132. Gedik B, Andrade H, Wu K, Yu PS, Doo M. Spade: the S declarative stream processing engine. In: 2008 ACM SIG-\n\nMOID international conference on management of data, Vancouver, Canada, 9–12 Jun 2008. 2008. p. 1123–34.\n 133. Mimic, II. http://physi onet.org/physi obank /datab ase/mimic 2db/. Accessed 4 Nov 2016.\n 134. Wu Z, Zou M. An incremental community detection method for social tagging systems using locality sensitive \n\nhashing. Neural Netw. 2014;58:14–28. https ://doi.org/10.1016/j.neune t.2014.05.019.\n 135. O’Callaghan L, Mishra N, Meyerson A, Guha S, Motwani R. Streaming-data algorithms for high-quality clustering. \n\nIn: Proceedings of IEEE international conference on data engineering, San Jose, CA, USA, 26 Feb–1 Mar 2002. 2002. \np. 685–94.\n\n 136. Aggarwal CC, Han JW, Wang JY. A framework for clustering evolving data streams. In: Proceedings of the 29th \nVLDB conference, vol. 29, Berlin, Germany, 9–12 Sep 2003. 2003. p. 81–92.\n\n 137. Backhoff O, Ntoutsi E. Scalable online-offline stream clustering in apache spark. In: 2016 IEEE 16th international \nconference on data mining workshops (ICDMW), Barcelona, Spain, 12–15 Dec 2016. 2016. p. 37–44. https ://doi.\norg/10.1109/icdmw .2016.0014.\n\n 138. Aggarwal CC, Han J, Wang J, Yu PS. A framework for projected clustering of high dimensional data streams. In: \nProceedings of the 30th international conference on very large data bases, 30, Toronto, Canada, 31 Aug–3 Sep \n2004. 2004. p. 852–63.\n\n 139. Cao F, Ester M, Qian W, Zhou A. Density-based clustering over an evolving data stream with noise. In: 2006 SIAM \nconference on data mining. 2006. p. 328–39.\n\n 140. Chen Y, Tu L. Density-based clustering for real-time stream data. In: Proceedings of the 13th ACM SIGKDD interna-\ntional conference on knowledge discovery and data mining, San Jose, CA, USA, 12–15 Aug 2007. 2007. p. 133–42.\n\n 141. Zhu WH, Yin J, Xie YH. Arbitrary shape cluster algorithm for clustering data stream. J Softw. 2006;17(3):379–87.\n 142. Khalilian M, Mustapha N, Sulaiman N. Data stream clustering by divide and conquer approach based on vector \n\nmodel. J Big Data. 2016;3:1. https ://doi.org/10.1186/s4053 7-015-0036-x.\n 143. Dai DB, Zhao G, Sun SL. Effective clustering algorithm for probabilistic data stream. J Softw. 2009;20(5):1313–28.\n 144. Ding S, Zhang J, Jia H, Qian J. An adaptive density data stream clustering algorithm. Cogn Comput. 2016;8(1):1–9. \n\nhttps ://doi.org/10.1007/s1255 9-015-9342-z.\n 145. Choi D, Song S, Kim B, Bae I. Processing moving objects and traffic events based on spark streaming. In: Proceed-\n\nings of the 8th international conference on disaster recovery and business continuity (DRBC), Jeju, South Korea, \n25–28 Nov 2015. 2015. p. 4–7.\n\n 146. Chen XJ, Ke J. Fast processing of conversion time data flow in cloud computing via weighted FPtree mining \nalgorithms. In: 2015 IEEE 12th intl conf on ubiquitous intelligence and computing and 2015 IEEE 12th intl conf on \nautonomic and trusted computing and 2015 IEEE 15th intl conf on scalable computing and communications and \nits associated workshops (UIC-ATC-ScalCom), Beijing, China, 10–14 Aug 2015. 2015.\n\n 147. Li T, Wang L. Key technology of online auditing data stream processing. In: 2015 IEEE 12th intl conf on ubiquitous \nintelligence and computing and 2015 IEEE 12th intl conf on autonomic and trusted computing and 2015 IEEE \n15th intl conf on scalable computing and communications and its associated workshops (UIC-ATC-ScalCom), \nBeijing, China, 10–14 Aug 2015. 2015.\n\n 148. Xiao F, Aritsugi M, Wang Q, Zhang R. Efficient processing of multiple nested event pattern queries over multi-\ndimensional event streams based on a triaxial hierarchical model. Artif Intell Med. 2016;72(1):56–71. https ://doi.\norg/10.1016/j.artme d.2016.08.002.\n\n 149. Wang Z, Zhao Z, Weng S, Zhang C. Incremental multiple instance outlier detection. Neural Comput Appl. \n2015;26:957–68. https ://doi.org/10.1007/s0052 1-014-1750-6.\n\n 150. Ruiz E, Casillas J. Adaptive fuzzy partitions for evolving association rules in big data stream. Int J Approx Reasoning. \n2018;93:463–86.\n\n 151. Jadhav SA, Kosbatwar SP. Concept-adapting very fast decision tree with misclassification error. Int J Adv Res Com-\nput Eng Technol (IJARCET). 2016;5(6):1763–7.\n\nPublisher’s Note\nSpringer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.\n\nhttps://doi.org/10.1109/MEMB.2010.936454\nhttps://docs.wso2.com/display/DAS300/Introducing%2bDAS\nhttps://docs.tibco.com\nhttp://www.striim.com/blog/2016/06/making-in-memorycomputing-enterprise-grade-overview/\nhttp://www.striim.com/blog/2016/06/making-in-memorycomputing-enterprise-grade-overview/\nhttps://www.kyvosinsights.com/\nhttp://info.atscale.com/atscale-overview\nhttp://atscale.com/product/\nhttp://physionet.org/physiobank/database/mimic2db/\nhttps://doi.org/10.1016/j.neunet.2014.05.019\nhttps://doi.org/10.1109/icdmw.2016.0014\nhttps://doi.org/10.1109/icdmw.2016.0014\nhttps://doi.org/10.1186/s40537-015-0036-x\nhttps://doi.org/10.1007/s12559-015-9342-z\nhttps://doi.org/10.1016/j.artmed.2016.08.002\nhttps://doi.org/10.1016/j.artmed.2016.08.002\nhttps://doi.org/10.1007/s00521-014-1750-6\n\n\tBig data stream analysis: a systematic literature review\n\tAbstract \n\tIntroduction\n\tBackground and related work\n\tStream computing\n\tBig data stream analysis\n\tKey issues in big data stream analysis\n\tScalability\n\tIntegration\n\tFault-tolerance\n\tTimeliness\n\tConsistency\n\tHeterogeneity and incompleteness\n\tLoad balancing\n\tHigh throughput\n\tPrivacy\n\tAccuracy\n\n\tRelated work\n\n\tResearch method\n\tResearch question\n\tSearch string\n\tData sources\n\tData retrieval\n\tInclusion criteria\n\tExclusion criteria\n\n\n\tResult\n\tResearch Question 1: What are the tools and technologies employed for big data stream analysis?\n\tShape of the data\n\tData access\n\tAvailability and consistency requirement\n\tWorkload profile required\n\tLatency requirement\n\n\tResearch Question 2: What methods and techniques are used in analysing big data streams?\n\tResearch Question 3: What do big data streaming tools and technologies have in common and their differences in terms of concept, purpose, and capabilities?\n\tResearch Question 4: What are the limitations and strengths of big data streaming tools and technologies?\n\tResearch Question 5: What are the evaluation techniques or benchmarks that are used for evaluating big data streaming tools and technologies?\n\n\tDiscussion\n\tLimitation of the review\n\tConclusion and further work\n\tAcknowledgements\n\tReferences\n\n\n\n\n",
      "metadata_storage_path": "aHR0cHM6Ly9jb3Jwb3JhdGV0cmFpbmluZ3N0b3JhZ2UuYmxvYi5jb3JlLndpbmRvd3MubmV0L3BhcGVycy9zNDA1MzctMDE5LTAyMTAtNy5wZGY1",
      "metadata_author": "Taiwo Kolajo ",
      "metadata_title": "Big data stream analysis: a systematic literature review",
      "metadata_creation_date": "2019-06-04T14:40:29Z",
      "keyphrases": [
        "Big data stream analysis",
        "systematic literature review"
      ]
    }
  ]
}